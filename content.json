[{"title":"博客搭建流程","date":"2020-01-15T17:18:17.000Z","path":"2020/01/博客搭建流程/","text":"背景准备用公司的电脑写博客上传到github，然后部署。之前的代码库在原来自己的电脑上，github上只有部署后的代码。遇到的问题就是，换了电脑之后如何切换写好的博客文章库 安装流程使用Hexo搭建github博客 Hexo搭建的博客其实是个静态的博客，每次需要新发表一篇博客时，需要在本地库中新增一个.md文件，执行hexo g再次生成一个新的网页，然后执行hexo d进行网页的部署，从而替换到原先的网页 优势：有着更大的自主性，从主题到博文展示 劣势：不能在线编辑，需要自己管理博文库 依赖的软件：Node.js 前提条件： 已安装Git工具 已有GitHub账号 （Mac）已安装Xcode command line tools 第一步-安装Node.js参考博文 官网下载地址 我直接在官网下下载的，一路安装都不存在问题 第二步-安装Hexo执行命令 install -g hexo-cli 1npm install -g hexo-cli 一开始我报了个某个文件夹没有写入权限 加上sudo再次执行就OK了 为了方便部署，安装 1npm install hexo-deployer-git --save 同时修改_config.yml文件 1234deploy: type: git repository: git@github.com:oldbuffalo&#x2F;oldbuffalo.github.io.git # 仓库用ssh 需要配一下公钥 branch: master 为了执行所有文章按钮 1npm i hexo-generator-json-content --save 迁移的过程中，我采用的比较笨的方法，将原先电脑中的文件夹拷贝到公司电脑 缺点：不方便，如果原先电脑出问题了，就不存在了 关于里面文件作用的解释： _config.yml 配置文件 必须拷贝 theme 自己下载的可选主题 必须拷贝 source 最重要 博文源码 必须拷贝 scaffolds 文章模板 不必拷贝 package.json 说明使用哪些包 不必拷贝 .gitignore 限制提交的时候哪些文件可以忽略 不必拷贝 后三个文件在执行 hexo init的时候会自动生成，上面六个可以全部拷贝过去 .git 没必要拷贝 node_modules npm install会重新生成 public hexo g 重新生成 .deploy_git hexo g 重新生成 db.json 不用管 其实上面五个文件也就是.gitignore文件里面记载的可以忽略的内容 需要注意的是：如果采用拷贝文件的方式迁移，则不必再执行hexo init，因为_config.yml会被重写 更优秀的做法看到知乎上有人在github上创建了两个分支，master用来发布，hexo存放hexo源码，以后每次需要迁移的时候只要配置一下hexo环境，然后git clone一下hexo分支下面的代码 参考链接 注意点修改配置文件的时候permalink 要与new_post_name 路径对齐 12permalink: :year&#x2F;:month&#x2F;:title&#x2F; # 控制页面点击博文时候的urlnew_post_name: :year&#x2F;:month&#x2F;:title.md # 控制新建博文时 在_posts中的路径","comments":true,"tags":[{"name":"git","slug":"git","permalink":"https://oldbuffalo.github.io/tags/git/"},{"name":"软件安装","slug":"软件安装","permalink":"https://oldbuffalo.github.io/tags/%E8%BD%AF%E4%BB%B6%E5%AE%89%E8%A3%85/"}]},{"title":"STL容器性能测试","date":"2019-04-28T11:15:35.000Z","path":"2019/04/STL容器性能测试/","text":"之前说到STL有六大部件，这里着重介绍一下容器部分。 容器就是用来装数据的，难的地方就是需要根据数据的特征以及考虑要对数据进行的操作选择合适的容器，同时还要考虑容器的内存分布。 STL容器总览图 其中主要分为顺序式和关联式。关联式的查找速度更快 array、vector、deque底层数据结构都是数组 list、forward_list底层数据结构是链表 set、multiset、map、multimap底层数据结构是红黑树 其中set、map键值不允许重复，multiset、multimap允许重复 unordered_set、unordered_multiset、unordered_map、unordered_multimap、 hash_set、hash_multiset、hash_multimap、hash_map底层数据结构是hash表 还有图中没写出来的stack、queue、priority_queue都是线性结构 STL容器详细文档 小技巧：在编写测试程序的时候，让每个单元在独立的命名空间里面 顺序式容器array这是C++11新添加的容器，封装了最常用的数组 array测试代码 vectorvector测试代码 vector只有push_back操作，而没有push_front操作，是因为push_front的话之后的元素都要后移，很耗费时间。在插入操作的时候不够的话自动扩展，二倍扩展，将原有数据拷贝到新的空间，然后释放旧空间。 通过测试，发现STL算法中的find算法相比较于 先排序(快排)再二分查找 前者查找的速度快很多。 listlist测试代码 双向链表，头尾都可以添加和删除 forward_listforward_list测试代码 单向链表，这也是C++11新添加的容器，只能头添加和头删除，因为如果没有指针标记链表尾部的话，从末尾添加元素每次都需要遍历到末尾，效率很低。 dequedeque测试代码 双端队列,内存不是真正意味上的连续，每一段之间是连续的,头尾都能添加和删除 stack栈(先进后出) ，push和pop操作 stack测试代码 queue队列(先进先出)，push和pop操作 queue测试代码 需要注意的是: 由上图可见，deque也能够完成stack的功能 由上图可见，deque也能够完成queue的功能 实际上，stack和queue的源代码内部拥有一个deque。也就是stack和queue本身没有去实现数据结构，而是用deque作为支撑。因此，stack和queue也能叫做容器的适配器。 关联式容器(适合查找)key值可以重复multisetmultiset测试代码 注意包含的是set头文件，插入元素用insert方法 使用全局的find()和容器自带的find()函数进行查找效率的比较，发现容器自带的find速度更大。 multimapmultimap测试代码 注意包含的是map头文件，插入元素用insert方法,用pair&lt;&gt;构建插入的键值对 unordered_multisetC++11新加入的容器 unordered_multiset测试代码 注意包含的是unordered_set头文件，插入元素用insert方法 使用全局的find()和容器自带的find()函数进行查找效率的比较，发现容器自带的find速度更大。 unordered_multimapC++11新加入的容器 unordered_multimap测试代码 注意包含的是unordered_map头文件，插入元素用insert方法,用pair&lt;&gt;构建插入的键值对 key值不能重复set和上面的multiset和unordered_multiset的区别在于，key值唯一不能有重复 set测试代码 map和上面的multimap和unordered_multimap的区别在于，key值唯一不能有重复 插入元素可以用[]和insert,而multimap只能用insert map测试代码 unordered_setC++11新加入的容器 unordered_set测试代码 和上面的multiset和unordered_multiset的区别在于，key值唯一不能有重复 unordered_mapC++11新加入的容器 和上面的multimap和unordered_multimap的区别在于，key值唯一不能有重复 插入元素可以用[]和insert unordered_map测试代码 注意点：各种类型的map都不支持全局的find函数 GNU C的标准库带的hash_set、hash_map、hash_multiset、hash_multimap就是现在C++11中以unordered开头的容器，因此就不再进行测试了。 GNU C 也有一个非标准库的单向链表类slist","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"},{"name":"STL","slug":"STL","permalink":"https://oldbuffalo.github.io/tags/STL/"}]},{"title":"策略模式","date":"2019-04-27T06:57:46.000Z","path":"2019/04/策略模式/","text":"策略模式和模板方法有着异曲同工之妙。 应用场景在软件构建过程中，某些对象使用的算法可能多种多样，经常改变，如果将这些算法都编码到对象中，将会使对象变得异常复杂，而且有时候支持不使用的算法也是一个性能负担。 定义： 定义一系列算法，把它们一个个封装起来，并且使它们可互相替换(变化)，该模式使得算法可独立于使用它的客户程序(稳定)而变化(扩展，子类化)。 实例演示，在许多电子商务平台有很多税务的计算 1234567891011121314151617181920212223enum TaxBase&#123; &#x2F;&#x2F;考虑跨国结算 CN_Tax, US_Tax, DE_Tax&#125;;class SalesOrder&#123; TaxBase tax;public: double CalculateTax()&#123; &#x2F;&#x2F;... if(tax &#x3D;&#x3D; CN_Tax)&#123; &#x2F;&#x2F;CN...... &#125; else if(tax &#x3D;&#x3D; US_Tax)&#123; &#x2F;&#x2F;US...... &#125; else if(tax &#x3D;&#x3D; DE_Tax)&#123; &#x2F;&#x2F;DE... &#125; &#x2F;&#x2F;... &#125;&#125;; 上面这种实现的弊端显而易见，如果在未来加入计算更多国家税务的需求，需要大量的更改源代码，违背了开闭原则。 使用策略模式之后的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445class TaxStrategy&#123;public: virtual double Calculate(const Context &amp;context) &#x3D; 0; virtual ~TaxStrategy()&#123;&#125;&#125;;class CNTax:public TaxStrategy&#123;public: virtual double Calculate(const Context &amp;context)&#123; &#x2F;&#x2F;..... &#125;&#125;;class USTax:public TaxStrategy&#123;public: virtual double Calculate(const Context &amp;context)&#123; &#x2F;&#x2F;..... &#125;&#125;；class DETax:public TaxStrategy&#123;public: virtual double Calculate(const Context &amp;context)&#123; &#x2F;&#x2F;..... &#125;&#125;；class SalesOrder&#123;private: TaxStrategy* strategy; &#x2F;&#x2F;因为是抽象类 所以必须放一个多态指针public: SalesOrder(StrategyFactory* strategyFactory)&#123; this-&gt;strategy&#x3D;strategyFactory-&gt;NewStrategy();&#x2F;&#x2F;通过工厂决定new哪个对象 &#125; ~SalesOrder()&#123; delete this-&gt;strategy; &#125; double CalculateTax()&#123; &#x2F;&#x2F;... Context contect; double val &#x3D; strategy-&gt;Calculate(contect); &#x2F;&#x2F;... &#125;&#125;; 当加入新的需求的时候，只需要新写一个类继承TaxStrategy类并重写Calculate方法。别的地方代码都没动，也就是SalesOrder得到了复用性。 类图 其中Context类就是上面的SalesOrder类， Strategy类是上面的TaxStrategy类。 这两个类是稳定的。 这里的关键就是将算法的逻辑抽象接口(ContextInterface)封装到Context类中 总结 Strategy及其子类为组件提供了一系列可重用的算法，从而可以使得类型在运行时方便地根据需要在各个算法之间进行切换 Strategy模式提供了用条件判断语句以外的另一种选择，消除条件判断语句，就是在解耦合。含有许多条件判断语句的代码通常都需要Strategy模式。 如果Strategy对象没有实例变量，那么各个上下文可以共享同一个Strategy对象，从而节省对象开销。","comments":true,"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://oldbuffalo.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"C++11的一些小知识点","date":"2019-04-26T11:19:52.000Z","path":"2019/04/C-11的一些小知识点/","text":"模板中的空格(C++ Primer p87)在之前的C++版本中，如果在容器中装的是又是一个容器，比如 1vector&lt;list&lt;int&gt; &gt; &#x2F;&#x2F;最后两个&gt;之间的空格不能省略 这是因为如果没有这个空格，编译器会认为这是一个&gt;&gt;操作符，编译会出错。 在C++11之后， 1vector&lt;list&lt;int&gt;&gt; &#x2F;&#x2F;这样写就可以了 nullptr and std::nullptr_t(C++ Primer p48)123int* p1 &#x3D; nullptr; &#x2F;&#x2F;等价于int* p1 &#x3D; 0;int* p2 &#x3D; 0; &#x2F;&#x2F;直接将p2初始化为字面常量0int* p3 &#x3D; NULL; &#x2F;&#x2F;需要#include&lt;cstdlib&gt; 等价于int* p3 &#x3D; 0; 123456void f(int);void f(void*);f(0); &#x2F;&#x2F;掉用f(int)f(NULL); &#x2F;&#x2F;掉用f(int)f(nullptr); &#x2F;&#x2F;调用f(void*) nullptr的类型是std::nullptr_t，定义在 12345&#x2F;&#x2F;4.92\\include\\stddef.h#if defined(__cplusplus) &amp;&amp; __cplusplus &gt;&#x3D; 201103L#ifndef _GXX_NULLPTR_T#define _GXX_NULLPTR_Ttypedef decltype(nullptr) nullptr_t; auto(C++ Primer p61)之前讲auto是指，一个函数的local变量类型是auto的，因为一个函数的局部变量，在函数结束的时候自动释放。 而在C++11中，auto能让编译器替我们去分析表达式所属的类型。 一般用于类型很长或者类型很复杂，一时想不起来的时候。 123456789101112131415auto i &#x3D; 42; &#x2F;&#x2F;i----------&gt;intdouble f();auto d &#x3D; f(); &#x2F;&#x2F;d-----------&gt;doublevector&lt;string&gt; v;auto pos &#x3D; v.begin(); &#x2F;&#x2F;pos-----&gt;vector&lt;string&gt;::iteratorauto I &#x3D; [](int x)-&gt;bool&#123; &#x2F;&#x2F;I是lambda类型 ..., &#x2F;&#x2F;传入int 返回bool&#125;;&#x2F;&#x2F;使用auto变量能在一条语句中声明多个变量&#x2F;&#x2F;因为一条声明语句只能有一个基本数据类型&#x2F;&#x2F;所以该语句中所有变量的初始基本数据类型都必须一样auto i &#x3D; 0,*p &#x3D; &amp;i; &#x2F;&#x2F;i是整数 p是整型指针 正确auto sz &#x3D; 0,pi &#x3D; 3.14; &#x2F;&#x2F;错误，sz和pi类型不一致 Uniform Initialization(C++ Primer p129)之前的初始化手法： 123Rect r1 &#x3D; &#123;3,7,20,25,&amp;area,&amp;print&#125;;Rect r2(3,7,20,25);int ia[6] &#x3D; &#123;1,2,3,4,5,6&#125;; C++11介绍了一致化初始化方式，就是提供一样的初始化方法，知道就行，具体采用哪种初始化方式根据习惯就好。 123int values[] &#123;1,2,3&#125;; &#x2F;&#x2F;注意和以前的区别 少去了&#x3D;vector&lt;int&gt; v&#123;2,3,4&#125;;complex&lt;double&gt; c&#123;4.0,3.0&#125;; &#x2F;&#x2F;等价于c(4.0,3.0) 原理就是：编译器看到{t1,t2,…,tn}就会做出一个initializer_list,它关联到一个array&lt;T,n&gt;,调用函数(例如ctor)时该array内的元素可以被编译器逐一分解传给函数。但是如果构造函数有一个版本的参数接受initializer_list，那么就整体传入。 Initializer Lists(C++ Primer p197)12345678910111213int i; &#x2F;&#x2F;i未定义的值int j&#123;&#125;; &#x2F;&#x2F;j &#x3D; 0;int *p; &#x2F;&#x2F;p未定义的指针int *q&#123;&#125;; &#x2F;&#x2F;q &#x3D; nullptrint x1(5.3); &#x2F;&#x2F;OK x1 &#x3D; 5 warningint x2 &#x3D; 5.3; &#x2F;&#x2F;OK x2 &#x3D; 5 warning&#x2F;&#x2F;不允许的窄化转换int x3&#123;5.3&#125;; &#x2F;&#x2F;errorint x4 &#x3D; &#123;5.3&#125;; &#x2F;&#x2F;errorchar c2&#123;99999&#125;; &#x2F;&#x2F;errorvector&lt;int&gt; v&#123;1,2.5,3,4.8&#125;; &#x2F;&#x2F;error {}背后的原理:类模板std::initializer_list&lt;&gt; 在C++11中，如果要编写处理不同数量的实参的函数的时候，有两种办法 如果所有实参类型相同，可以传递一个initializer_list的标准库类型 如果实参类型不同，可以用可变参数模板编写 第一点就是现在在介绍的东西。 1234567void print(initializer_list&lt;int&gt; vals)&#123; for(auto p &#x3D; vals.begin();p !&#x3D; vals.end();p++)&#123; cout&lt;&lt;*p&lt;&lt;endl; &#125;&#125;print(&#123;12,3,5,7,11,13&#125;); 下图很好的展示了initializer_list构造的调用： 实质上当{}出现，编译器就生成一个initializer_list对象，这个模板类需要一个array容器作为支持。 在STL源码中，initializer_list被大量运用在容器的初始化，赋值，插入等操作上，因为这些情况下大多操作不定数量的相同类型的数据。在算法中，比如min，max,之前只之前两个元素，有了initializer_list就能获取不定数量的列表中的最大值和最小值 12345678910111213vector&lt;int&gt; v1&#123;1,2,3&#125;;vector&lt;int&gt; v2(&#123;4,5,6&#125;);vector&lt;int&gt; v3;v3 &#x3D; &#123;7,8,9&#125;;v3.insert(v3.begin()+2,&#123;10,11&#125;);for(auto i: v3) cout&lt;&lt;i&lt;&lt;&quot; &quot;;cout&lt;&lt;endl; &#x2F;&#x2F; 7 8 10 11 9cout&lt;&lt;max(&#123;string(&quot;abc&quot;),string(&quot;xyz&quot;),string(&quot;qrt&quot;)&#125;)&lt;&lt;endl; &#x2F;&#x2F;xyzcout&lt;&lt;min(&#123;string(&quot;abc&quot;),string(&quot;xyz&quot;),string(&quot;qrt&quot;)&#125;)&lt;&lt;endl; &#x2F;&#x2F;abccout&lt;&lt;max(&#123;1,5,7,8,9&#125;)&lt;&lt;endl; &#x2F;&#x2F;9cout&lt;&lt;min(&#123;1,5,7,8,9&#125;)&lt;&lt;endl; &#x2F;&#x2F;1 explicit(C++ Primer p516)这个关键字主要用在构造函数之上，主要为了防止隐式类型转换，一般发生在一个对象和另一个类型的变量做某种操作的时候。 C++11之前，只有non-explicit one-argument 构造函数才能进行隐式类型转换，在C++11之后，多个实参的构造函数也提供explicit 参考博文 范围for(C++ Primer p168)用法: 123456vector&lt;double&gt; vec;...for(auto elem : vec) cout&lt;&lt;elem &lt;&lt; endl;for(auto &amp;elem : vec) elem *&#x3D; 3; 需要注意的是：如果要改变容器中的值，必须加引用 原理,借助了迭代器 12345678910111213141516for(decl : coll)&#123; statement&#125;&#x2F;&#x2F;编译器转换成for(auto _pos&#x3D;coll.begin(),_end&#x3D;coll.end();_pos!&#x3D;_end;_pos++）&#123; decl &#x3D; *_pos; statement&#125;&#x2F;*------------------------------------------*&#x2F;for(const auto &amp;elem : coll) cout&lt;&lt;elem&lt;&lt;endl;&#x2F;&#x2F;编译器转换成for(auto _pos&#x3D;coll.begin();_pos!&#x3D;coll.end();_pos++)&#123; const auto &amp;elem &#x3D; *_pos; cout&lt;&lt;elem&lt;&lt;endl;&#125; Alias Templatealias declaration(C++ Primer p60) 1234567891011template&lt;typename T&gt;using Vec &#x3D; vector&lt;T, allocator&lt;T&gt;&gt;;Vec&lt;int&gt; v; &#x2F;&#x2F;等价于vector&lt;int, allocator&lt;int&gt;&gt; v&#x2F;*------------不能用宏---------------------*&#x2F;#define Vec&lt;T&gt; template&lt;typename T&gt; vector&lt;T,allocator&lt;T&gt;&gt;&#x2F;&#x2F;这样会变成Vec&lt;int&gt; v; &#x2F;&#x2F;----&gt;template&lt;typename int&gt; vector&lt;int,allocator&lt;int&gt;&gt; v;&#x2F;*-------------不能用typedef----------------*&#x2F;typedef vector&lt;int,allocator&lt;int&gt;&gt; Vec;Vec v;&#x2F;&#x2F;Vec不能带参数了 只能是int 注意点：模板化名不能做特化(偏或者全)","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"},{"name":"C++11","slug":"C-11","permalink":"https://oldbuffalo.github.io/tags/C-11/"}]},{"title":"模板方法","date":"2019-04-26T09:59:10.000Z","path":"2019/04/模板方法/","text":"“组件协作”模式现代软件专业分工之后的第一个结果就是“框架和应用程序的划分”，“组件协作”模式通过晚绑定，实现框架和应用程序之间的松耦合，是两者之间协作时常用的模式。 典型模式有： Template Method Strategy Observer Template Method模式定义： 定义一个操作中的算法的骨架(稳定)，而将一些步骤延迟(变化)到子类中。Template Method使得子类可以不改变(复用)一个算法的结构即可重定义(重写)该算法的某些特定步骤。 应用场景： 在软件构建过程中，对于某一项任务，它常常有稳定的整体结构，但各个子步骤却有很多改变的需求(某一特定的业务逻辑在不同的对象中有不同的细节实现)。 实例演示： 没有应用设计模式的做法 1234567891011121314151617181920212223242526272829303132333435363738class Library&#123; &#x2F;&#x2F;程序库开发人员public: void step1()&#123; &#x2F;&#x2F;... &#125; void step3()&#123; &#x2F;&#x2F;... &#125; void step5()&#123; &#x2F;&#x2F;... &#125;&#125;;class Application&#123; &#x2F;&#x2F;应用程序开发人员public: bool step2()&#123; &#x2F;&#x2F;... &#125; void step4()&#123; &#x2F;&#x2F;... &#125;&#125;;int main()&#123; Library lib; Application app; &#x2F;&#x2F;整体框架 流程 lib.step1(); if(app.step2()) lib.step3(); for(int i &#x3D; 0;i&lt;4;i++) app.step4(); lib.step5(); return 0;&#125; 应用模板方法的做法 12345678910111213141516171819202122232425262728293031323334353637383940414243class Library&#123; &#x2F;&#x2F;程序库开发人员public: void Run()&#123; &#x2F;&#x2F;稳定 template method step1(); if(step2()) &#x2F;&#x2F;支持变化&#x3D;&#x3D;&gt;虚函数的多态调用 step3(); for(int i &#x3D; 0;i&lt;4;i++) step4(); &#x2F;&#x2F;支持变化&#x3D;&#x3D;&gt;虚函数的多态调用 step5(); &#125; virtual ~Library()&#123;&#125;protected: void step1()&#123;&#x2F;&#x2F;稳定 &#x2F;&#x2F;... &#125; void step3()&#123;&#x2F;&#x2F;稳定 &#x2F;&#x2F;... &#125; void step5()&#123;&#x2F;&#x2F;稳定 &#x2F;&#x2F;... &#125; virtual bool step2() &#x3D; 0; &#x2F;&#x2F;变化 virtual void step4() &#x3D; 0; &#x2F;&#x2F;变化&#125;;class Application:public Library&#123; &#x2F;&#x2F;应用程序开发人员public: virtual bool step2()&#123; &#x2F;&#x2F;...子类重写实现 &#125; virtual void step4()&#123; &#x2F;&#x2F;...子类重写实现 &#125;&#125;;int main()&#123; Library* plib &#x3D; new Application; plib-&gt;Run(); delete plib; return 0;&#125; 对于做法一的流程(结构化设计流程)： 对于做法二的流程： 本质的变化： 对于Library来说，肯定是早出现的，而Application出现的晚，对于一个早的东西调用一个晚的东西就是晚绑定。 模式类图 这里的TemplateMethod就是上面的Run PrimitiveOperation1就是step2 PrimitiveOperation2就是step4 省略了step1,step3,step5 模式总结 用最简洁的机制(虚函数的多态性)为很多应用程序框架提供了灵活的扩展点，是代码复用方面的基本实现结构 除了可以灵活应对子步骤的变化外，”不要调用我，让我来调用你”的反向控制结构是Template Method的典型应用 在具体实现方面，被Template Method调用的虚方法可以具有实现，也可以没有任何实现，但一般推荐将它们设置为protected方法","comments":true,"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://oldbuffalo.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"STL六大部件","date":"2019-04-25T12:37:20.000Z","path":"2019/04/STL六大部件/","text":"C++中很重要的一个库就是STL(Standard Template Library),叫做标准模板库，是C++标准库的一部分。 六大组件 容器(Containers) 分配器(Allocator) 算法(Algorithms) 迭代器(Iterators) 适配器(Adapters) 仿函数(Functors) 容器的作用是存储数据，数据需要占用内存，但是不需要我们管理内存，所以背后需要有分配器去支持容器。 有一些操作是在容器本身做的，但是更多的操作被独立出来写成一个一个模板函数，封装在算法模块中。 这里有一个观念需要注意：在面向对象编程中，我们希望数据和对数据的操作封装在一个类中，而STL将数据存储在容器中，对数据的操作写在算法中，做到了数据结构和算法的分离，这是模板编程的思想(generic programming)。 迭代器是容器和算法之间的桥梁，迭代器就像是一种泛化的指针。 仿函数作用像是一种函数 适配器，adapter在英文中就是变压器，变压器做的就是电压的转换工作。因此适配器做的也是转换工作。 实例程序： 1234567891011121314151617181920#include&lt;vector&gt;#include&lt;algorithm&gt;#include&lt;functional&gt;#include&lt;iostream&gt;using namespace std;int main()&#123; int ia[6] &#x3D; &#123; 27,210,12,47,109,40 &#125;; vector&lt;int, allocator&lt;int&gt;&gt; iv(ia, ia + 6); &#x2F;&#x2F;allocator可以不写，底层默认有分配器 cout &lt;&lt; count_if(iv.begin(), iv.end(), not1(bind2nd(less&lt;int&gt;(), 40))); &#x2F;&#x2F;count_if 满足条件的元素的数量 &#x2F;&#x2F;less&lt;int&gt;() 仿函数 比较两个元素 但是现在是和40比较 因此用bind2nd固定第二个参数 &#x2F;&#x2F;bind2nd是一个仿函数适配器，bind2nd(less&lt;int&gt;(), 40)表示小于40 &#x2F;&#x2F;not1也是仿函数适配器，表示对条件取反，也就是编程大于等于40 &#x2F;&#x2F;最终输出的是数组中大于等于40的元素个数 也就是4 return 0;&#125; 遍历容器的方法： 1234567891011121314151617181920212223242526Container&lt;T&gt; c; &#x2F;&#x2F;这里Container只是泛指，没有具体指哪个容器...Container&lt;T&gt;::iterator ite &#x3D; c.begin();for(;ite !&#x3D; c.end();ite++) ... list&lt;string&gt; l;...list&lt;string&gt;::iterator ite;ite &#x3D; ::find(l.begin(),l.end(),target);&#x2F;&#x2F;C++11之后的简便写法 range-based for的应用以及auto关键字for(int i : &#123;2,3,4,7,9&#125;) cout&lt;&lt;i&lt;&lt;endl;vector&lt;double&gt; vec;...for(auto elem : vec) cout&lt;&lt;elem&lt;&lt;endl;for(auto &amp;elem : vec) elem *&#x3D; 3; list&lt;string&gt; l;...auto ite &#x3D; ::find(l.begin(),l.end(),target);","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"},{"name":"STL","slug":"STL","permalink":"https://oldbuffalo.github.io/tags/STL/"}]},{"title":"Variadic Templates","date":"2019-04-25T06:22:25.000Z","path":"2019/04/Variadic-Templates/","text":"记录一下可变模板参数的使用方法。(C++ Primer p619) 用一个省略号来指出一个模板参数或函数参数表示一个包。在一个模板参数列表中，class…或typename…指出接下来的参数表示零个或者多个类型的列表。 先来看一个例子 12345678910111213141516void print()&#123;&#125;template &lt;typename T,typename...Types&gt;void print(const T&amp; firstArg,const Types&amp;...args)&#123; cout&lt;&lt;firstArg&lt;&lt;endl; print(args...); &#x2F;&#x2F;recursive&#125;int main()&#123; print(7.5, &quot;hello&quot;, bitset&lt;16&gt;(100), 42); &#125;&#x2F;&#x2F;最终输出7.5hello000000000110010042 …叫做一个所谓的pack(包) Types是模板参数包，args是函数参数包，都表示零个或多个参数 注意点： 三次…的位置的区别，语法规范 第一行单写的一个print是递归终止的条件，很关键。对于主函数中调用的print，传入的参数是4个，对于可变模板方法而言是1个和其他，就把第一个输出，把其他三个传入print，再把第一个输出，把其他两个传入print，再把第一个输出，其他一个传入print，再把第一个输出，其他零个传入print，这时候就调用第一行的print。 进一步思考： 1234template &lt;typename...Types&gt;void print(const Types&amp;...args)&#123; &#x2F;&#x2F;...&#125; 这个可变参数模板函数能和上面的共存吗？ 按照正常的理解，假如传入print的参数个数是5个，既可以被看成1个和4个，也可以被看成5个，这会造成歧义。但实际上编译时可以通过的。 经过测试，调用的是1个和其他个的版本，至于原因，以后补上。 通过sizeof…运算符可以知道包中元素的个数。 12345template &lt;typename...Types&gt;void print(const Types&amp;...args)&#123; cout&lt;&lt;sizeof...(Types)&lt;&lt;endl; cout&lt;&lt;sizeof...(args)&lt;&lt;endl;&#125;","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"},{"name":"C++11","slug":"C-11","permalink":"https://oldbuffalo.github.io/tags/C-11/"}]},{"title":"八大设计原则","date":"2019-04-24T12:27:23.000Z","path":"2019/04/八大设计原则/","text":"最近在看李建忠老师的设计模式的课程，做一下学习笔记,可以参考书籍《设计模式:可复用面向对象软件的基础》,这本书是四个人写的，所以也简称GOF设计模式。 解决复杂问题主要的方式有两种： 分解,分而治之。像C语言这种结构化的语言就是如此 抽象。由于不能掌握全部的复杂对象，选择忽视它的非本质细节，而去锤泛化和理想化的对象模型 在设计模式中和重要的一个东西就是抽象。 结构化VS面向对象演示的任务：画图形 分解的设计方法,以伪码的方式展示： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192&#x2F;&#x2F;shape.h 封装一些特定的形状class Point&#123;public: int x; int y;&#125;;class Line&#123;public: Point start; Point end; Line(const Point&amp;start,const Point&amp;end)&#123; this-&gt;start &#x3D; start; this-&gt;end &#x3D; end; &#125;&#125;;class Rect&#123;public: Point leftUp; int width; int height; Rect(const Point&amp; leftUp,int width,int height)&#123; this-&gt;leftUp &#x3D; leftUp; this-&gt;width &#x3D; width; this-&gt;height &#x3D; height; &#125;&#125;;------------------------------------------------------------&#x2F;&#x2F;MainForm.h 窗口类 负责处理各种事件 #include&quot;shape.h&quot;class MainForm : public Form&#123;private: Point p1; Point p2; &#x2F;&#x2F;鼠标画图的起始点和终止点 vector&lt;Line&gt; linevector; vector&lt;Rect&gt; rectVector;public: MainForm()&#123; &#x2F;&#x2F;... &#125;protected: virtual void OnMouseDown(const MouseEventArgs&amp; e); virtual void OnMouseUp(const MouseEventArgs&amp; e); virtual void OnPaint(const MouseEventArgs&amp; e);&#125;;void MainForm::OnMouseDown(const MouseEventArgs&amp; e)&#123; p1.x &#x3D; e.x; p1.y &#x3D; e.y; &#x2F;&#x2F;... Form::OnMouseDown(e);&#125;void MainForm::OnMouseUp(const MouseEventArgs&amp; e)&#123; p2.x &#x3D; e.x; p2.y &#x3D; e.y; if(rdoLine.Checked)&#123; Line line(p1,p2); lineVector.push_back(line); &#125; else if(rdoRect.Checked)&#123; int width &#x3D; abs(p2.x-p1.x); int height &#x3D; abs(p2.y-p1.y); Rect rect(p1,width,height); rectVector.push_back(rect); &#125; &#x2F;&#x2F;... this-&gt;Refresh(); Form::OnMouseUp(e);&#125;void MainForm::OnPaint(const MouseEventArgs&amp; e)&#123; &#x2F;&#x2F;针对直线 for(int i &#x3D; 0;i&lt;lineVector.size();i++)&#123; e.Graphics.DrawLine(Pens.Red, lineVector[i].start.x, lineVector[i].start.y, lineVector[i].end.x, lineVector[i].end.y); &#125; &#x2F;&#x2F;针对矩形 for(int i &#x3D; 0;i&lt;rectVector.size();i++)&#123; e.Graphics.DrawRectangle(Pens.Res, rectVector[i],leftUp, rectVector[i].width, rectVector[i].height); &#125; &#x2F;&#x2F;... Form::OnPaint(e);&#125; 抽象的设计方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788&#x2F;&#x2F;shape.h &#x2F;&#x2F;抽象出一个Shape的基类，让具体的形状类继承它class Shape&#123; &#x2F;&#x2F;抽象类public: virtual void Draw(const Graphics&amp; g) &#x3D; 0; virtual ~Shape()&#123;&#125;&#125;class Point&#123;public: int x; int y;&#125;class Line:public Shape&#123;public: Point start; Point end; &#x2F;&#x2F;Line的构造函数 同上 &#x2F;&#x2F;实现自己的Draw,负责画自己 virtual void Draw(const Graphics&amp; g)&#123; g.DrawLine(Pens.Red,start.x,start.y,end.x,end.y); &#125;&#125;;class Rect&#123;public: Point leftUp; int width; int height; &#x2F;&#x2F;Rect的构造函数 同上 &#x2F;&#x2F;实现自己的Draw,负责画自己 virtual void Draw(const Graphics&amp; g)&#123; g.DrawLine(Pens.Red,leftUp，width,height); &#125;&#125;;-----------------------------------------------------------------#include&quot;shape.h&quot;class MainForm : public Form&#123;private: Point p1; Point p2; &#x2F;&#x2F;鼠标画图的起始点和终止点 &#x2F;&#x2F;针对所有形状 vector&lt;Shape*&gt; shapeVector; 存储的是指针 因为需要多态性public: MainForm()&#123; &#x2F;&#x2F;... &#125;protected: virtual void OnMouseDown(const MouseEventArgs&amp; e); virtual void OnMouseUp(const MouseEventArgs&amp; e); virtual void OnPaint(const MouseEventArgs&amp; e);&#125;;void MainForm::OnMouseDown(const MouseEventArgs&amp; e)&#123; p1.x &#x3D; e.x; p1.y &#x3D; e.y; &#x2F;&#x2F;... Form::OnMouseDown(e);&#125;void MainForm::OnMouseUp(const MouseEventArgs&amp; e)&#123; p2.x &#x3D; e.x; p2.y &#x3D; e.y; if(rdoLine.Checked)&#123; &#x2F;&#x2F;需要注意的是 因为容器里放的是指针 因此不能放一个栈对象 lineVector.push_back(new Line(p1,p2)); &#125; else if(rdoRect.Checked)&#123; int width &#x3D; abs(p2.x-p1.x); int height &#x3D; abs(p2.y-p1.y); rectVector.push_back(new Rect(p1,width,height)); &#125; &#x2F;&#x2F;... this-&gt;Refresh(); Form::OnMouseUp(e);&#125;void MainForm::OnPaint(const MouseEventArgs&amp; e)&#123; &#x2F;&#x2F;统一处理所有的形状 for(int i &#x3D; 0;i&lt;shapeVector.size();i++)&#123; shapeVector[i]-&gt;Draw(e.Graphics); &#x2F;&#x2F;多态调用，各负其责 &#125; &#x2F;&#x2F;... Form::OnPaint(e);&#125; 通过加入一个新的需求来对比一下两种设计方法。 比如要新加一个画图的功能。 对于分解的方法： 在shape文件中新添一个Circle类 然后在MainForm里面加入一个vector存储所有的Circle对象，然后在OnMouseUp中添加一个加入Circle对象的判断，最后在OnPaint中加入一个循环遍历画出所有的Circle对象。 对于抽象的方法： 在shape文件中新添一个Circle类，继承Shape类，实现自己的Draw方法 在MainForm，在OnMouseUp中添加一个加入Circle对象指针的判断(可以用工厂设计模式消除这种变化)。 可以看见，对于一个新的需求的加入，抽象的方法改动的代码远远少于分解的方法，也就是扩展性、复用性的体现。 面向对象设计原则变化是复用的天敌。面向对象设计最大的优势在于：抵御变化！ 设计原则比模式更为重要，先码下来后面结合具体的设计模式再好好理解。 依赖倒置原则（DIP） 高层模块(稳定)不应该依赖于底层模块(变化)，二者都应该依赖于抽象(稳定) 抽象(稳定)不应该依赖于实现细节(变化)，实现细节应该依赖于抽象 对于上面的例子，第一种做法MainForm依赖于Line和Rect，MainForm就相当于高层模块，Line和Rect相当于低层模块。第二种做法MainForm依赖于Shape，Line和Rect也依赖Shape，这里的Shape就是抽象，从而实现隔离变化，这就符合了依赖倒置原则，简而言之，就是稳定的不能依赖不稳定的，要让不稳定的依赖稳定的。 开放封闭原则（OCP） 对扩展开放，对更改封闭 类模块应该是可扩展的，但是不可修改。 对于上面的例子，加入一个新的需求的时候，第一种做法改变源码的地方很多。在工程中，改变源码意味着需要重新编译，重新测试，重新部署，代价很高。第二种做法所做的变动很小，扩展性更好。 单一职责原则（SRP） 一个类应该仅有一个引起它变化的原因 变化的方向隐含着类的责任 Liskov替换原则（LSP） 子类必须能够替换它们的基类(IS-A) 继承表达类型抽象 接口隔离原则（ISP） 不应该强迫客户程序依赖它们不用的方法 接口应该小而完备(不要把不必要的方法public) 优先使用对象组合，而不是类继承 类继承通常为“白箱复用”，对象组合通常为“黑箱复用” 继承在某种程度上破坏了封装性，子类父类耦合度高 而对象组合则只要求被组合的对象具有良好定义的接口，耦合度低 封装变化点(封装更高层次的理解) 使用封装来创建对象之间的分界层，让设计者可以在分界层的一侧进行修改，而不会对另一侧产生不良的影响，从而实现层次间的松耦合。 针对接口编程，而不是针对实现编程 不将变量类型声明为某个特定的具体类，而是声明为某个接口 客户程序无需获知对象的具体类型，只需要知道对象所具有的接口 减少系统中各部分的依赖关系，从而实现“高内聚、松耦合”的类型设计方案 在之前的例子中，第一种做法MainForm里面包含Line，Rect的数组，这就是依赖了具体类，不符合针对接口编程。第二种做法就是包含Shape指针的数组，就是接口，然后只使用对象所具有的接口。 总结设计模式的学习一个漫长的过程，在不同的场景分析其特点准备运用设计模式是一个很困难的事情。在实际情况中，一般可以先满足需求，然后比对设计原则，分析代码的劣势，运用某些设计模式重构代码。 软件设计的特征是“需求的频繁变化”，设计模式的要点就是寻找变化点，然后在变化点运用设计模式。 重构的关键技法 静态转动态 早绑定转晚绑定 继承转组合 编译时依赖转运行时依赖 紧耦合转松耦合","comments":true,"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://oldbuffalo.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"禁止拷贝构造和赋值","date":"2019-04-23T12:23:02.000Z","path":"2019/04/禁止拷贝构造和赋值/","text":"在某些特定的场合，对于某些类我们不希望类对象产生副本，也就是不能调用拷贝构造和赋值运算符。 例如，iostream类阻止了拷贝，以避免多个对象写入或读取相同的IO缓冲。 在研究muduo库Mutex文件的发现继承了一个noncopyable类，就能达成上面的作用。 查了一下，发现这是《Effective C++》中的条款6：若不想使用编译器自动生成的函数，就该明确拒绝。 首先我们需要知道，如果定义一个空类，编译器会自动帮我们声明： default无参构造函数 析构函数 拷贝构造函数 赋值操作符重载函数 并且这些函数都是public且inline的，只有当这些函数被调用的时候，它们才被编译器创建出来。 因此，如果不在类中定义拷贝构造函数和赋值运算符，我们尝试调用它们的时候，编译器会帮我们声明，不能达到我们想要的目的。 把要禁止的函数声明为private问题的关键是，编译器声明的函数都是public的，要阻止这些函数被创建，需要自行声明它们为private。但是这种做法不是绝对安全，因为类成员函数和友元函数还是可以调用private函数，因此可以不去实现它们。 小技巧：把要禁止的函数声明为private，并且故意不去实现它们。当别处调用这个函数的时候，就会得到一个链接期的错误(无法解析的外部符号XXXX)。 1234567class Test&#123;private: Test(const Test&amp;); Test&amp; operater&#x3D;(const Test&amp;); &#x2F;&#x2F;只有声明public: ...&#125;; 专门声明一个阻止拷贝动作的类这样做的好处在于将连接期的错误移至编译期，因为越早侦测出错误越好。 123456789101112class Uncopyable&#123;protected: Uncopyable()&#123;&#125; &#x2F;&#x2F;允许derived对象构造和析构 ~Uncopyable()&#123;&#125;private: Uncopyable(const Uncopyable&amp;); &#x2F;&#x2F;但是阻止copying Uncopyable&amp; operator&#x3D;(const Uncopyable&amp;);&#125;;class Test:private Uncopyable&#123; &#x2F;&#x2F;private不加 默认private ...&#125; 无论是类外部、类成员函数还是友元函数进行对象拷贝操作，编译期都会试着生成一个拷贝构造函数和一个赋值操作符，但是由于继承，这两个函数会尝试调用其基类的对应兄弟，可是基类中这两个函数是private，因此调用会被编译期拒绝。 C++11的做法(C++ Primer p449)1234567891011class noncopyable&#123;protected: noncopyable() &#x3D; default; &#x2F;&#x2F;允许derived对象构造和析构 ~noncopyable() &#x3D; default;public: noncopyable(const Uncopyable&amp;) &#x3D; delete; &#x2F;&#x2F;但是阻止copying noncopyable&amp; operator&#x3D;(const Uncopyable&amp;) &#x3D; delete;&#125;;class Test:private noncopyable&#123; &#x2F;&#x2F;private不加 默认private ...&#125;","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"},{"name":"Effective C++","slug":"Effective-C","permalink":"https://oldbuffalo.github.io/tags/Effective-C/"}]},{"title":"gdb调试","date":"2019-04-20T07:50:10.000Z","path":"2019/04/gdb调试/","text":"gdb是一个文件界面的调试工具，但是功能很强大。 通过实战来熟悉一下常用操作。 首先需要注意的是如果要用gdb调试，在编译的时候需要加上-g选项 调试最基础的swap程序gdb调试多进程程序 单独调试子进程(attach) 调试用例程序：进程池实现的CGI服务器 首先启动服务器 然后输入gdb启动gdb调试器，然后输入attach 子进程pid 一开始attach失败了 根据错误信息的提示然后查阅资料，得知是内核参数/proc/sys/kernel/yama/ptrace_scope的原因 要设置成0，才能attach成功。 因此，采用临时修改的方式 1echo 0 | sudo tee &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;yama&#x2F;ptrace_scope 当然也可以在/etc/sysctl.d/10-ptrace.conf中修改从而永久有效 1kernel.yama.ptrace_scope &#x3D; 0 下一步设置断点 接下来在另一个终端使用telnet 127.0.0.1 12345来连接服务器并发送一些数据，调试器就在断点处暂停了，并且使用bt查看堆栈调用。 使用调试器选项follow-fork-mode gdb调试器的选项follow-fork-mode允许我们选择程序执行fork系统调用后是继续调试父进程还是调试子进程。 1set follow-fork-mode mode(parent&#x2F;child) 还是使用上面的CGI程序进行调试，但是不同的是启动gdb调试的时候需要 gdb +程序文件名 接下来在另一个终端使用telnet 127.0.0.1 12345来连接服务器并发送一些数据，调试器就在断点处暂停了，并且使用bt查看堆栈调用。 gdb调试多线程程序gdb有一组命令可辅助多线程程序的调试 info threads,显示当前可调试的所有线程.gdb会为每个线程分配一个ID，可以使用这个ID来操作对应的线程。ID前面有”*”号的线程是当前被调试的线程 thread ID,调试目标ID指定的线程 set scheduler-locking[off|on|step]。调试多线程程序时，默认除了被调试的线程在执行外，其他线程也继续执行。但有的时候我们希望只让被调试的线程运行，这可以通过这个命令实现。 off表示不锁定任何线程，即所有线程都可以继续执行，这是默认值 on表示只有当前被调试的线程会继续执行 step表示在单步执行的时候，只有当前线程会执行 调试用例程序：多线程Web服务器 分别设置父线程中的断点和子线程中的断点，然后启动程序 然后在另一个终端使用telnet 127.0.0.1 12345来连接服务器并发送一些数据，调试器就在预期的断点处暂停了。并且查看线程信息，发现当前被调试的是主线程，ID是1 紧接着设置scheduler-locking值为on，让其他线程不执行，锁定调试对象，然后逐步执行,最终重新阻塞在epoll_wait上，然后按crtl+C结束主线程 然后切换到子线程进行调试，其ID为2 这里用到了一个技巧，就是先将线程池创建的线程个数减少到1，来观察程序的逻辑是否正确，然后再逐步增加线程的数量进行调试。","comments":true,"tags":[{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"常用工具","slug":"常用工具","permalink":"https://oldbuffalo.github.io/tags/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"lsof","date":"2019-04-20T04:14:43.000Z","path":"2019/04/lsof/","text":"lsof(list open file)是一个列出当前系统打开的文件描述符的工具。通过它可以了解感兴趣的进程打开了哪些文件描述符，或者感兴趣的文件描述符被哪些进程打开。 常用选项： -i，显示scoket文件描述符 使用方法： 1lsof -i [46] [protocol] [@hostname|ipaddr][:service|port] 其中4表示IPv4协议，6表示IPv6协议，protocol指定传输层协议，可以是TCP或者UDP，hostname指定主机名，ipaddr指定主机的IP地址，service指定服务名，port指定端口号。|代表两个填一个就行 例如，要显示所有连接到主机192.168.1.108的ssh服务的socket文件描述符 1losf -i@192.168.1.108:22 -u，显示指定用户启动的所有进程打开的所有文件描述符 -c，显示指定的命令打开的所有文件描述符， 比如要查看websrv程序打开了哪些文件描述符，可以使用如下命令: lsof -c websrc -p，显示指定的进程打开的所有文件描述符 -t，仅显示打开了目标文件描述符的进程的pid 还可以直接将文件名作为lsof命令的参数，以查看哪些进程打开了该文件。 lsof命令的输出内容：","comments":true,"tags":[{"name":"常用工具","slug":"常用工具","permalink":"https://oldbuffalo.github.io/tags/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"服务器内核参数配置","date":"2019-04-20T03:59:58.000Z","path":"2019/04/服务器内核参数配置/","text":"Linux平台一个优秀的特性就是内核微调，即可以通过修改文件的方式来调整内核参数。记录一些与服务器性能相关的部分内核参数。 几乎所有的内核模块，包括内核核心模块和驱动程序,都在/proc/sys文件系统中提供了某些配置文件以供用户调整模块的属性和行为。通常一个配置文件对应一个内核参数，文件名就是参数的名字，文件的内容就是参数的值。 可以通过 sysctl -a来查看所有的内核参数。 最大文件描述符数Linux对应用程序能打开的最大文件描述符数量有两个层次的限制：用户级限制和系统级限制。 用户级限制是指目标用户运行的所有进程总共能打开的文件描述符数 系统级限制是指所有用户总共能打开的文件描述符数 ulimit -n 是常用的查看用户级文件描述符限制的方法 默认一般为1024 ulimit -SHn max-file-number(自己设定数值) 将用户级文件描述符限制设为max-file-number’ 加-H就是硬，加-S就是软，默认显示的是软限制 如果运行ulimit命令修改的时候没有加上这两个选项的话，就是两个参数一起改变。 但是上面的这种设置是临时的，只在当前的session有效 如果要永久修改用户级文件描述符数限制，可以在/etc/security/limits.conf文件加入两项，然后重启生效： 12* soft nofile max-file-number(自己设置数值 32768)* hard nofile max-file-number(自己设置数值 65536) 配置文件最前面的是指domain，设置为星号代表全局，另外也可以针对不同的用户做出不同的限制。 注意：这个当中的硬限制是实际的限制，而软限制，是warning限制，只会做出warning 如果要修改系统级文件描述符限制，可以使用如下命令： sysctl -w fs.file-max=max-file-number(自己设置数值) 注意后面不能有空格，但是该命令也是临时更改系统限制 系统总限制是在这里,/proc/sys/fs/file-max,可以通过cat查看目前的值 如果要永久更改系统级文件描述符限制，则需要在/etc/sysctl.conf文件中添加如下一项： fs.file-max=max-file-number(自己设置数值) 然后通过执行sysctl -p命令使更改生效 /proc/sys/fs/file-nr，可以看到整个系统目前使用的文件句柄数量。 查找文件句柄问题的时候，还有一个很实用的程序lsof(list open file)。 可以很方便看到某个进程开了那些句柄，也可以看到某个文件/目录被什么进程占用了。 /proc/sys/fs目录下的部分文件/proc/sys/fs目录下的内核参数都与文件系统有关。对于服务器程序，比较重要的是 /proc/sys/fs/file-max，系统级文件描述符数限制，修改方式上面介绍过，一般修改/proc/sys/file-max后，应用程序需要把/proc/sys/fs/inode-max设置为新/proc/sys/fs/file-max值的3~4倍，否则可能导致i节点数不够 /proc/sys/fs/epoll/max_user_watches,一个用户能够往epoll内核事件表中注册的事件总量。它是指该用户打开的所有epoll实例总共能监听的事件数目，而不是单个epoll实例能监听的事件数目。往epoll内核事件表中注册一个事件，在32位系统上大概消耗90字节的内核空间，在64位系统上消耗160字节的内核空间。所以，这个内核参数限制了epoll使用的内核内存总量。(我的ubuntu16.04默认值为308299) /proc/sys/net目录下的部分文件内核中网络模块的相关参数都位于/proc/sys/net目录下，其中和TCP/IP协议相关的参数主要位于下面三个子目录：core、ipv4和ipv6。 /proc/sys/net/core/somaxconn。指定listen监听队列中，能够建立完整连接从而进入ESTABLISHED状态的socket最大数目。(我的ubuntu16.04默认值为128) /proc/sys/net/ipv4/tcp_max_syn_backlog。指定listen监听队列中，能够转移到ESTABLISHED状态或者SYN_RCVD状态的socket的最大数目，也就是处于半连接状态的socket的上限值。这是由于自Linux内核2.2之后，listen的backlog参数只表示处于完全连接状态的socket的上限 /proc/sys/net/ipv4/tcp_wmem,包含3个值，分别指定一个socket的TCP写缓冲区的最小值、默认值和最大值 (我的ubuntu16.04下为4096 16384 4194304) /proc/sys/net/ipv4/tcp_rmem,包含3个值，分别指定一个socket的TCP读缓冲区的最小值、默认值和最大值 可以修改这个参数来改变接收通告窗口的大小(我的ubuntu16.04下为4096 87380 6015840) /proc/sys/net/ipv4/tcp_syncookies,指定是否打开TCP同步标签(syncookie)，同步标签通过启动cookie来防止一个监听socket因为不停地接收来自同一个地址的连接请求(同步报文段)，而导致listen监听队列溢出(SYN flood) 除了通过直接修改文件的方式来修改这些系统参数外，也可以使用sysctl命令来修改它们。 但是上面这两种修改方式都是临时的，永久的修改方式是在/etc/sysctl,conf文件中加入相应网络参数及其数值 并执行sysctl -p使之生效。","comments":true,"tags":[{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"线程池","date":"2019-04-19T12:33:47.000Z","path":"2019/04/线程池/","text":"用线程池实现一个简易的Web服务器，代码链接 采用半同步/半反应堆并发模式，这种模式下主线程负责管理监听socket和连接socket，有新的连接，主线程建立连接，有新的事件发生，插入到请求队列，工作线程从队列中取出任务并执行。 首先，需要准备好一个线程池，采用模板类 模板的参数是http_coon类对象，这个类待会再介绍 线程池主要封装： 线程池的线程数量(固定，初始化的时候传入) 请求队列允许的最大请求数(也就是同一时刻队列中能同时存在的任务总数) 类型为pthread_t的指针，保存线程池中的线程 任务队列(这里用的是链表模拟) 保护任务队列的互斥锁 信号量(表示是否有任务需要处理，每来一个任务都释放一个信号量，每个线程都阻塞等待信号量) 线程结束标志 主要的方法就： 往队列中添加任务append 线程处理函数调用run() run()的工作是从队列中取出任务，并执行，执行用模板传入的对象调用自身的process方法 这里需要注意的是：线程处理函数作为类的成员函数需要声明为静态成员。 而线程处理函数拿到类的普通成员变量和函数的方法有： 1.通过类的静态对象来调用，比如单例模式 2.在创建线程的时候将类对象作为参数传给静态函数，比较常用， 而线程处理函数的工作就是从队列中取出任务并执行，但是每次需要类中的普通成员都要用对象的指针拿到比较麻烦，因此单独写一个类的普通成员函数run()来完成自己要做的工作，而自己只需要调用run(). main函数的工作： 进行一些网络的初始化工作，创建线程池，预先准备好http_conn数组，用连接socket作为数组的索引，代表所有可能的连接的连接信息。 然后使用epoll管理监听socket和所有的连接socket，采用非阻塞socket和ET工作模式。 对于连接socket，还设置EPOLLONESHOT选项 主线程监听到新的连接，接收并交给epoll管理，监听到可读事件，主线程读取数据，然后将任务投递到线程池(调用append方法，相当于将数据给线程去进行逻辑处理)，监听到可写事件，主线程负责将数据写回给客户端(HTTP响应的报文是由线程完成填写的，主线程只负责发送),监听到错误，关闭连接。 在进行逻辑处理的过程，用到一些技巧： 有限状态机，主线程每接收一段数据就交给线程池处理，也就是在一边接收请求报文，一边进行报文分析，相对于完整地接收整个HTTP请求报文再去进行分析，这样做节省了很多时间。 集中写writev，对于HTTP应答，可能有应答头部和消息体，而这两部分大概率内存不连续，一种常规的操作是准备一块足够大的缓冲区，将头部信息读入缓冲区，再将消息体也读入缓冲区，然后一起发送。但是，使用writev就可以将两块不连续的内存一次性发送出去，提升了效率。 通过实现一个可变参数的函数add_response简化了添加HTTP响应的代码 如果请求的是文件，经过一系统检验如果请求合法，使用mmap共享内存将文件映射到某块内存，提升了效率，避免了从硬盘读入内存的过程。 压力测试","comments":true,"tags":[{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"线程","slug":"线程","permalink":"https://oldbuffalo.github.io/tags/%E7%BA%BF%E7%A8%8B/"}]},{"title":"进程池","date":"2019-04-17T09:50:41.000Z","path":"2019/04/进程池/","text":"为什么需要池？多进程的网络模型为主进程负责accept，每来一个客户端就fork出一个子进程为之服务。这种动态创建子进程(子线程)来实现并发服务器有着诸多缺点。 动态创建进程(或线程)比较耗费时间，会导致较慢的客户响应 动态创建的子进程(或子线程)通常只用来为一个客户服务(除非做特殊的处理)，这将导致系统上产生大量的细微进程(线程)。进程(线程)切换将消耗大量CPU时间 动态创建的子进程是当前进程的完整映像。当前进程必须谨慎管理其分配的文件描述符和堆内存等系统资源，否则子进程可能复制这些资源，从而使得系统的可用资源急剧下降，影响服务器的性能。 进程池是由服务器预先创建一组子进程。进程池中的所有子进程都运行着相同的代码，并具有相同的属性，比如优先级、pgid等。因为进程池在服务器启动之前就创建好了，所以每个子进程相对干净，即它们没有打开不必要的文件描述符，也不会错误地使用大块的堆内存。 当有新的任务来的时候，主进程将通过某种方式选择进程池中某一个子进程来为之服务。 主进程使用某种算法来主动选择子进程。随机算法和Round Robin(轮流选取)算法。但更优秀、更智能的算法应该考虑负载的均衡 主进程和所有子进程通过一个共享的工作队列来同步，子进程都睡眠在该工作队列上。 选择好子进程之后，主进程还需要使用某种通知机制告诉目标子进程有新任务需要处理，并传递必要的数据。最简单的方法是通过管道。 半同步/半异步进程池实现 半同步/半异步模型是主进程负责管理所有监听socket，而各个子进程分别管理属于自己的连接socket。 代码主要逻辑分析： main函数负责进行网络的一些初始化工作，已经创建进程池，需要注意的是在创建进程池之前需要创建好监听socket，一旦进程池创建成功，调用run函数就使得父进程(程序一执行就存在，只不过发生了代码逻辑的跳转)和八个子进程同时启动，开始监听事件。 run函数区分父进程和子进程用了一个小技巧，通过循环创建进程时子进程继承过来的索引进行区分。父进程一开始初始化为-1，子进程都大于等于0。 父进程：负责监听listenfd和信号管道的fd[0]端。信号管道用于统一事件源。 父进程一旦监听到有新的连接到来时，通过Round Robin选择一个子进程(简单地通过m_pid是否为-1来选取)，然后就通过父子进程之间已经建立好的管道将这个事件通知给子进程。 父进程还会监听到信号管道发来的信号事件，根据不同的信号进行相应的处理。比较需要注意的子进程的回收，还要关闭相应的管道 子进程：负责监听父子进程通信的管道的fd[1]端，信号管道的fd[0]端和通过该子进程建立连接的confd。维护该子进程连接着的所有用户请求对象的一个数组。 子进程一旦监听到父进程通过管道给自己发送数据，就代表有的客户连接需要接收。调用accept接收用户连接，然后进行用户请求类的初始化 子进程监听到信号管道发来的信号事件，根据相应的信号进行对应的处理 子进程监听到已经建立连接的用户有数据请求，就调用用户请求对象的process方法 还有一个很关键的类，就是用来处理客户CGI请求的类，需要实现init方法和process方法，process方法就完成了CGI请求(创建一个子进程，用来执行CGI程序，并且将标准输出重定向到网络socket) 小技巧：子进程中需要的变量都从父进程继承了过来，并根据需要进行相应的修改也不会相互影响 扩展性：该进程池具有一定的扩展性，本次实例中process用来实现的CGI请求，但是可以根据不同的场景需要进行修改，但不会修改进程池内部源码。","comments":true,"tags":[{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"进程","slug":"进程","permalink":"https://oldbuffalo.github.io/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"高性能服务器程序框架","date":"2019-03-25T09:14:01.000Z","path":"2019/03/高性能服务器程序框架/","text":"服务器主要可以分成三个模块 I/O处理单元 逻辑单元 存储单元 服务器模型 C/S模型(客户端/服务器模型) 这种模型很好理解，服务器掌控着资源，客户端每次都需要请求服务器来获取资源。 这种模型很适合资源相对集中的场合，但是当访问量过大时，可能所有客户都将得到很慢的回应。 P2P模型(点对点模型) 网络中所有的主机都是对等的地位。P2P模型使得每台机器在消耗服务的同时也给别人提供服务，这样资源能够充分、自由地共享，但是当用户之间传输的请求过多时，网络的负载将加重。 云计算机群是P2P模型的一个典范。 上图所示的P2P模型存在一个显著的问题，就是主机之间很难互相发现，所以实际使用的P2P模型通常带一个专门的发现服务器。发现服务器通常还提供查找服务，使得每个客户都能尽快找到自己需要的资源。 I/O处理单元 I/O模型 阻塞I/O 非阻塞I/O I/O复用 信号驱动I/O(SIGIO) 异步I/O 具体参见Linux下的网络I/O模型 两种高效的事件处理模式 服务器通常要处理三类事件：I/O事件、信号、定时事件 1.Reactor 同步I/O模型通常用于实现Reactor模式 Reactor:要求主线程(I/O处理单元)只负责监听文件描述符上是否有事件发生，有的话就立即将该事件通知工作线程(逻辑单元)。除此之外，主线程不做任何其他实质性的工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。 使用同步I/O模型(epoll_wait)实现Reactor。 主线程往epoll内核事件表中注册socket上的读就绪事件 主线程调用epoll_wait等待socket上有数据可读 当socket上有数据可读时，epoll_wait通知主线程。主线程则将socket可读事件放入请求队列 睡眠在请求队列上的某个工作线程被唤醒，它从socket上读取数据，并处理客户端请求，然后往epoll内核事件表中注册该socket上的写就绪事件 主线程调用epoll_wait等待socket可写 当socket可写时，epoll_wait通知主线程，主线程将socket可写事件放入请求队列 睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果 2.Proactor 异步I/O模型通常用于实现Proactor模式，同步I/O也能模拟 Proactor:将所有I/O操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。因此这种模式更符合一般的服务器编程框架。 使用异步I/O模型(aio_read和aio_write)实现Proactor模式 主线程中的epoll_wait调用仅仅用来检测监听socket上的连接请求事件，而不能检测连接socket上的读写事件。连接socket上的读写事件是通过aio_read和aio_write向内核注册的，内核通过信号向应用程序通知连接socket上的读写事件。 主线程调用aio_read函数向内核注册socket上的读完成事件，并告诉内核用户读缓冲区的位置，以及读操作完成时如何通知应用程序(以信号为例) 主线程继续处理其他逻辑(这里体现出异步，不同于同步的阻塞) 当socket上的数据被读入用户缓冲区，内核将向应用程序发送一个信号，以通知应用程序数据已经可用 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后，调用aio_write函数向内核注册socket上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序(以信号为例) 主线程继续处理其他逻辑 当用户缓冲区的数据被写入socket之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕 应用程序预先定义好的信号处理函数选择一个工作线程来做善后处理，比如决定是否关闭socket 使用同步I/O模拟Proactor模式 原理：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一”完成事件”。那么从工作线程的角度来看，它们直接获得了数据读写的结果，只需要对读写的结果进行逻辑处理。 主线程往epoll内核事件表中注册socket上的读就绪事件 主线程调用epoll_wait等待socket上有数据可读 当socket上有数据可读时，epoll_wait通知主线程。主线程从socket循环读取数据，知道没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列 睡眠在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket的写就绪事件 主线程调用epoll_wait等待socket可写 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果 逻辑单元 两种高效的并发模式 并发模式：I/O处理单元和多个逻辑单元之间协调完成任务的方法 1.半同步/半异步模式 首先区分一下并发模式中的同步和异步概念 在I/O模式中，同步和异步的区别在于内核向应用程序通知的是什么类型的事件，换句话说I/O读写是由谁完成的 在并发模式中，“同步”指的程序完全按照代码序列顺序执行，”异步”指的是程序的执行需要由系统事件来驱动。常见的系统事件有中断、信号等。 下图描绘了并发模式下同步异步的区别： 异步线程执行效率高，实时性强，很多嵌入式程序采用的模型，但是以异步方式执行的程序相对复杂，难以调试和扩展，不适合于大量的并发。 同步线程虽然效率相对较低，实时性较差，但逻辑简单。 因此，像服务器这种既要求较好的实时性，又要求同时处理多个客户请求的应用程序，应该同时使用同步线程和异步线程相结合来实现，也就是半同步/半异步模式。 半同步/半异步模式中，同步线程用于处理客户逻辑，相当于逻辑单元，异步线程用于处理I/O事件，相当于I/O处理单元。异步线程监听到客户请求后，就将其封装成请求对象并插入请求队列中。请求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象。 在服务器程序中，结合考虑两种事件处理模式和几种I/O模型，那么半同步/半异步模式存在多种变体 半同步/半反应堆模式 异步线程只有一个，由主线程充当，负责监听所有socket上的事件如果监听socket上有可读事件发生，即有新的连接请求到来，主线程就接收之以得到新的连接socket，然后往epoll内核事件表中注册该socket上的读写事件。如果连接socket上有读写事件发生，即有新的客户请求到来或有数据要发送给客户端，主线程就将该连接socket插入请求队列中。 所有的工作线程都睡眠在请求队列上，当有任务到来时，它们 将通过竞争(比如申请互斥锁)来获得任务的接管权。这种竞争机制使得只有空闲的工作线程才有机会来处理新任务。 由于主线程插入请求队列的任务是就绪的连接socket，因此半同步/半反应堆模式采用的事件处理模式是Reactor模式，要求工作线程自己从socket上读取客户请求和往socket写入服务器应答。 缺点： 1.主线程和工作线程共享请求队列。主线程往请求队列中添加任务或者工作线程从请求队列中取出任务，都需要对请求队列加锁保护，从而白白耗费CPU时间 2.每个工作线程在同一时间只能处理一个客户请求。如果客户数量较多，而工作线程较少，请求队列中就会堆积很多任务对象，客户端的响应速度将越来越慢。如果通过增加工作线程来解决这个问题，工作线程的切换也将消耗大量的CPU时间 半同步/半异步模式 主线程只管理监听socket，连接socket由工作线程来管理。当有新的连接到来时，主线程就接受之并将新返回的连接socket派发给某个工作线程，此后该新socket上的任何I/O操作都由被选中的工作线程来处理，直到客户关闭连接。主线程向工作线程派发socket的最简单的方式，是往它和工作线程之间的管道里写数据。工作线程检测到管道里有数据可读时，就分析是否是一个新的客户连接请求到来。如果是，就把新的socket上的读写事件注册到自己的epoll内核事件表中。因此，每个工作线程都能同时处理多个客户连接。 每个线程(主线程和工作线程)都维持着自己的事件循环，它们各自独立地监听不同的事件。因此，半同步/半异步模式下，每个线程都工作在异步的模式。 2.领导者/追随者模式 领导者/追随者：多个工作线程轮流获得事件源集合，轮流监听、分发并处理事件 在任意时间点，程序都仅有一个领导者线程，它负责监听I/O事件，而其他线程都是追随者，他们休眠在线程池中推选出新的领导者线程，然后处理I/O事件。此时，新的领导者等待新的I/O事件，而原来的领导者则处理I/O事件，二者实现了并发。 该模式主要包括：句柄集、线程集、事件处理器、具体事件处理器。 具体关系参见《Linux高性能服务器编程》P134 有限状态机 逻辑单元内部的一种高效编程方法。我们以一个HTTP请求的读取和分析程序来分析一下，在服务器读取HTTP请求时，如果没有利用有限状态机，就需要等读取到表示头部结束的空行才能对头部进行解析，但是用有限状态机之后可以一边接受数据一边进行分析，其效率更高。】 使用有限状态机读取和分析HTTP请求，代码实例 模拟了正确的请求报文和错误的请求报文两种情况，发现其正常工作。 在main函数中，循环调用recv函数往buf中读入用户数据，每次成功读取数据后，交给parse_content函数来分析读入的数据。parse_content函数首先要做的是调用parse_line函数来获取完整一行，对于完整的一行根据行状态的不同调用不同的处理函数。 分析一下发现，这里面存在着两个有限状态机，分别是主状态机和从状态机，从状态机就是一个parse_line函数，负责从buf中解析出一个行，其初始状态为LINE_OK，原始驱动力来源于buf中新到达的数据，而当从状态机读取到了一个完整的行，就需要将这个行交给主状态机处理，主状态机中根据当前状态调用不同的函数对报文进行解析，从而实现状态转移。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"网络中一些高级I/O函数","date":"2019-03-24T12:44:57.000Z","path":"2019/03/网络中一些高级IO函数/","text":"跟着游双老师的《Linux高性能服务器编程》第六章敲了一些demon 理解了一些特殊场合使用的函数 dup和dup2用来创建一个文件描述符，一般用来重定向 CGI服务器原理：把标准输入重定向到一个网络连接 12int dup(int file_descriptor)int dup2(int file_descriptor_one,int file_descriptor_two) dup函数创建一个新的文件描述符，新的fd和原有文件描述符file_descriptor指向同一个文件，dup返回系统当前可用的最小的整数值。 dup2和dup类似，不过它返回第一个不小于file_descriptor_two的整数值。 注意点：dup和dup2创建的文件描述符不继承原文件描述符的属性，如close-on-exec和no-blocking等 CGI服务器原理代码 readv和writevreadv:将数据从文件描述符读到分散的内存块中，分散读 writev:将多块分散的内存书籍怒一并写入文件描述符中，几种写 1234567ssize_t readv(int fd,const struct iovec* vector,int count);ssize_t writev(int fd,const struct iovec* vector,int count);struct iovect&#123; void* iov_base; &#x2F;&#x2F;内存起始地址 size_t iov_len; &#x2F;&#x2F;这块内存的长度&#125;; 这两个函数相当于简易版的recvmsg和sendmsg。 对于web服务器，在收到一个HTTP请求之后，解析请求，需要回复一个HTTP应答(应答头+请求资源)给用户，可能HTTP应答放在一块内存中，而资源的内容被读入到另一块内存中，并不需要把这两部分内容拼接到一起再发送，而是可以借助writev将它们同时写出。 web服务器上的集中写 sendfile该函数在两个文件描述符中直接传递数据，完全在内核中操作，避免了内核缓冲区到用户缓冲区之间的数据拷贝，效率高，也叫零拷贝。 1ssize_t sendfile（int out_fd,int in_fd,off_t* offset,size_t count）； out_fd:待写入内容的文件描述符,必须是一个socket in_fd:待读出内容的文件描述符,必须指向真是的文件，不能是socket和管道 offset:从读入文件流的哪个位置开始读，如果是NULL，默认从起始位置。 因此，sendfile是专门为网络上传输文件设计的。 sendfile传输文件 splice用于在两个文件描述符之间移动数据，也是零拷贝操作 1ssize_t splice(int fd_in,loff_t* off_in,int fd_out,loff_t* off_out,size_t len,unsigned int flags) fd_in:带输入数据的文件描述符。如果fd_in是管道文件，off_in必须是NULL off_in:如果fd_in不是管道文件，该参数表示从输入数据流的何处开始读取位置，如果是NULL，表示从输入数据流的当前偏移位置读入。 flags参数： 注意：fd_in和fd_out中至少有一个是管道文件描述符 使用splice实现的echo服务器 tee在两个管道文件描述符之间复制数据，也是零拷贝操作。不消耗数据，因此源文件描述符上的数据仍然可以用于后续操作。 1ssize_t tee(int fd_in,int fd_out,size_t len,unsigned int flags) 参数含义和splice一样。 注意：fd_in和fd_out必须都是管道文件描述符 利用tee实现同时输出数据到终端和文件","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"优秀博客整理","date":"2019-03-23T11:38:38.000Z","path":"2019/03/优秀博客整理/","text":"整理一些优秀的博文，方便以后复习 C++多种继承方式的对象模型 C++11explicit 网络backlog参数理解 半连接队列和全连接队列 算法位操作 软件安装ubuntu16.04安装mysql linux解决解决/usr/bin/ld: cannot find -lxxx Windows下vs2012安装boost库 小插曲:一开始安装的是boost_1_70_0，日志提示应该是工具集不匹配的问题，又乖乖按照博客中的boost_1_67_0进行安装。 能够成功安装，但是无法使用，又配合下面的博客成功完成boost的使用。 boost库安装的问题解决 Windows下vs2012安装OpenCV2.4.13 虽然安装的OpenCV版本比较旧，但是这也是一次初体验 遇到的问题： 一开始编译能通过但是找不到库，重启了一下机器就ok了，因为系统环境变量需要重启才能生效 imread读取图片失败 注意链接库版本：debug的库为xxxd.dll，release的库为xxx.dll 更坑爹的是，都正确了还是不行，编译能过，但是一直有warning:由通用字符名称“\\u202A”表示的字符不能在当前代码页(936)中表示出来，就一直没在意，但是一直运行不出来。查了一下才发现是路径复制过来的问题。 imshow图片显示不出来：imshow之后要调用waitKey或者cvWaitKey ubuntu16.04安装OpenCV 不行的话就加个sudo提权 pkg-config –modversion opencv 版本查看 测试用例 ubuntu16.04 vscode 配置C++环境 https://blog.csdn.net/fengbingchun/article/details/60780232 https://blog.csdn.net/tt_ren/article/details/53227900 https://blog.csdn.net/feierban/article/details/80283727","comments":true,"tags":[{"name":"随笔","slug":"随笔","permalink":"https://oldbuffalo.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"虚函数表","date":"2019-03-23T05:44:50.000Z","path":"2019/03/虚函数表/","text":"前置知识C++中virtual主要是用来实现多态，一般的流程是用父类的指针指向子类的对象，然后通过父类的指针调用子类重写父类的虚函数。所谓多态，就是让父类指针有“多种形态”，换言之，就是用不变的代码实现可变的算法。比如：模板技术，RTTI技术，虚函数技术，要么是试图做到在编译时决议，要么试图做到运行时决议。 virtual函数的实现又借助了虚函数指针(vptr)和虚函数表(v-table)实现。vptr的位置为编译器决定，现在很多C++的编译器保证虚函数表的指针存在于对象实例中最前面的位置。 虚函数表12345678910111213141516171819202122232425class Base&#123;public: double x; int y;public: virtual void f()&#123; cout&lt;&lt;&quot;f&quot;&lt;&lt;endl;&#125; virtual void g()&#123;cout&lt;&lt;&quot;g&quot;&lt;&lt;endl;&#125; virtual void h()&#123;cout&lt;&lt;&quot;h&quot;&lt;&lt;endl;&#125;&#125;;typedef void(*PFUN)(); int main()&#123; Base b; printf(&quot;%p\\n&quot;,&amp;b); &#x2F;&#x2F;对象的地址 printf(&quot;%p\\n&quot;,*(int*)&amp;b); &#x2F;&#x2F;vptr的值，也就是虚函数表的地址 PFUN pfun &#x3D; (PFUN)*(int*)*(int*)&amp;b; pfun(); &#x2F;&#x2F;调用了f() (*pfun)()也行 return 0; &#125;&#x2F;*(PFUN)*((int*)*(int*)&amp;b+0) --------&gt;Base::f()的地址(PFUN)*((int*)*(int*)&amp;b+1) --------&gt;Base::g()的地址(PFUN)*((int*)*(int*)&amp;b+2) --------&gt;Base::h()的地址*&#x2F; 根据上面这个实例，可见通过对实例取地址，转换成int类型指针，然后间接引用取到vptr的值，也就是虚表的地址，然后再进行一次强转int类型指针，再次间接引用，取得函数地址。 注意点：32位的机器用int类型指针强转，而64位机器要用long long 强转 因为32位和64位指针大小不一样 一般单继承原则： 子类与父类拥有各自的一个虚函数表 若子类并无overwrite父类虚函数，用父类虚函数 若子类重写（overwrite）了父类的虚函数，则子类虚函数将覆盖虚表中对应的父类虚函数 若子声明了自己新的虚函数，则该虚函数地址将扩充到虚函数表最后 子类没有重写父类的虚函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Base&#123;public: int m_x;public: Base(int x &#x3D; 1):m_x(x)&#123;&#125; virtual void f()&#123; cout&lt;&lt;&quot;f&quot;&lt;&lt;endl;&#125; virtual void g()&#123;cout&lt;&lt;&quot;g&quot;&lt;&lt;endl;&#125; virtual void h()&#123;cout&lt;&lt;&quot;h&quot;&lt;&lt;endl;&#125;&#125;;class Derive:public Base&#123;public: Derive(int x &#x3D; 2.0):Base(x)&#123;&#125; virtual void f1()&#123; cout&lt;&lt;&quot;f1&quot;&lt;&lt;endl;&#125; virtual void g1()&#123;cout&lt;&lt;&quot;g1&quot;&lt;&lt;endl;&#125; virtual void h1()&#123;cout&lt;&lt;&quot;h1&quot;&lt;&lt;endl;&#125;&#125;;typedef void(*PFUN)(); int main()&#123; Base b; PFUN pfun &#x3D; (PFUN)*(int*)*(int*)&amp;b; printf(&quot;%d\\n&quot;,sizeof(b)); &#x2F;&#x2F;实例b的字节数 输出8 printf(&quot;%p\\n&quot;,&amp;b); &#x2F;&#x2F;对象b的地址 010FFABC printf(&quot;%p\\n&quot;,&amp;b.m_x); &#x2F;&#x2F;对象中m_x成员的地址 010FFAC0 比上一个多4 也就是vptr的大小 &#x2F;&#x2F;将对象的地址 移动一个int 然后强制成int* 010FFAC0 也就是m_x的地址 printf(&quot;%p\\n&quot;,(int*)((int*)&amp;b+1)); &#x2F;&#x2F;将对象的地址 移动一个int 然后强制成int* 再间接引用 取出来m_x的值 输出1 printf(&quot;%d\\n&quot;,*(int*)((int*)&amp;b+1)); pfun(); Derive d; PFUN pfun1 &#x3D; (PFUN)*(int*)*(int*)&amp;d; &#x2F;&#x2F;Base::f()的地址 PFUN pfun2 &#x3D; (PFUN)*((int*)*(int*)&amp;d+3); &#x2F;&#x2F;Derive::f1()的地址 printf(&quot;%d\\n&quot;,sizeof(d)); &#x2F;&#x2F; 实例d的字节数 输出8 printf(&quot;%p\\n&quot;,&amp;d); &#x2F;&#x2F;对象b的地址 010FFAA0 printf(&quot;%p\\n&quot;,&amp;d.m_x);&#x2F;&#x2F;对象中m_x成员的地址 010FFAA4 比上一个多4 也就是子类vptr的大小 &#x2F;&#x2F;将对象的地址 移动一个int 然后强制成int* 010FFAA4 也就是m_x的地址 printf(&quot;%p\\n&quot;,(int*)((int*)&amp;d+1)); &#x2F;&#x2F;将对象的地址 移动一个int 然后强制成int* 再间接引用 取出来m_x的值 输出2 printf(&quot;%d\\n&quot;,*(int*)((int*)&amp;d+1)); pfun1(); pfun2(); getchar(); return 0; &#125; Derive类的虚函数表如下： 由上图可以看到下面几点：1）虚函数按照其声明顺序放于表中。2）父类的虚函数在子类的虚函数前面。 有一个问题： 123456class Test&#123; int a; double b; virtual void A()&#123;&#125;&#125;;sizeof(Test)------------&gt;24 why? 好像不符合内存字节对齐的规律 子类重写父类的虚函数 123456789101112131415161718192021222324252627282930class Base&#123;public: int m_x;public: virtual void f()&#123; cout&lt;&lt;&quot;Base::f&quot;&lt;&lt;endl;&#125; virtual void g()&#123;cout&lt;&lt;&quot;g&quot;&lt;&lt;endl;&#125; virtual void h()&#123;cout&lt;&lt;&quot;h&quot;&lt;&lt;endl;&#125;&#125;;class Derive:public Base&#123;public: virtual void f()&#123; cout&lt;&lt;&quot;Derive::f&quot;&lt;&lt;endl;&#125; virtual void g1()&#123;cout&lt;&lt;&quot;g1&quot;&lt;&lt;endl;&#125; virtual void h1()&#123;cout&lt;&lt;&quot;h1&quot;&lt;&lt;endl;&#125;&#125;;typedef void(*PFUN)(); int main()&#123; Derive d; PFUN pfun&#x3D; (PFUN) *(int*)*(int*)&amp;d; &#x2F;&#x2F; Derive::f() PFUN pfun1&#x3D; (PFUN)*((int*)*(int*)&amp;d+3);&#x2F;&#x2F; Derive::g1() pfun(); pfun1(); getchar(); return 0; &#125; Derive类的虚函数表如下： 由上图可以看到下面几点：1）覆盖的f()函数被放到了虚表中原来父类虚函数的位置。2）没有被覆盖的函数依旧。 因此，多态的实现可以通过 12Base *b &#x3D; new Derive();b-&gt;f(); 由b所指的内存中的虚函数表的f()的位置已经被Derive::f()函数地址所取代，于是在实际调用发生时，是Derive::f()被调用了。这就实现了多态。 多重继承原则： 若子类新增虚函数，放在声明的第一个父类的虚函数表中 若子类重写了父类的虚函数，所有父类的虚函数表都要改变：如fun1 内存布局中，父类按照其声明顺序排列 无虚函数重写 类图： Derive类的虚函数表如下： 由上图可以看到下面几点：1） 每个父类都有自己的虚表。2） 子类的成员函数被放到了第一个父类的表中。（所谓的第一个父类是按照声明顺序来判断的） 有虚函数重写 图中子类重写了父类的f()函数 Derive类的虚函数表如下： 12345678910Derive d;Base1 *b1 &#x3D; &amp;d;Base2 *b2 &#x3D; &amp;d;Base3 *b3 &#x3D; &amp;d;b1-&gt;f(); &#x2F;&#x2F;Derive::f()b2-&gt;f(); &#x2F;&#x2F;Derive::f()b3-&gt;f(); &#x2F;&#x2F;Derive::f()b1-&gt;g(); &#x2F;&#x2F;Base1::g()b2-&gt;g(); &#x2F;&#x2F;Base2::g()b3-&gt;g(); &#x2F;&#x2F;Base3::g() 虚继承虚继承解决了菱形继承中派生类拥有多个间接父类实例的情况 原则： 虚继承的子类，如果本身定义了新的虚函数，则编译器为其生成一个新的虚函数指针（vptr）以及一张虚函数表。该vptr位于对象内存最前面（对比非虚继承：直接扩展父类虚函数表） 虚继承的子类也单独保留了父类的vptr与虚函数表 虚继承的子类有虚基类表指针（vbptr） 简单虚继承 1234567891011121314151617181920212223242526272829303132class Base&#123;private: int m_base;public: virtual void fun1()&#123;cout &lt;&lt; &quot;Base::fun1&quot;&lt;&lt;endl;&#125; virtual void fun2()&#123;cout&lt;&lt;&quot;Base::fun2&quot;&lt;&lt;endl;&#125;&#125;;class Derive : virtual public Base&#123;private: int m_y;public: void fun1()&#123;cout &lt;&lt; &quot;Derive::fun1&quot;&lt;&lt;endl;&#125; virtual void fun3()&#123;cout &lt;&lt; &quot;Derive::fun3&quot;&lt;&lt;endl;&#125;&#125;;typedef void (*PFUN)();int main()&#123; Derive d; PFUN pfun &#x3D; (PFUN)*(int*)*(int*)&amp;d; &#x2F;&#x2F; Derive::fun3 pfun(); PFUN pfun1 &#x3D; (PFUN)*(int*)*((int*)&amp;d+3); &#x2F;&#x2F; Derive::fun1 PFUN pfun2 &#x3D; (PFUN) *((int*)*((int*)&amp;d+3)+1); &#x2F;&#x2F;Base::fun2 pfun1(); pfun2(); getchar(); return 0; &#125; 对象模型： 菱形虚继承 对象模型:","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"}]},{"title":"算法整理","date":"2019-03-20T10:45:02.000Z","path":"2019/03/算法整理/","text":"数组问题二维数组中的查找 旋转数组的最小数字 调整数组顺序使奇数位于偶数前面 顺时针打印矩阵 数组中出现次数超过一半的数字 最小的k个数 连续子数组的最大和_dp问题 两个不相交的字数组的最大和 把数组排成最小的数 数组中的逆序对 栈和队列两个栈实现队列 两个队列实现栈 包含min函数的栈 leetcode 155 栈的压入、弹出序列 滑动窗口的最大值 仅用递归函数和栈操作逆序一个栈 猫狗队列 用一个栈实现另一个栈的排序 用栈来求解汉诺塔问题 构造数组的MaxTree 最大子矩阵的大小 京东环形烽火台问题 链表问题从尾到头打印链表 leetcode 206 打印两个有序链表的公共部分 反转单向和双向链表 反转部分单向链表 合并两个有序的链表 leetcode 21 链表中倒数第K个元素 在单链表和双链表中删除倒数第k个节点 删除链表的中间节点和a/b处的节点 复杂链表的复制 letcode 138 判断链表是否有环，如果有环返回入环结点 两个无环单链表的第一个相交结点 两个有环单链表的相交结点 删除链表中重复的结点 判断一个链表是否为回文结构 leetcode 234 单向链表按某值划分左边小、中间相等、右边大 单链表中的数字相加 leetcode 2 给单链表重新排序(reorder) leetcode 143 树问题二叉树的重建 二叉树的子结构 二叉树的镜像 二叉搜索树的后序遍历序列 二叉树中和为某一值的路径 二叉搜索树变成双向链表 二叉树的深度 二叉树的后继结点 对称的二叉树 之字型打印二叉树 层次遍历_把二叉树打印成多行 判断平衡二叉树 序列化和反序列化二叉树 二叉搜索树的第k个结点 数据流中的中位数 图问题位操作数值计算整数中1出现的次数 丑数 字符串问题排序搜索动态规划矩形嵌套问题 回溯","comments":true,"tags":[{"name":"算法","slug":"算法","permalink":"https://oldbuffalo.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数据结构","slug":"数据结构","permalink":"https://oldbuffalo.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}]},{"title":"进程","date":"2019-03-15T09:44:38.000Z","path":"2019/03/进程/","text":"最近面了鹅厂实习的提前批，复试凉凉，还是挂在操作系统。 所以决定恶补一波，跟着工大孙志岗老师的视频和《操作系统之哲学原理》重新学一下操作系统。 操作系统操作系统的作用是管理计算机上的各种资源，在硬件和软件之间起到桥梁的作用。 资源主要包括CPU、内存、文件系统、I/O等。 进程针对CPU管理，操作系统使用的是进程模型，也就是说操作系统用进程来控制CPU进行计算。 进程是为了在CPU上实现多道编程而出现的概念，也就是通过并发来提高系统利用率，同时缩短系统响应时间。 进程：执行中的程序，也就是说一个程序加载到内存中就变成了进程。 每一个进程都占用一片内存空间，那么如何让多个进程共享同一个物理内存而不发生冲突，这就涉及到内存管理 如何将CPU在多个进程之间进行切换，这就涉及进程实现的另一个问题，CPU调度 进程控制linux在操作系统通过进程控制块(PCB)来管理进程,实际上就是一个task_struct结构体。 在我的虚拟机上，它保存在/usr/src/linux-headers-4.4.0-21/include/linux/sched.h文件中 通过/ str(待查找的字符串)可以找到task_struct结构体的定义，保存了进程所有的信息。 单个进程是通过PCB来管理的，那么操作系统又是怎么管理所有进程的PCB的呢？(有待查证) 维护所有进程的队列、就绪队列、设备队列(每个I/O设备都有一个队列，进程阻塞在对应IO的队列上) 那么队列是用什么数据结构实现的呢？ 由于各个队列之间需要频繁的添加、删除操作，因此用链表实现似乎更适合。 但是，在操作系统底层用的一个大数组，然后用指针指向一个结构体存储所有就绪队列的编号，用指针指向一个结构体存储设备队列的编号。 为什么要数组呢？ 1.访问比较快速，链表遍历是一个很耗时的操作 2.局部性原理(cache)，链表遍历可能造成cache一直刷新，效率低，局部性原理和数组比较般配 3.缺点：有空间的闲置、空洞，造成内存浪费，但是如今硬件条件更好了。 进程在内存中的模型虚拟地址空间 32位系统 0-4G 64位系统 0-256TB 以32位为例 Linux 使用虚拟地址空间，大大增加了进程的寻址空间，由低地址到高地址分别为： 只读段：该部分空间只能读，不可写；(包括：代码段、rodata 段(C常量字符串和#define定义的常量) ) 数据段：保存全局变量、静态变量的空间； 堆 ：就是平时所说的动态内存， malloc/new 大部分都来源于此。其中堆顶的位置可通过函数 brk 和 sbrk 进行动态调整。 文件映射区域 ：如动态库、共享内存等映射物理空间的内存，一般是 mmap 函数所分配的虚拟地址空间。 栈：用于维护函数调用的上下文空间，一般为 8M ，可通过 ulimit –s 查看。 内核虚拟空间：用户代码不可见的内存区域，由内核管理(页表就存放在内核虚拟空间) 其中 0x080480000xbfffffff 是用户空间，0xc00000000xffffffff 是内核空间，包括内核代码和数据、与进程相关的数据结构（如页表、内核栈）等。另外，%esp 执行栈顶，往低地址方向变化；brk/sbrk 函数控制堆顶_edata往高地址方向变化。","comments":true,"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://oldbuffalo.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程","slug":"进程","permalink":"https://oldbuffalo.github.io/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"Linux进程间通信方式","date":"2019-03-13T12:52:05.000Z","path":"2019/03/linux进程间通信方式/","text":"进程间通信(InterProcess Communication)当多个进程同时访问系统上的某个资源的时候，比如同时写一个数据库的某条记录，或者同时修改某个文件，就需要考虑进程同步的问题，确保任一时刻只有一个进程可以拥有对资源的独占式访问。 程序对共享资源访问的代码只是很短的一段，但就是这一段代码引发了进程之间的竞态条件，那么这段代码称为关键段，也叫临界区。 进程间通信大体思路有两种：1.数据传递(通过内核) 2.共享内存 管道1int pipe(int fd[2]); &#x2F;&#x2F;成功返回0 出错返回-1 局限性： 半双工(数据只能在一个方向上流动)。现在UNIX域套接字默认是全双工的(通过socketpair创建) 只能在具有公共祖先的两个进程之间使用。一般都是一个进程先调用pipe，然后调用fork 父进程把文件描述符传给子进程之后父子进程 之间通信 也可以父进程fork两次，把文件描述符传给两个子进程，然后两个子进程之间通信 缓冲区有限（在管道创建时，为缓冲区分配一个页面大小），常量PIPE_BUF决定 fork之后做什么取决于我们想要的数据流方向。对于从父进程到子进程的管道，父进程关闭管道的读端(fd[0])，子进程关闭管道的写端(fd[1])。 使用注意事项(假设都是阻塞I/O操作)： 当读一个写端被关闭的管道(引用计数为0)，在所有数据都被读取后，read返回0，表示文件结束。 如果写端没有被关闭，这时有进程从管道读数据，那么管道中剩余的数据被读取完之后，再次调用read将阻塞，直到持有写端的进程向管道中写入数据 当对于一个读端被关闭的管道进行写操作，将产生SIGPIPE信号，默认动作终止进程。如果忽略该信号或者捕捉该信号并从其处理程序返回，write返回-1，并设置errno为EPIPE 如果读端没有被关闭，持有读端的进程也没有读数据，这是写端向管道写数据，管道被写满时再次调用write将阻塞，知道有数据被read才能继续写入 PIPE_BUF规定了内核的管道缓冲区大小。 如果对管道调用write，并且要求写的字节数小于等于PIPE_BUF，则此操作不会与其他进程对同一管道(或者FIFO)的write交叉进行。 如果有多个进程同时写一个管道(或者FIFO)，而且要求写的字节数超过PIPE_BUF,那么所写的数据可能会与其他进程所写的数据相互交叉。 //有待实验 用pathconf或者fpathconf函数可以确定PIPE_BUF的值。","comments":true,"tags":[{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"},{"name":"操作系统","slug":"操作系统","permalink":"https://oldbuffalo.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"进程","slug":"进程","permalink":"https://oldbuffalo.github.io/tags/%E8%BF%9B%E7%A8%8B/"},{"name":"apue","slug":"apue","permalink":"https://oldbuffalo.github.io/tags/apue/"}]},{"title":"socket选项","date":"2019-03-13T09:15:03.000Z","path":"2019/03/socket选项/","text":"socket文件描述符本质上也是文件，可以用fcntl系统调用来控制文件描述符属性(通用POSIX方法) 专门操作socket文件描述符属性的函数： int getsockopt(int sockfd,int level,int option_name,void* option_value,socklen_t* restrict option_len); int setsockopt(int sockfd,int level,int option_name,const void* option_value,socklen_t option_len); level:操作那个协议 IPv4/IPv6/TCP… 常用的选项： 需要注意的是：对服务器而言，有部分socket选项只能来listen调用前针对监听socket设置才有效。比如TCP_MAXSEG选项，代表TCP最大报文段大小，该选项只能由同步报文段来发送。accept从listen监听队列中接收的连接至少是TCP_RECV状态，也就是服务器已经给接收连接端发送了同步报文段，如果TCP_MAXSEG选项在这之后设置，就不起作用了。对客户端而言，这些选项要在connect之前设置。 解决方案：对监听socket设置这些socket选项，那么accept返回的连接socket将自动继承这些选项。 这些选项包括：SO_DEBUG、SO_DONTROUTE、SO_KEEPLIVE、SO_LINGER、SO_OOBINLINE、SO_RCVBUF、SO_RCVLOWAT、SO_SNFBUF、SO_SNDLOWAT、TCP_MAXSEG、TCP_NODELAY。 SO_REUSEADDR选项服务器可以通过设置socket选项SO_REUSERADDR来强制使用处于TIME_WAIT状态的连接占用的socket地址。 1234int sockfd &#x3D; socket(AF_INET,SOCK_STREAM,0);assert(sockfd &gt;&#x3D; 0);int reuse &#x3D; 1;setsockopt(sockfd,SOL_SOCKET,SO_REUSEADDR,&amp;reuse,sizeof(reuse)); 此外，也可以通过改变内核参数/proc/sys/net/ipv4/tcp_tw_recycle来快速回收被关闭的socket 0表示禁用，1表示开启 SO_RCVBUF和SO_SNDBUF分别表示TCP接受缓冲区和发送缓冲区的大小。 用setsockopt选项设置TCP的接收缓冲区和发送缓冲区的大小时，系统会将其值加倍，并且不得小于某个最小值。 下面编写修改发送缓冲区和接收缓冲区的程序。客户端 服务器 服务器输出： 改变输入参数： 客户端输出： 改变输入参数： 从服务器的输出可见，系统会将设置的接收缓冲区的值翻倍，但是如果翻倍的值不足系统默认的最小值，我的机器(Ubuntu16.04)默认2240字节，系统就设置成2240字节。 从客户端的输出可见，系统会将设置的发送缓冲区的值翻倍，但是如果翻倍的值不足系统默认的最小值，系统就设置成4480字节。 SO_LINGER选项用来控制close系统调用在关闭TCP连接时的行为。 设置SO_LINGER选项的值时，需要给setsockopt(getsockopt)系统调用传递一个linger类型的结构体 1234struct linger&#123; int l_onoff; &#x2F;&#x2F;开启(非0)还是关闭(0)该选项 int l_linger; &#x2F;&#x2F;滞留时间&#125;; 根据linger结构体两个成员变量的不同值，close系统调用可能产生如下3种行为： l_onoff = 0。SO_LINGER不起作用。close采用默认行为关闭socket。 ​ 默认行为：立即返回，TCP模块负责把该socket对应的TCP发送缓冲区中残留的数据发送给对方 l_onoff !=0,l_linger = 0。close立即返回，TCP模块将丢弃被关闭的socket对杨的TCP发送缓冲区中残留的数据，同时给对方发送一个复位报文段。因此，这种情况给服务器提供了异常终止一个连接的方法。 l_onoff != 0,l_linger &gt; 0。此时close的行为取决于1.被关闭的socket对应的TCP发送缓冲区中是否有残留的数据。2.该socket是阻塞的，还是非阻塞的。 对于阻塞的socket，close将等待一段长为l_linger的时间，直到TCP模块发送完所有残留数据并得到对方的确认。如果这段时间内TCP模块没有发送完残留数据并得到对方的确认，close返回-1并设置errno为EWOULDBLOCK。 对于非阻塞的socket，close将立即返回，此时需要根据其返回值和errno来判断残留数据是否已经发送完毕。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"Linux网络编程流程","date":"2019-03-12T11:40:26.000Z","path":"2019/03/linux网络编程流程/","text":"服务器端1.创建socket int socket(int domain,int type,int protocol)； 自Linux内核2.6.17起，type参数可以接收SOCK_NONBLOCK和SOCK_CLOEXEC 分别表示将新创建的socket设置为非阻塞(fcntl也能完成)，以及用fork调用创建子进程时在子进程中关闭该socket 2.命名socket int bind(int sockfd,const struct sockaddr* my_addr,socklen_t addrlen); 将一个socket和socket地址绑定称为给socket命名 socket地址分为通用socket地址和专用socket地址，具体参见《Linux高性能服务器编程》p71-73 成功返回0，错误返回-1并设置errno。常见的errno是EACCES和AADDRINUSE EACCES：被绑定的地址是受保护的地址，进超级用户能访问，比如普通用户将socket绑定到知名服务端口 EADDRINUSE：被绑定的地址正在使用中。比如讲socket绑定到一个处于TIME_WAIT状态的地址 在构建socket地址的时候涉及一些转换函数。 主机字节序和网络字节序之间的转换（大小端） uint32_t htonl(uint32_t hostlong); uint16_t htons(uint16_t hostshort); uint32_t ntohl(uint32_t netlong); uint16_t ntohs(uint16_t netshort);IP地址转换函数 in_addr_t inet_addr(const char *cp); int inet_aton(const char *cp, struct in_addr *inp); char *inet_ntoa(struct in_addr in); 不可重入函数，内部用静态变量保存结果 /*上面三个针对IPv4，下面两个IPv4和IPv6都适用*/ in_addr_t inet_addr(const char *cp); const char *inet_ntop(int af, const void *src,char *dst, socklen_t size);3.监听socket int listen(int sockfd,int backlog); 创建监听队列来存放待处理的客户连接。 Linux内核2.2之后，backlog参数表示处于完全连接状态(ESTABLISHED)的socket的上限。 处于半连接状态的socket上限由/proc/sys/net/ipv4/tcp_max_syn_backlog内核参数定义 下面通过程序测试，代码链接 启动服务器，设置backlog参数值为5 在本机开启终端用telnet连接服务器 在本机开启了8个终端，连接到服务器，然后用netstat观察 观察到8个连接中有6个处于ESTABLISHED状态，两个处于SYN_RECV状态。 可见处于ESTABLISHED状态的连接最多是backlog+1个，改变backlog值重新测试，也能得到相同结论。 在不同系统上，结果可能会不同。一般完整连接数都略大于backlog的值。(有待考证) 4.接受连接 int accept(int sockfd,struct sockaddr* addr,socklen_t *addrlen_t); 对于接受连接的accept函数，它从监听队列中取出一个连接，与其建立连接，而不管其处于ESTABLISHED或CLOSE_WAIT状态，更不关心任何网络变化。 考虑一种特殊情况：如果监听队列中处于ESTABLISHED状态的连接对应的客户端出现网络异常等原因导致提前退出，根据上述的结论，accept也能调用成功。 5.数据读写 TCP: ssize_t recv(int sockfd,void* buf,size_t len,int flags); ssize_t send(int sockfd,const void* buf,size_t len,int flags); 因为Unix下一切皆文件，因此对文件的读写操作read和write同样适用于socket flags参数为数据收发提供了额外的控制，一般设置为0。它可以设置为下图选项中的一个或几个。 send和recv接发普通数据和带外数据,客户端、服务器 总共发送了三次数据 普通数据 “123” 带外数据 “abc” 普通数据 “123” 服务器端的输出为： 客户端发给服务器的3字节带外数据“abc”中，仅有最后一个字符‘c’被服务器当成真正的带外数据接收。 并且服务器对正常数据的接收被带外数据截断。”123ab”和“123”不能被一个recv全部读出来。 tcpdump关于带外数据的输出： 标志U代表TCP头部设置了紧急标志，”urg 3”是紧急偏移值，指出带外数据在字节流中的位置的下一个字节位置是7(4+3,4是该TCP报文的序号值的相对初始序号值的偏移)。因此带外数据是字节流中的第6个字符，即’c’。 注意：flags参数支队send和recv的当前调用生效。通过setsockopt可以永久性修改socket的某些属性。 关于带外数据： 很多时候，我们无法预期带外数据何时到来，但是好在Linux内核检测到TCP紧急标志时，会通知应用程序有带外数据需要接收。内核通知应用程序带外数据到达的两种常见方式： I/O复用产生的异常事件 SIGURG信号 除了需要知道有带外数据到达，还需要知道带外数据在字节流中的位置。 int sockatmark(int sockfd); 该函数的作用是判断sockfd是否处于带外标记，即下一个被读取到的数据是否是带外数据，如果是，返回1，此时就可以利用带MSG_OOB标记的recv调用来接收带外数据。 如果不是，返回0。 UDP： ssize_t recvfrom(int sockfd,void* buf,size_t len,int flags,struct sockaddr* src_addr,socklen_t* addrlen); ssize_t sendto(int sockfd,const void* buf,size_t len,int flags,const struct sockaddr* dest_addr,socklen_t addflen); 因为UDP通信没有连接的概念，所以我们每次读取数据都需要获取发送端的socket地址。 特别的：recvfrom/sendto也可以用于面向连接（STREAM）的socket的数据读写， 只需要把最后两个参数设置为NULL。 通用数据读写函数：ssize_t recvmsg(int sockfd,struct msghdr* msg,int flags); ssize_t sendmsg(int sockfd,struct msghdr* msg,int flags); 1234567891011121314struct msghdr&#123; void* msg_name; &#x2F;&#x2F;socket地址 socklen_t msg_namelen; &#x2F;&#x2F;socket地址的长度 struct iovec* msg_iov; &#x2F;&#x2F;分散的内存块 int msg_iovlen; &#x2F;&#x2F;分散内存块的数量 void* msg_control; &#x2F;&#x2F;指向辅助数据的起始位置 socklen_t msg_controllen; &#x2F;&#x2F;辅助数据的大小 int msg_flags; &#x2F;&#x2F;复制函数中的flags参数，并在调用过程中更新&#125;;struct iovec&#123; void* iov_base; &#x2F;&#x2F;内存起始地址 size_t iov_len; &#x2F;&#x2F;这块内存的长度&#125;; 对于recvmsg而言，数据将被读取并存放在msg_iovlen块分散的内存中，这些内存的位置和长度则由msg_iov指向的结构体指定，这称为分散读。 对于sendmsg而言，msg_iovlen块分散内存中的数据将一并发送，这称为集中写。 6.关闭连接 int close(int fd); 注意：close系统调用并非总是立即关闭一个连接，而是将fd的引用计数减1.只有当fd的引用计数为0时才真正关闭连接。多进程程序中，一次fork系统调用默认将使父进程中打开的socket的引用计数加1，因此必须在父进程和子进程中都对该socket执行close调用才能将连接关闭。(创建socket的时候有SOCK_CLOEXEC选项可以解决这个问题) int shutdown(int sockfd,int howto); 无论如何都要立即终止连接，而不是将socket的引用计数减1。 客户端1.创建socket 注意：客户端不需要命名socket，只需要用操作系统自动分配的socket地址，服务器需要bind，是因为客户端需要找到它，因此每次都需要一个固定的ip+port。 2.发起连接 int connect(int sockfd,const struct sockaddr* serv_addr,socklen_t addrlen); 发起连接需要知道服务器的socket地址 成功返回通信的socket，失败返回-1并设置errno,常见的errno ECONNREFUSED:目标端口不存在，连接被拒绝 ETIMEOUT:连接超时 EINPROGRESS:发生在对非阻塞的socket调用connect，而连接又没有立即建立。这时候我们可以调用select、poll等函数来监听这个连接失败的socket上的可写事件。当select、poll等函数返回后，再利用getsockopt来读取错误码并清除该socket上的错误。如果错误码为0，表示连接成功建立，否则连接失败 非阻塞connect 3.数据读写 4.关闭连接 一些额外的信息地址信息函数 int getsockname(int sockfd,struct sockaddr* address,socklen_t* address_len); int getpeername(int sockfd,struct sockaddr* address,socklen_t* address_len); 分别的作用是获取sockfd对应的本端socket地址和远端socket地址。 网络信息函数 socket地址两个要素：ip+port，都是数值，不方便记忆。 可以用主机名来访问一台机器，用服务名来代替端口号。 struct hostent* gethostbyname(const char* name); 根据主机名称获取主机的完整信息，通常先在/etc/hosts配置文件中查找主机，如果没找到，再访问DNS服务器 struct hostent* gethostbyaddr(const void* addr,size_t len,int type); 根据IP地址获取主机的完成信息 1234567struct hostent&#123; char* h_name; &#x2F;&#x2F;主机名 char** h_aliases; &#x2F;&#x2F;主机别名列表 int h_addrtype; &#x2F;&#x2F;地址类型(地址族) int h_length; &#x2F;&#x2F;地址长度 char** h_addr_list; &#x2F;&#x2F;按网络字节序列出的主机IP地址列表&#125;; struct servent* getservbyname(const char* name,const char* proto); 根据名称获取某个服务的完整信息 struct servent* getservbyport(int port,const char* proto); 根据端口号获取某个服务的完整信息 实际上两个函数都是通过读取/etc/services文件来获取服务信息的 123456struct servent&#123; char* s_name; &#x2F;&#x2F;服务名称 char** s_aliases; &#x2F;&#x2F;服务的别名列表 int s_port; &#x2F;&#x2F;端口号 char* s_proto; &#x2F;&#x2F;服务类型 tcp&#x2F;udp&#125;; int getaddrinfo(const char* hostname,const char* service,const struct addrinfo* hints,struct addrinfo** result); 该函数既能通过主机名获得IP地址，也能通过服务器获得端口号。 hostname既可以是主机名，也可以是IP地址 service既可以是服务器，也可以是字符串表示的十进制端口号 hints是用来对getaddrinfo输出进行更精确的控制，也可以设置为NULL result参数返回的是一个链表，该链表用来存储getaddrinfo反馈的结果 void freeaddrinfo(struct addrinfo* res)； 释放getaddrinfo为res申请的堆空间 12345678910struct addrinfo&#123; int ai_flags; &#x2F;&#x2F;见下图 int ai_family; &#x2F;&#x2F;地址族 int ai_socktype; &#x2F;&#x2F;服务类型 SOCK_STREAM&#x2F;SOCK_DGRAM int ai_protocol; &#x2F;&#x2F;具体网络协议 通常为0 socklen_t ai_addrlen; &#x2F;&#x2F;socket地址长度 char* ai_addrlen; &#x2F;&#x2F;主机的别名 struct sockaddr* ai_addr; &#x2F;&#x2F;指向socket地址 struct addrinfo* ai_next; &#x2F;&#x2F;指向下一个addrinfo对象&#125;; int getnameinfo(const struct sockaddr* sockaddr,socklen_t addrlen,char* host,socklen_t hostlen,char* serv,socklen_t servlen,int flags); 该函数能通过socket地址同时获得以字符串表示的主机名和服务名。 flags参数 getaddrinfo和getnameinfo返回的错误码","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"}]},{"title":"HTTP协议","date":"2019-03-12T07:58:31.000Z","path":"2019/03/HTTP协议/","text":"HTTP请求例子： 第一行是请求行，格式为方法+URL+协议版本（主流版本是HTTP/1.1） 第二行开始是请求头部，格式为头部选项：实体内容 请求方法有很多种，如下图： 具体字段就不赘述了。 HTTP应答例子： 第一行是状态行，格式为协议版本+状态码+状态信息 第二行开始是应答头部。格式为头部选项： 实体内容 状态码和状态信息如下： 有一些字段需要注意一下，比如Cookie。 CookieHTTP是一种无状态的协议，每个HTTP请求之间没有上下文关系。但是，在交互式Web应用程序兴起，很多时候需要之前的信息。因此，就需要用额外的手段来保持HTTP连接状态，Cookie起的就是这个作用。Cookie是服务器发给客户端的特殊信息(通过HTTP应答头部选项Set-Cookie),通知客户端保存Cookie,客户端每次想服务器发送给客户端都需要带上这些信息(通过请求头部选项Cookie)，服务器发现客户端发过来Cookie以后，会去检查是哪个客户端发来的，对比服务器上的记录得到状态信息。浏览器的自动登录就是这么实现的。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"HTTP","slug":"HTTP","permalink":"https://oldbuffalo.github.io/tags/HTTP/"}]},{"title":"HTTP代理服务器","date":"2019-03-10T12:20:53.000Z","path":"2019/03/HTTP代理服务器/","text":"HTTP代理服务器工作原理代理服务器的作用是实现对目标资源的中转访问，一般部署在客户端和目标服务器之间。 按照使用方式和作用分为：正向代理服务器、反向代理服务器、透明代理服务器 代理服务器通常提供缓存目标资源的功能，这样用户下次访问同一资源时速度会很快。 正向代理要求客户端自己设置代理服务器的地址。 客户端每次请求都直接发送到该代理服务器，并由代理服务器来请求目标资源。 比如处于局域网内的机器要访问Internet、访问一些被屏蔽掉的外网。 反向代理设置在服务器端，客户端无须进行任何设置。 用代理服务器来接收Internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从内部服务器得到的结果返回给客户端。这种情况下，代理服务器对外就表现为一个真实的服务器。 很多时候，ping同一个域名，有多个ip地址，这是因为设置了反向代理服务器。 上图很形象得反映了两者的区别。 透明代理只能设置在网关。用户访问Internet的数据报必然要经过网关，如果在网关上设置了代理，则该代理对用户来说显然是透明的，透明代理可以看做正向代理的一种特殊情况。 开源软件squid、varnish都是提供了缓存能力的代理服务器软件‘ squid支持所有代理方式,varnish仅能做反向代理 部署squid代理服务器以后码上","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"HTTP","slug":"HTTP","permalink":"https://oldbuffalo.github.io/tags/HTTP/"}]},{"title":"TCP数据传输","date":"2019-03-10T08:10:33.000Z","path":"2019/03/TCP数据传输/","text":"TCP交互数据流交互数据仅包含很少的字节，使用交互数据的应用程序(或协议)对实时性要求高，比如telnet、ssh等 延迟确认延迟确认：每次需要发送的确认报文段不马上发送，而是在一段延迟时间后查看本端是否有数据需要发送，如果有，就和确认信息一起发出。延迟确认可以减少发送TCP报文段的数量，提高通信效率。 一般服务器对客户请求处理得很快，所以它发送确认报文段的时候总有数据一起发送，常用延迟确认。而客户端用户的输入速度明显慢于客户端程序的处理速度，所以客户端的确认报文一般不携带任何应用程序数据。 在TCP四次挥手的时候，也有可能发生延迟确认。（确认客户端FIN包的ACK包可以和应用数据一起发送） Nagle算法在广域网中，交互数据流可能经受很大的延迟，并且，如果携带交互数据流的微小TCP报文段数量很多的时候(一个按键就导致一个TCP报文段)，可能导致拥塞发生，影响网络性能。 解决方案是:Nagle算法 Nagle算法要求当一个TCP连接中有在传数据(即那些已发送但还未经确认的数据)，小的报文段(长度小于SMSS)就不能发送，直到所有的在传数据都收到ACK。并且，在收到ACK后，TCP需要收集这些小数据，将其整合到一个报文段中发送。迫使TCP遵循停等规程。这样就极大地减少了网络上的微小TCP报文段的数量，另一个优点是自适应性：确认到达得越快，数据也就发送得越快。 TCP成块数据流成块数据的长度通常为TCP报文段允许的最大数据长度，使用成块数据的应用程序（或协议）对传输效率要求高，比如ftp。 当传输大量大块数据的时候，发送方会连续发送多个TCP报文段，接收方可以一次确认所有这些报文段。 发送方在收到上一次确认后，能连续发送多少个TCP报文段取决于接收通告窗口大小和拥塞窗口大小。 可以修改TCP接收缓冲区和发送缓冲区的大小。 带外数据用来迅速通告对方本端发生的重要事件，因此带外数据比普通数据有更高的优先级，应该总是立即被发送，而不论发送缓冲区中是否有排队等待发送的普通数据。 带外数据的传输可以使用一条独立的传输层连接，也可以映射到传输普通数据的连接上。 UDP没实现带外数据传输，TCP也没真正的带外数据，但是TCP可以利用头部中的紧急指针标志和紧急指针两个字段，给应用程序提供一种紧急方式。TCP的紧急方式利用传输普通数据的连接来传输紧急数据。 假设一个进程已经往某个TCP连接的发送缓冲区中写入了N个字节的普通数据，并等待其发送。在数据被发送之前，该进程又向这个连接写入了3字节的带外数据”abc”，此时，待发送的TCP报文段的头部被设置URG标志，且紧急指针被设置成指向最后一个带外数据的下一字节。 发送端一次发送的多字节带外数据中只有最后一字节被当作带外数据(c)，而其他数据(a、b)被当成普通数据。如果TCP以多个TCP报文段来发送上图所示TCP发送缓冲区中的内容，则每个TCP报文段都将设置自URG标志，并且它们的紧急指针指向同一位置，但只有一个TCP报文段真正携带带外数据。 TCP接收带外数据，接收端只有在接收到紧急指针标志时才检查紧急指针，然后根据紧急指针所指位置确定带外数据位置，并将它读入一个特殊的缓存，这个缓存只有1字节，称为带外缓存。如果上层应用没有及时将带外数据从带外缓存中读出，后续的带外数据将覆盖它。 上面的接收方式是TCP默认的接收方式，如果给TCP连接设置SO_OOBINLINE，那么带外数据将和普通数据一样被TCP模块存放在TCP接收缓冲区内。那么这样如何区分带外数据和普通数据? 1.紧急指针可以用来指出带外数据的位置2.socket编程接口提供了识别带外数据的系统调用 数据传输超时重传区别于三次握手的时候的超时重连策略 TCP超时重传策略：如果某个数据报在规定时间内没收到确认包，接下来一共执行5次重传，间隔分别是0.2s、0.4s、0.8s、1.6s、3.2s。 Linux中有两个重要的内核参数与TCP超时重传有关。 /proc/sys/net/ipv4/tcp_retries1 : 指定底层IP接管之前TCP最少执行的重传次数，默认值是3 /proc/sys/net/ipv4/tcp_retries2 : 指定连接放弃前TCP最多可以执行的重传次数，默认值是15(一般对应13~30min)","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"TCP","slug":"TCP","permalink":"https://oldbuffalo.github.io/tags/TCP/"}]},{"title":"IP协议","date":"2019-03-07T03:04:56.000Z","path":"2019/03/IP协议/","text":"特点IP协议是TCP/IP协议族的动力，它为上层协议提供无状态、无连接、不可靠的服务。 无状态：IP通信双方不同步传输数据的状态信息，因此所有的IP数据报的发送、传输和接收都是相互独立、没有上下文关系的。UDP和HTTP都是无状态 缺点：无法处理乱序和重复的IP数据报，因为数据报之间没有任何上下文关系 比如发送端发送的第N个IP数据报可能比第N+1个数据报后到达，就造成乱序 同一个IP数据报也可能经过不同的路径多次到达接收端 优点：简单、高效，无须为保持通信的状态分配一些内核资源，也无须每次传输数据都携带状态信息 无连接：IP通信双方不长久地维持对方的任何信息。因此，上层协议每次发送数据的时候，都必须明确指定对方的IP地址 不可靠：IP协议不能保证IP数据报准确到达接收端，只是尽最大努力交付，很多情况都能导致IP数据报发送失败。 某个中转路由器发现IP数据报在网络上存活时间太长(根据IP头部TTL字段)，那它将被丢弃，并返回一个ICMP错误信息(超时错误)给发送端。 接收端发现收到的IP数据报不正确(通过CRC校验)，它也将丢弃之，并返回一个ICMP错误信息(IP头部参数错误)给发送端。 无论哪种情况，发送端的IP模块一旦检测到IP数据报发送失败，就通知上层协议发送失败，而不会试图重传。因此，使用IP服务的上层协议(比如TCP)需要自己实现数据确认、超时重传等机制来达到可靠传输的目的。 IPv4头部 4位版本号：指定IP协议的版本。对IPv4来说，值是4。其他IPv4协议的扩展版本(如SIP协议和PIP协议)则具有不同的版本号(头部也和上图不一样) 4位头部长度：标识该IP头部有多少个32bit字（4字节）。因为4位最大能表示15，所以IP头部最长是60字节 8位服务类型：包括一个3位的优先权字段（现在已经被忽略），4位的TOS字段和1位保留字段（必须置0）。4位的TOS字段分别表示：最小延时、最大吞吐量、最高可靠性和最小费用。其中最多有一个能置为1，应用程序应该根据实际需要设置。比如像ssh和telnet这样的登录程序需要最小延时服务，文件传输程序则需要最大吞吐量服务。 16位总长度：整个IP数据报的长度，以字节为单位，因此IP数据报最大长度时65535字节，但由于MTU的限制，长度超过MTU的数据报都将被分片传输。 16位标识：唯一地标识主机发送的每一个数据报。其初始值由系统随机生成，每发送一个数据包，值就加1.该值在数据报分片时被复制到每个分片中，因此同一个数据报的所有分片都有相同的标识值。 3位标志字段：第一位保留，第二位表示“禁止分片”，在这种情况下，如果IP数据报长度超过MTU，IP模块将丢弃该数据报并返回一个ICMP差错报文。第三位表示“更多分片”，除了数据报的最后一个分片外，其他分片都要置1 13位分片偏移：是分片相对原始IP数据报开始处（仅指数据部分）的偏移。实际的偏移值是该值左移3位(乘8)后得到的，由于这个原因，除了最后一个IP分片外，每个IP分片的数据部分的长度必须是8的整数倍。 8位生存时间（TTL）：数据报到达目的地之前允许经过的路由器跳数。TTL值被发送端设置(通常是64)，数据报每经过一个路由，值就减1。减到0的时候就丢弃数据报，返回ICMP差错报文，TTL的值可以防止数据报陷入路由循环。 8位协议：用来区分上层协议。ICMP是1，TCP是6，UDP是17 16位头部校验和：由发送端填充，接收端对其使用CRC算法以验算IP数据报头部(只检验头部)在传输过程中是否损坏 32位的源端IP和目的端IP用来标识数据报的发送端和接收端。 IPv4最后一个字段是可变长的可选信息。最多包含40字节，列举常用的，更多可以看RFC 1393 记录路由，告诉数据报途径的所有路由器都将自己的IP地址填入IP头部的选项部分，就可以跟踪数据报的传递路径 时间戳：告诉每个路由器都将数据报被转发的时间(或时间与IP对)填入IP头部的选项部分，这样就可以测量途经路由之间数据报传输的时间 松散源路由选择：指定一个路由器IP地址列表，数据报发送过程中必须经过其中所有的路由器 严格源路由选择：和松散源路由选择类似，不过数据报只能经过指定的路由器 tcpdump抓包在用telnet远程登录的时候，遇到一些问题。 提示我无法连接到远程主机，连接被拒绝，上网查了一下发现telnet因为采用明文传送报文，安全性不好，很多Linux服务器都不开放telnet服务，而改用更安全的ssh方式了。因此需要打开telnet服务。 1.安装openbsd-inetd sudo apt-get install openbsd-inetd 2.安装telnetd sudo apt-get install telnetd 3.重启openbsd-inetd sudo /etc/init.d/openbsd-inetd restart 4.查看telnet运行状态 没开启之前输出为空 sudo netstat -a | grep telnet 这时候开始进行抓包 sudo tcpdump -i lo -ntx #抓取本地回路上的数据包 开启另外一个终端执行telnet命令 用tcpdump抓取到的第一个关于telmet的数据包(开头有两个DNS请求和应答的数据包) 该数据包描述的是一个IP数据报，由于使用telnet登录本机，所以IP数据报的源端IP地址和目的端IP地址都是 “127.0.0.1”。telnet服务器程序使用的端口号是23，而telnet客户端程序使用临时端口号34620与服务器通信。 “Flags”、“seq”、“win”、“options”都是TCP头部的信息，这里不展开。“length”描述的是IP数据报所携带的应用程序数据的长度。 由上图可知，这个数据包共60字节，其中前20字节是IP头部，后40字节是TCP头部，不包含应用程序数据 分析IP头部： 十六进制数 十进制表示 IP头部信息 0x4 4 IP 0x5 5 头部长度为5个32位(20字节) 0x10 TOS选项中最小延时服务被开启 0x003c 60 数据报总长度，60字节 0x3174 数据报标识 0x4 设置了禁止 0x000 0 分片偏移 0x40 64 TTL被设为64 0x06 6 协议字段为6，表示上层协议是T 0x0b36 IP头部校验和 0x7f000001 32位源端IP地址127.0.0.1 0x7f000001 32位目的端IP地址127.0.0.1 由此可见，IPv4头部结构和分析的完全吻合，并且知道了telnet服务选择使用具有最小延时的服务，并且默认使用的传输层协议是TCP协议，并且这个IP数据报没有分片，因为它没有携带任何应用程序数据。 IP分片 第一个IP分片长度1500字节，IP头部设置了MF标志 第二个IP分片长度21字节，没有设置MF标志，因为已经是最后一个分片 需要注意的是：第二个IP分片里面没有ICMP的头部信息，因为IP模块重组ICMP报文的只需要一份ICMP头部信息 通过抓包来分析IP分片 ping www.baidu.com -s 1473 #指定放1473字节的数据 抓包的IP数据包如下： 这两个数据包标识值都是46843，说明他们是同一个IP数据报的分片。第一个分片的片偏移值是0，而第二个是1480。第一个分片设置了MF标志标识(flags[+])还有后续分片,第二个没设置说明是最后一个分片。两个分片的长度分别是1500和21字节。 由此可见，通过tcpdump抓包的分析和图片的分析完全一致。 IP路由IP协议的核心任务是数据报的路由，也就是决定数据报到目标机器的路径。 工作流程图 此图的具体分析可以参考游双老师的《Linux高性能服务器编程》P23 路由机制首先了解一下路由表，可以用route命令或者netstat查看 各个字段的解释： 接下来需要考虑的问题：路由表如何按照IP地址进行分类？或者说给定数据报的IP地址，将匹配路由表中的哪一项？这也就是IP的路由机制，有三个步骤。 查找路由表中和数据报的目标IP地址完全匹配的主机IP地址。如果找到，就使用路由项，没找到就跳转步骤2 查找路由表中和数据报的目标IP地址具有相同网路ID的网络IP地址(例如route命令展示的路由表的第三项)，如果找到就使用该路由项，没找到就跳转步骤3 选择默认路由项，这通常意味着数据报的下一跳路由是网关 也就是说，对于本机，所有发送到IP地址为192.168.152.*的机器的IP数据报都可以直接发送到目标机器，而所有访问因特网的请求都将通过网关来转发。 路由表更新可以用route命令来修改路由表(路由缓存 加-C选项) sudo route add -host 192.168.152.1 dev ens33 添加主机192.168.152.1对应的路由项，以后所有从本机发送到192.168.152.1的IP数据报将通过网卡ens33直接发送到目标机器的接收网卡。 sudo route del -net 192.168.152.0 netmask 255.255.255.0 删除网络192.168.152.0对应的路由项，这样主机就无法访问该局域网上的任何其他机器 sudo route del default 删除默认路由项，这样就无法访问因特网 通过route命令和其他工具修改的路由表，都是静态的路由更新方式。对于大型路由器，通常是通过BGP、RIP、OSPF等协议来发现路径，并更新自己的路由表，这样式动态的、自动的。 IP转发路由器都能执行数据报的转发操作，而主机一般只能发送和接收数据报，因为主机上/proc/sys/net/ipv4/ip_forward内核参数默认被设置为0。 可以修改这个参数使主机具有数据报转发能力 1.用root身份 sudo su 2.echo 1 &gt; /proc/sys/net/ipv4/ip_forward 路由器或主机进行数据报转发的操作： 检查数据报头部的TTL值，为0就丢弃 查看数据报头部的严格源路由选择项。如果该选项被设置，就检测数据报的目标IP是否是本机的某个IP地址，如果不是，则发送一个ICMP源站选路失败报文给发送端。 如果有必要，就给源端发送一个ICMP重定向报文，以告诉它一个更合理的下一个路由器 将TTL值减1 处理IP头部选项 如果有必要，则执行IP分片操作 重定向 重定向报文类型值是5，代码字段有4个可选值，代表不同的重定向类型。 /proc/sys/net/ipv4/conf/all/send_redirects内核参数指定是否允许发送ICMP重定向报文 /proc/sys/net/ipv4/conf/all/accept_redirects内核参数指定是否允许接收ICMP重定向报文 一般，主机只能接收，路由器只能发送。 IPv6（RFC 2460）不仅解决了IPv4地址不够用的问题，还做了很大的改进。比如 增加了多播和流的功能，为网络上多媒体内容的质量提供精细的控制 引入自动配置功能，使得局域网管理更方便 增加专门的网络安全功能 4位版本号：指定IP协议的版本。对IPv6来说，值是6 8位通信类型：指定数据流通信类型或优先级，和IPv4中的TOS类似 20位流标签：IPv6新增加的字段，用于某些对连接的服务质量有特殊要求的通信，比如音频或视频等实时数据传输 16位净荷长度：IPv6扩展头部和应用程序数据长度之和，不包括固定头部长度 8位下一个包头：指出紧跟IPv6固定头部后的包头类型，如扩展头或某个上层协议头 8位跳数限制：类似于IPv4中的TTL IPv6用128位(16字节)来表示IP地址，IP地址总数达到2^128个 32位表示的IPv4地址一般用点分十进制来表示，而IPv6地址一般用十六进制字符串来表示 “FE80:0000:0000:0000:1234 :5678:0000:0012”用：分割成8组，每组16位 “FE80:​:1234 :5678:0000:0012​” 零压缩法——省略连续的、全零的组，一个地址中只能用一次，所以后面的零没压缩 IPv6扩展头部","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"DNS","date":"2019-03-07T01:23:40.000Z","path":"2019/03/DNS/","text":"DNS工作原理DNS是一套分布式的域名服务系统。每个DNS服务器上都存放着大量的机器名和IP地址的映射，并且是动态更新的。众多网络客户端程序都使用DNS协议来向DNS服务器查询目标主机的IP地址。 DNS查询和应答报文详解 16位标识：标记一对DNS查询和应答，以此区分一个DNS应答是哪个DNS查询的回应 16位标记：协商具体的通信方式和反馈通信状态。 标志字段细节如下： QR：查询/应答标志。0表示这是一个查询报文，1表示这个一个应答报文 opcode：定义查询和应答的类型。0表示标准查询，1表示反向查询(由IP获得域名)，2表示请求服务器状态 AA：授权应答标志，仅由应答报文使用。1表示域名服务器是授权服务器 TC：截断标志，仅当DNS报文使用UDP服务时使用，因为UDP数据报有长度限制，所以过长的DNS报文将被截断。1表示DNS报文超过512字节，并被截断。 RD：递归查询标志。1表示执行递归查询，即如果目标DNS服务器无法解析某个主机名，则它将向其他DNS服务器继续查询，如此递归，知道获得结果并把该结果返回给客户端。0表示执行迭代查询，即如果目标DNS服务器无法解析某个主机名，则它将自己知道的其他DNS服务器的IP地址返回给客户端，以供客户端参考 RA：允许递归标志，仅供应答报文使用,1表示支持递归查询 zero：这3位未用，必须都置0 rcode：4位返回码，表示应答的状态。常用值0（无错误），3（域名不存在） 接下来的4个字段分别指出DNS报文的最后4个字段的资源记录数目。对查询报文而言，一般包含一个查询问题，而应答资源记录数、授权资源记录数和额外资源记录数则为0。应答报文的应答资源记录数则至少为1，而授权资源记录数和额外资源记录数可为0或非0。 查询问题的格式如下： 查询名：以一定的格式封装了要查询的主机域名。 查询类型：表示如何执行查询操作 类型A：值为1，表示获取目标主机的IP地址 类型CNAME：值为5，表示获得目标主机的别名 类型PTR：值为12，表示反向查询 查询类：通常是1，表示获取因特网地址（IP地址） 应答字段、授权字段和额外信息字段都使用资源记录格式。 资源记录格式如下： 域名：该记录中与资源对应的名字，其格式和查询问题中的查询名字段相同 类型和类字段与DNS查询问题的对应字段相同 生存时间：表示该查询记录结果可被本地客户端程序缓存多长时间，单位是秒 资源数据长度和资源数据字段的内容取决于类型字段。对类型A而言，资源数据是 32位的IPv4地址，资源数据长度时4(字节)。 访问DNS服务Linux下使用/etc/resolv.conf文件来存放DNS服务器的IP地址 Linux下常用的访问DNS服务器的客户端程序是host，host使用DNS协议和DNS服务器通信 -t选项告诉DNS协议使用哪种查询类型，这里用A，通过域名查询IP地址 由结果可见，www.baidu.com是www.a.shifen.com.的别名，并且该机器名对应两个IP地址。 tcpdump抓包 这两个数据包开始的”IP”指出，它们后面的内容是IP数据包 tcpdump以“IP 地址.端口号”的形式来描述通信的某一端；以”&gt;”表示数据传输方向，”&gt;”前面是源端，后面是目的端。 由此可见第一个数据包是从我的虚拟机(IP为”192.168.152.129”)向其首选DNS服务器(IP地址是192.168.152.2)发送的DNS查询报文(目标端口53是DNS服务器使用的端口)，第二个数据包是服务器反馈的DNS应答报文。 在第一个数据包中，数值61258是DNS查询报文的16位标识值，因此该值也出现在应答报文中。“+“表示开启递归查询标志，”A?“表示使用A类型的查询方式。”www.baidu.com&quot;是DNS查询问题中的查询名。括号中的数值31是DNS查询报文的长度(以字节为单位)。 第二个数据包中的 3/0/0 表示该报文中包含3个应答资源记录、0个授权资源记录、0个额外信息记录。后面的三项就是表示3个应答资源记录，该报文长度时90字节。 书上没有展示-x之后的效果，自己试了一下 由于抓取的是IP数据包，因此还封装了IP头和UDP头，定位DNS数据包不太容易。 根据DNS查询报文的标识值10807，算出16进制0x2a37，在数据包中能找到2a37 观察2a37后两个字节0x0100代表DNS查询标志字段，对比DNS标志字段的详细信息可见第7位(从0开始)正是RD字段，1表示执行递归查询。接下来两个字节0x0001表示1个问题个数，然后六个字节都是0x00，表示0个应答资源记录、0个授权资源记录、0个额外资源数目。然后分析遇到了问题(很难受，先码上吧，以后解决)。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"tcpdump","date":"2019-03-06T13:18:10.000Z","path":"2019/03/tcpdump/","text":"码上一些tcpdump的选项，方便自己查看。 -n 使用IP地址表示主机，而不是主机名；使用数字表示端口号，而不是服务名称 -i 指定要监听的网卡接口。”-i any”表示抓取所有网卡接口上的数据包 -v 输出一个稍微详细的信息，例如，显示IP数据包中的TTL和TOS信息 -t 不打印时间戳 -e 显示以太网帧头部信息 -c 仅抓取指定数量的数据包 -x 以十六进制数显示数据包的内容，但不显示包中以太网帧的头部信息 -X 与-x类似，不过还打印每个十六进制字节对应的ASCII字符 -XX 与-X相同，不过还打印以太网帧的头部信息 -s 设置抓包时的抓取长度。4.0版本之前默认68字节，4.0之后的版本默认65535 -S 以绝对值来显示TCP报文段的序号,而不是相对值 -w 将tcpdump的输出以特殊的格式定向到某个文件 -r 从文件读取数据包信息并显示之 除了使用选项之外，tcpdump还支持用表达式来进一步过滤数据包。 表达式操作数分为3种：类型、方向、协议 类型，解释其后面紧跟着的参数的含义。支持的类型有host、net、port和portrange 比如要抓取整个1.2.3.0/255.255.255.0网络上的数据包，可以用 tcpdump net 1.2.3.0/24 方向，src指定数据包的发送端，dst指定数据包的目的端 比如要抓取进入端口1234的数据包 tcpdump dst port 1234 协议，指定目标协议，比如要抓取所有ICMP数据包 tcpdump icmp 可以用逻辑操作符组织上面的操作数 支持 and(&amp;&amp;) 、or(||)、not(!) 例如抓取来自主机1.2.3.4，目标端口是1234或者2048的数据包 tcpdump ‘src 1.2.3.4 and (dst port 1234 or 2048)’ 需要注意的是：在使用括号进行分组的时候，需要用单引号将其括住或者用’&#39;进行转义，避免被shell所解释 直接使用数据包中的部分协议字段的内容来过滤数据包 例如，只抓取TCP同步报文段 tcpdump ‘tcp[13] &amp; 2 != 0’ ＃TCP头部的第14个字节的第二个位正是SYN tcpdump ‘tcp[tcpflags] &amp; tcp-syn != 0’","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"常用工具","slug":"常用工具","permalink":"https://oldbuffalo.github.io/tags/%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7/"}]},{"title":"ARP协议分析","date":"2019-03-06T12:22:07.000Z","path":"2019/03/ARP协议分析/","text":"ARP协议工作原理ARP协议是TCP/IP栈中数据链路层很重要的一个协议，能实现任意网络层地址到任意物理地址的转换，比如ip地址到MAC地址的转换。ARP通信在TCP连接之前就建立完成。 工作原理：主机向自己所在的网络广播一个ARP请求，该请求包含目标机器的网络地址。此网络中的其他极其都将收到这个请求，但只有被请求的目标机器会回应一个ARP应答，其中包含自己的物理地址。 以太网ARP请求/应答报文详解 1.硬件类型字段定义物理地址的类型，值为1表示MAC地址 2.协议类型字段表示要映射的协议地址类型，值为0x800,表示IP地址 3.硬件地址长度字段和协议地址长度字段，单位是字节，对MAC地址来说，长度为6，对IP(v4)地址来说，长度为4 4.操作字段指出4种操作类型：ARP请求（值为1）、ARP应答（值为2）、RARP请求（值为3）、RARP应答（值为4） 5.最后4个字段指定通信双方的以太网地址和IP地址。 ARP高速缓存在现实情况中，ARP的工作方式就是，先在ARP缓存中找，找不到了再在局域网上“发帖求助”。也就是说ARP维护一个高速缓存，其中包含经常访问或者最近访问的机器的IP地址和物理地址的映射。 这样避免了重复的ARP请求，提高了发送数据包的效率 Linux下可以用arp命令来查看和修改ARP高速缓存 使用 arp 当没有参数时打印（到屏幕上）当前表中的内容。 arp -a 以BSD风格输出ARP缓存中的内容 sudo arp -d ip #删除该ip对应的主机所对应的ARP缓存项 sudo arp -s ip MAC #添加该ip对应的主机所对应的ARP缓存项 使用场景ARP协议使用场景：网络层使用IP地址寻址一台机器，但是数据链路层使用物理地址来寻址一台机器，因此网络层必须先将目标机器的IP地址转化成物理地址，才能使用数据链路层提供的服务。 RARP协议使用场景：仅用于网络上的某些无盘工作站，因为缺乏存储设备，无盘工作站无法记住自己的IP地址，但它们可以利用网卡上的物理地址来向网络管理者（服务器或网络管理软件）查询自身的IP地址。运行RARP服务的网络管理者通常存有该网络上的所有机器的物理地址到IP地址的映射。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"}]},{"title":"epoll","date":"2018-12-01T13:52:13.000Z","path":"2018/12/epoll/","text":"模型特点1.不同于select和poll,epoll采用回调函数的方式获取文件描述符的就绪状态(主动通知)2.采用红黑树管理epoll_event结构体3.内核维护一个就绪队列，只传出就绪的文件描述符4.有ET(边缘触发)和LT(水平触发)，而select和poll都只有LT5.同样也突破了select并发量的限制 具体使用内核事件表epoll把用户关心的文件描述符上的事件放在内核里的一个事件表，不同于select、poll每次调用都要重复传入文件描述符集或事件集，因此epoll需要一个额外的文件描述符来唯一标识内核中的这个事件表，这个文件描述符用epoll_create函数来创建。 int epoll_create(int size)； size参数现在不起作用，只是给内核一个提示，告诉它内核事件表需要多大，该函数返回的文件描述符将作用于其他所有epoll系统调用的第一个参数，以指定要访问的内核事件表 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) epfd：为epoll_creat的句柄op：表示动作，用3个宏来表示： EPOLL_CTL_ADD(注册新的fd到epfd) EPOLL_CTL_MOD(修改已经注册的fd的监听事件) EPOLL_CTL_DEL(从epfd删除一个fd) event：告诉内核需要监听的事件struct epoll_event{​ __uint32_t events; //监控的事件​ epoll_data_t data; //用户数据};epoll支持的事件类型和poll基本相同，表示epoll事件类型的宏是在poll对应的宏前加上“E”，但epoll有两个额外的事件类型(EPOLLET和EPOLLONESHOT)，这两个宏对于epoll的高效运作很重要。 EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里 typedef union epoll_data {​ void *ptr; //指定与fd相关的用户数据​ int fd;​ uint32_t u32;​ uint64_t u64;} epoll_data_t; int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout) 成功返回就绪的文件描述符个数，失败返回-1并设置errno epoll_wait函数如果检测到事件，就将所有就绪的时间从内核事件表中复制到它的第二个参数events指向的数组，这个数组只用于输出epoll_wait检测到的就绪事件，而不像select、poll的数组参数既用于传入用户注册事件，又用于输出内核检测到的就绪事件，这就大大提高了应用程序索引就绪文件描述符的效率。 对于select、poll，需要遍历整个数组找出就绪的文件描述符，然后判断是什么类型的事件发生 O(n) 对于epoll,数组中的所有文件描述符都是就绪的，直接可以判断是什么类型的事件发生 O(1) ET和LTLT是默认的工作模式，这种模式下epoll相当于一个效率较高的poll.当epoll内核事件表宏注册了一个文件描述符EPOLLET时，采用ET模式LT：只要一个文件描述符上的事件一次没有处理完，会在以后调用epoll_wait时次次返回就绪ET：只返回一个就绪，不管处理完还是没有处理完 举个例子:1.某个客户端向服务器传输了2KB的数据2.服务器epoll_wait()返回，然后读了1KB3.两种模式比较 如果是LT模式下，下次epoll_wait()还会返回，然后继续读，直到数据被处理完毕 如果是ET模式下，下次epoll_wait()会阻塞，因此ET模式只适用于非阻塞的socket，需要循环读取保证所有数据被处理完毕。 设置非阻塞 1.socket创建指定选项 2.fcntl 3.iocnlsocket ET模式很大程序上降低了同一个epoll事件被重复触发的次数，效率更高。但是LT能保证数据读取完整，ET读取数据如果被信号打断，可能读取不全。 对于监听的 sockfd，最好使用水平触发模式，边缘触发模式会导致高并发情况下，有的客户端会连接不上。如果非要使用边缘触发，可以用 while 来循环 accept()。 ET和LT 为什么ET模式下socket要设置成非阻塞？如果是阻塞 connfd 的边缘触发，如果不一次性读取一个事件上的数据，会干扰下一个事件，所以必须在读取数据的外部套一层循环，这样才能完整的处理数据。但是外层套循环之后会导致另外一个问题：处理完数据之后，程序会一直卡在 recv() 函数上，因为是阻塞 IO，如果没数据可读，它会一直等在那里，直到有数据可读。但是这个时候，如果用另一个客户端去连接服务器，服务器就不能受理这个新的客户端了。 如果是非阻塞 connfd 的边缘触发，和阻塞版本一样，必须在读取数据的外部套一层循环，这样才能完整的处理数据。因为非阻塞 IO 如果没有数据可读时，会立即返回，并设置 errno。这里我们根据 EAGAIN 和EWOULDBLOCK 来判断数据是否全部读取完毕了，如果读取完毕，就会正常退出循环了。 EPOLLONESHOT (Linux高性能服务器编程P157)即使我们使用ET模式，那一个socket上的事件也有可能被触发多次，这在并发程序中会引起一个问题。比如一个线程读取socket上的数据后开始处理这些数据，而在数据的处理过程中该socket上又有新数据可读，此时另外一个线程来读取这些数据，于是就出现了两个线程同时操作一个socket的情况。而我们期望一个socket连接在任意时刻都只被一个线程处理，这一点我们可以用EPOLLONESHOT事件实现。 对于注册了EPOLLONESHOT事件的文件描述符，操作系统最多触发其注册的读、写、异常中的一个，并且只触发一次，除非重新用epoll_ctl重置该文件描述符的EPOLLONESHOT事件。因此，每次处理完都需要立即重置这个socket上的EPOLLONESHOT事件，以确保这个socket下一次可读时，EPOLLIN能被触发。 注意：监听socket上不能注册EPOLLONESHOT，否则只能处理一个客户端的连接 EPOLLONESHOT 对于EPOLLOUT事件的一些理解在一次发送大量数据（超过发送缓冲区大小）的情况下，如果使用阻塞方式，程序一直阻塞，直到所有的数据都写入到缓冲区中。例如，要发送M字节数据，套接字发送缓冲区大小为B字节，只有当对端向本机返回ack表明其接收到大于等于M-B字节时，才意味着所有的数据都写入到缓冲区中。很明显，如果一次发送的数据量非常大，比如M=10GB、B=64KB，则：1）一次发送过程中本机线程会在一个fd上阻塞相当长一段时间，其他fd得不到及时处理；2）如果出现发送失败，无从得知到底有多少数据发送成功，应用程序只能选择重新发送这10G数据，结合考虑网络的稳定性，只能呵呵；总之，上述两点都是无法接受的。因此，对性能有要求的服务器一般不采用阻塞而采用非阻塞。 采用非阻塞套接字一次发送大量数据的流程： 1.使劲往发送缓冲区中写数据，直到返回不可写 2.等待下一次缓冲区可写 3.要发送的数据写完 其中2可以有两种方式 查询式，程序不停地查询是否可写 程序去干其他的事情（多路分离器的优在），等出现可写事件后再接着写；很明显方式b）更加优雅 例如需要将一个10G大小的文件返回给用户，那么简单send这个文件是不会成功的。这个场景下，send 10G的数据，send返回值不会是10G，而是大约256k，表示你只成功写入了256k的数据。接着调用send，send就会返回EAGAIN，告诉你socket的缓冲区已经满了，此时无法继续send,需要重新注册EPOLLOUT事件，进行新一轮的监听。此时异步程序的正确处理流程是调用epoll_wait，当socket缓冲区中的数据被对方接收之后，缓冲区就会有空闲空间可以继续接收数据，此时epoll_wait就会返回这个socket的EPOLLOUT事件，获得这个事件时，你就可以继续往socket中写出数据。 EPOLLOUT事件就是以事件的方式通知用户程序，可以继续往缓冲区写数据了。 优缺点分析缺点：1.在高并发高活跃的情况下，对内部树进行频繁的操作，效率可能不如select和poll2.实现的是伪并发，对于客户端的请求只能一个一个处理，并且如果处理流程过长，影响用户体验。 优点:1.非常适用于高并发低活跃的情况下2.采用回调函数的方式传出fd，高效3.直接传出就绪的文件描述符，减少了索引就绪文件描述符的时间 4.真正突破了文件描述符的限制，不采用轮询，不会因为fd数量的增长而导致效率下降5.有ET工作模型和EPOLLONESHOT，进一步提升了工作效率 LT工作模型下的服务器(客户端同多进程模型)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115#include&lt;stdio.h&gt;#include&lt;ctype.h&gt;#include&lt;string.h&gt;#include&lt;unistd.h&gt;#include&lt;sys&#x2F;types.h&gt;#include&lt;sys&#x2F;socket.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;sys&#x2F;epoll.h&gt;#include&lt;arpa&#x2F;inet.h&gt;#define PORT 1234#define LISTEN 128#define IP 16#define BUFSIZE 1500#define MAXSIZE 200000int main()&#123; struct sockaddr_in addr,clientaddr; char ip[IP] &#x3D; &#123;0&#125;; bzero(&amp;addr,sizeof(addr)); addr.sin_family &#x3D; AF_INET; addr.sin_addr.s_addr &#x3D; htonl(INADDR_ANY); addr.sin_port &#x3D; htons(PORT) ; int Serverfd; Serverfd &#x3D; socket(AF_INET,SOCK_STREAM,0); if(Serverfd &#x3D;&#x3D; -1)&#123; perror(&quot;Socket Create Faile&quot;); exit(-1); &#125; printf(&quot;Serverfd:%d\\n&quot;,Serverfd); if(-1 &#x3D;&#x3D; bind(Serverfd,(struct sockaddr*)&amp;addr,sizeof(addr)))&#123; perror(&quot;BIND ERROR&quot;); exit(-1); &#125; if(-1 &#x3D;&#x3D; listen(Serverfd,LISTEN))&#123; perror(&quot;LISTEN ERROR&quot;); exit(-1); &#125; printf(&quot;epoll Server is running\\n&quot;); struct epoll_event ent[MAXSIZE]; struct epoll_event tmp; int epfd,ready,nlen; char buf[BUFSIZE]; for(int i &#x3D; 0;i&lt;MAXSIZE;i++)&#123; ent[i].data.fd &#x3D; -1; &#125; epfd &#x3D; epoll_create(MAXSIZE); &#x2F;&#x2F;红黑树 tmp.data.fd &#x3D; Serverfd; tmp.events &#x3D; EPOLLIN; epoll_ctl(epfd,EPOLL_CTL_ADD,Serverfd,&amp;tmp); while(1)&#123; ready &#x3D; epoll_wait(epfd,ent,MAXSIZE,-1); while(ready)&#123; if(ent[--ready].data.fd &#x3D;&#x3D; Serverfd)&#123; int Clientfd; int nlen &#x3D; sizeof(clientaddr); Clientfd &#x3D; accept(Serverfd,(struct sockaddr*)&amp;clientaddr,&amp;nlen); if(Clientfd &#x3D;&#x3D; -1)&#123; perror(&quot;Accpet Error&quot;); exit(-1); &#125; else&#123; inet_ntop(AF_INET,&amp;clientaddr.sin_addr.s_addr,ip,sizeof(ip)); printf(&quot;IP:%s Port:%d Clientfd:%d\\n&quot;,ip,clientaddr.sin_port,Clientfd); tmp.data.fd &#x3D; Clientfd; tmp.events &#x3D; EPOLLIN; epoll_ctl(epfd,EPOLL_CTL_ADD,Clientfd,&amp;tmp); &#125; &#125; else&#123; if(ent[ready].data.fd !&#x3D; -1)&#123; nlen &#x3D; read(ent[ready].data.fd,buf,sizeof(buf)); if(0 &#x3D;&#x3D; nlen)&#123; epoll_ctl(epfd,EPOLL_CTL_DEL,ent[ready].data.fd,NULL); close(ent[ready].data.fd); printf(&quot;Clientfd:%d客户端终止\\n&quot;,ent[ready].data.fd); ent[ready].data.fd &#x3D; -1; &#125; else&#123; for(int i &#x3D; 0;i&lt;nlen;i++)&#123; buf[i] &#x3D;toupper(buf[i]); &#125; write(ent[ready].data.fd,buf,nlen); &#125; &#125; &#125; &#125; &#125; close(Serverfd); return 0;&#125;","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"},{"name":"IO复用","slug":"IO复用","permalink":"https://oldbuffalo.github.io/tags/IO%E5%A4%8D%E7%94%A8/"}]},{"title":"poll","date":"2018-11-30T13:51:59.000Z","path":"2018/11/poll/","text":"模型特点1.和select类似，但是突破了并发量的限制。2.采用的依旧是轮询3.采用struct pollfd结构体记录fd的状态 具体使用int poll(struct pollfd *fds, nfds_t nfds, int timeout); 成功返回就绪的文件描述符个数，失败返回-1并设置errnofds:结构体数组首地址nfds:数组元素个数timeout：3种情况 -1 永远等待 0 立即返回 大于0 等待指定数目的毫秒数 struct pollfd {​ int fd; //文件描述符​ short events; //监控的事件​ short revents; //监控事件中满足条件返回的事件}; 如果不再监控某个文件描述符时，可以把pollfd中的fd设置为-1，poll不再监控此fd,该pollfd中的revents返回0 每次poll调用都会自动把上次的revents清空 优缺点分析优点:1.突破了select并发量的限制，但是需要设置进程最大打开的文件描述符个数2.做到了传入传出分离，更易于操作 缺点：1.采用轮询，随着fd的线性增长，效率呈线性下降2.实现的是伪并发，对于客户端的请求只能一个一个处理，并且如果处理流程过长，影响用户体验。3.每次调用poll传入时都需要从用户空间拷贝到内核空间，poll返回时传出结果从内核拷贝用用户，有着很大的拷贝开销，并且很多时候是重复的工作。 4.只支持毫秒级别的精度 注意点:1.在我的虚拟机上Ubuntu16.04一个进程默认的最大打开文件描述符是1024，为了实现poll的高并发需要自己修改这个值。修改文件描述符个数方法 2.在判断对应的事件是否发生的时候用位与操作。 为什么不用相等？加入我注册的事件是POLLIN(这是POLLRDNORM|POLLRDBAND)，这时候POLLRDNORM触发了，如果是相等就不对了。 3.应用程序需要根据recv调用的返回值来区分socket上接收到的是有效数据还是对方关闭连接的请求，并做相应的处理。自Linux内核2.6.17开始，GNU为poll增加了一个POLLRDHUP事件，它在socket上接收到对方关闭连接的请求之后触发，这为区分上述的两种情况提供了一种就简便方法。但在使用POLLRDHUP事件的时候，需要在代码最开始定义_GNU_SOURCE。 4.poll在事件触发之后，要对revent进行清空操作。 poll聊天室练习 客户端 服务器 服务器代码(客户端代码同多进程模型)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130#include&lt;stdio.h&gt;#include&lt;sys&#x2F;time.h&gt;#include&lt;sys&#x2F;types.h&gt;#include&lt;sys&#x2F;socket.h&gt;#include&lt;string.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;arpa&#x2F;inet.h&gt;#include&lt;ctype.h&gt;#include&lt;pthread.h&gt;#include&lt;sys&#x2F;select.h&gt;#include&lt;poll.h&gt;#define IPSIZE 16#define BUFSIZE 1500#define POLLFD_SIZE 1500#define PORT 1234#define LISTEN_SIZE 128int main()&#123; struct sockaddr_in addr, clientaddr; int ListenSock; char ip[IPSIZE]; bzero(&amp;addr,sizeof(addr)); addr.sin_family &#x3D; AF_INET; addr.sin_addr.s_addr &#x3D; htonl(INADDR_ANY); addr.sin_port &#x3D; htons(PORT); ListenSock &#x3D; socket(AF_INET,SOCK_STREAM,0); if(ListenSock &#x3D;&#x3D; -1)&#123; perror(&quot;SCOKET CALL FAILED&quot;); exit(-1); &#125; if(bind(ListenSock,(struct sockaddr *)&amp;addr,sizeof(addr)) &#x3D;&#x3D; -1)&#123; perror(&quot;BIND CALL FAILED&quot;); exit(-1); &#125; if(listen(ListenSock,LISTEN_SIZE) &#x3D;&#x3D; -1)&#123; perror(&quot;LISTEN CALL FAILED&quot;); exit(-1); &#125; printf(&quot;Poll Server is Running\\n&quot;); char buf[BUFSIZE]; int ready,nlen; struct pollfd PollArr[POLLFD_SIZE]; &#x2F;&#x2F;memset(ClientSockArr,-1,sizeof(ClientSockArr)); for(int i &#x3D; 0;i&lt;POLLFD_SIZE;i++) PollArr[i].fd &#x3D; -1; PollArr[0].fd &#x3D; ListenSock; PollArr[0].events &#x3D; POLLIN; while(1)&#123; ready &#x3D; poll(PollArr,POLLFD_SIZE,-1); if(ready &#x3D;&#x3D; -1)&#123; perror(&quot;POLL Filed&quot;); exit(-1); &#125; while(ready)&#123; if(PollArr[0].revents &amp; POLLIN)&#123;&#x2F;&#x2F;ListenSock就绪 int addrsize &#x3D; sizeof(clientaddr); int ClientSock; ClientSock &#x3D; accept(ListenSock,(struct sockaddr* )&amp;clientaddr,&amp;addrsize); if(ClientSock &#x3D;&#x3D; -1) perror(&quot;ACCEPT ERROR&quot;); if(ClientSock&gt;0)&#123; inet_ntop(AF_INET,&amp;clientaddr.sin_addr.s_addr,ip,sizeof(ip)); printf(&quot;IP:%s Port:%d ClientSock:%d\\n&quot;,ip,clientaddr.sin_port,ClientSock); &#x2F;&#x2F;加入到数组当中 for(int i &#x3D; 1;i&lt;POLLFD_SIZE;i++)&#123; if(PollArr[i].fd &#x3D;&#x3D; -1)&#123; PollArr[i].fd &#x3D; ClientSock; PollArr[i].events &#x3D; POLLIN; break; &#125; &#125; &#125; &#125; else&#123; &#x2F;&#x2F;遍历客户端数组找出哪个有事件发生 for(int i &#x3D; 1;i&lt;POLLFD_SIZE;i++)&#123; if(PollArr[i].fd !&#x3D; -1)&#123; if(PollArr[i].revents &amp; POLLIN )&#123; &#x2F;&#x2F;判断是否就绪 nlen &#x3D; read(PollArr[i].fd,buf,sizeof(buf)); if(nlen &#x3D;&#x3D; 0) &#123;&#x2F;&#x2F;客户端关闭 close(PollArr[i].fd); printf(&quot;ClientSock:%d断开连接\\n&quot;,PollArr[i].fd); PollArr[i].fd &#x3D; -1; break; &#125; for(int j &#x3D; 0;j&lt;nlen;j++)&#123; buf[j] &#x3D; toupper(buf[j]); &#125; write(PollArr[i].fd,buf,nlen); break; &#125; &#125; &#125; &#125; ready--; &#125; &#125; close(ListenSock); return 0;&#125;","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"},{"name":"IO复用","slug":"IO复用","permalink":"https://oldbuffalo.github.io/tags/IO%E5%A4%8D%E7%94%A8/"}]},{"title":"Linux下的select模型","date":"2018-11-28T13:51:24.000Z","path":"2018/11/linux下的select模型/","text":"模型特点1.select能监听的文件描述符个数受限于FD_SETSIZE,一般为10242.采用的是轮询的工作原理3.文件描述符采用fd_set类型管理 具体使用int select(int nfds, fd_set *readfds, fd_set *writefds,fd_set *exceptfds, struct timeval *timeout);成功返回就绪的文件描述符个数，失败返回-1并设置errno 阻塞期间，程序收到信号，select立即返回-1，设置errno为EINTR nfds:通常被设置成select监听的所有文件描述符最大值+1，因为文件描述符从0开始。 为了效率考虑，这个参数会告诉内核检测前多少个文件描述符的状态 readfds:监控有读数据到达文件描述符集合，传入传出参数 writefds：监控写数据到达文件描述符集合，传入传出参数 exceptfds：监控异常发生达文件描述符集合,如带外数据到达异常，传入传出参数 通过这3个参数传入自己感兴趣的文件描述符，select调用返回时，内核将修改它们来通知应用程序哪些文件描述符已经就绪。 timeout：定时阻塞监控时间(微秒) struct timeval { long tv_sec; //seconds long tv_usec; //microseconds}; 3种情况: NULL，永远等下去 设置timeval，等待固定时间 设置timeval里时间均为0，检查描述字后立即返回，轮询。 当然，如果readfds，writefds，exceptfds三个参数都传空，就相当于一个高配版的sleep() void FD_CLR(int fd, fd_set *set); 把文件描述符集合里fd清0int FD_ISSET(int fd, fd_set *set); 测试文件描述符集合里fd是否置1void FD_SET(int fd, fd_set *set); 把文件描述符集合里fd位置1void FD_ZERO(fd_set *set); 把文件描述符集合里所有位清0 fd_set假设是一个int类型的数组，那么第一个元素就可以监控0-31文件描述符，第二个元素监控32-63，以此类推 现在假设文件描述符3,4,5已经加入readfds 此时3,4就绪，那么select返回值为2，readfds传出3,4 由于readfds是传入传出参数，因此需要准备一个需要监听的fd_set，每次调用select的时候都拷贝给它。 文件描述符就绪条件哪些情况文件描述符被认为可读、可写或者出现异常？ socket可读 socket内核接收缓存区中的字节数大于或等于其低水位标记SO_RCVLOWAT，此时可以无阻塞读这个socket socket通信的对方关闭连接，对socket读操作返回0 监听socket上有新的连接请求 socket上有未处理的错误。此时可以用getsockopt读取和清除该错误 socket可写 socket内核发送缓存区中的可用字节数大于或等于其低水位标记SO_SNDLOWAT。此时可以无阻塞地写该socket socket的写操作被关闭。对写操作被关闭的socket执行写操作将触发一个SIGPIPE信号 socket使用非阻塞connect连接成功或者失败(超时)之后 socket上有未处理的错误。此时可以用getsockopt读取和清除该错误 socket出现异常 socket上接收到带外数据 注意点1.每次调用select都需要给传入的集合重新复制。2.需要准备一个数据结构保存已连接的socket3.select第一个参数是文件描述符最大值加1，而不是个数的最大值+14.select也可以监控普通的文件描述符，例如标准输入(FILENO_STDIN)，int fileno(File*) 优缺点分析优点：1.单个进程实现伪并发，易于实现，轻量2.适合并发量不高，处理流程不长的情况。比如局域网中的某个服务。3.支持微妙级别的时间精度 缺点:1.每次都要对传入传出的集合重新拷贝赋值，操作麻烦2.并发量有1024的上限值3.采用轮询，随着fd的线性增长，效率呈线性下降4.实现的是伪并发，对于客户端的请求只能一个一个处理，并且如果处理流程过长，影响用户体验。5.传入传出参数每次调用select传入时都需要从用户空间拷贝到内核空间，select返回时传出结果从内核拷贝用用户，有着很大的拷贝开销，并且很多时候是重复的工作。 服务器代码(客户端代码同多进程模型)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134#include&lt;stdio.h&gt;#include&lt;sys/time.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;string.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;ctype.h&gt;#include&lt;pthread.h&gt;#include&lt;sys/select.h&gt;#define IPSIZE 16#define BUFSIZE 1500#define CLIENTSOCK_SIZE 1024#define PORT 1234#define LISTEN_SIZE 128int main()&#123; struct sockaddr_in addr, clientaddr; int ListenSock; char ip[IPSIZE]; bzero(&amp;addr,sizeof(addr)); addr.sin_family = AF_INET; addr.sin_addr.s_addr = htonl(INADDR_ANY); addr.sin_port = htons(PORT); ListenSock = socket(AF_INET,SOCK_STREAM,0); if(ListenSock == -1)&#123; perror(\"SCOKET CALL FAILED\"); exit(-1); &#125; if(bind(ListenSock,(struct sockaddr *)&amp;addr,sizeof(addr)) == -1)&#123; perror(\"BIND CALL FAILED\"); exit(-1); &#125; if(listen(ListenSock,LISTEN_SIZE) == -1)&#123; perror(\"LISTEN CALL FAILED\"); exit(-1); &#125; printf(\"Select Server is Running\\n\"); char buf[BUFSIZE]; fd_set set,oldset; int Max,ready,nlen; int ClientSockArr[CLIENTSOCK_SIZE]; //memset(ClientSockArr,-1,sizeof(ClientSockArr)); for(int i = 0;i&lt;CLIENTSOCK_SIZE;i++) ClientSockArr[i] = -1; FD_ZERO(&amp;oldset); FD_SET(ListenSock,&amp;oldset); Max = ListenSock; printf(\"ListenSock:%d\\n\",ListenSock); while(1) &#123; set = oldset; ready = select(Max+1,&amp;set,NULL,NULL,NULL); while(ready)&#123; if(FD_ISSET(ListenSock,&amp;set))&#123;//ListenSock就绪 int addrsize = sizeof(clientaddr); int ClientSock; ClientSock = accept(ListenSock,(struct sockaddr* )&amp;clientaddr,&amp;addrsize); if(ClientSock == -1) perror(\"ACCEPT ERROR\"); if(ClientSock&gt;0)&#123; inet_ntop(AF_INET,&amp;clientaddr.sin_addr.s_addr,ip,sizeof(ip)); printf(\"IP:%s Port:%d,ClientSock:%d\\n\",ip,clientaddr.sin_port,ClientSock); //加入到数组当中 for(int i = 0;i&lt;CLIENTSOCK_SIZE;i++)&#123; if(ClientSockArr[i] == -1)&#123; ClientSockArr[i] = ClientSock; if(ClientSockArr[i] &gt; Max) Max = ClientSockArr[i]; //加入到集合当中 FD_SET(ClientSockArr[i],&amp;oldset); break; &#125; &#125; &#125; &#125; else&#123; //遍历客户端数组找出哪个有事件发生 for(int i = 0;i&lt;CLIENTSOCK_SIZE;i++)&#123; if(ClientSockArr[i] != -1)&#123; if(FD_ISSET(ClientSockArr[i],&amp;set))&#123; //判断是否就绪 bzero(buf,sizeof(buf)); nlen = read(ClientSockArr[i],buf,sizeof(buf)); if(nlen == 0)&#123; //客户端关闭 这种方式检测客户端终止不好最好心跳机制 FD_CLR(ClientSockArr[i],&amp;oldset); close(ClientSockArr[i]); printf(\"Cilentfd:%d终止\\n\",ClientSockArr[i]); ClientSockArr[i] = -1; break; &#125; printf(\"%s\\n\",buf); for(int j = 0;j&lt;nlen;j++)&#123; buf[j] = toupper(buf[j]); &#125; write(ClientSockArr[i],buf,nlen); break; &#125; &#125; &#125; &#125; ready--; &#125; &#125; close(ListenSock); return 0;&#125; 处理带外数据","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"},{"name":"IO复用","slug":"IO复用","permalink":"https://oldbuffalo.github.io/tags/IO%E5%A4%8D%E7%94%A8/"}]},{"title":"linux下的多进程服务器模型","date":"2018-11-27T13:42:24.000Z","path":"2018/11/linux下的多进程服务器模型/","text":"整体思路服务器端完成的工作是将客户端传来的字符串，小写变大写，再返回给客户端父进程负责accept，每来一个connect就fork出一个子进程专门处理对应客户端的请求。 需要注意的问题1.fork子进程的时候继承父进程的文件描述符，需要关闭。2.客户端退出之后，对应的子进程也就终止，需要回收子进程。3.在回收子进程的过程中，利用信号捕捉SIGCHLD。在执行信号捕捉函数的时候，会导致accept调用失败。4.在多个子进程同时退出的时候，需要用waitpid循环回收。5.创建一根线程专门回收的时候，需要在主线程对SIGCHLD信号设置屏蔽字 服务器端代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124#include&lt;stdio.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;string.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;arpa/inet.h&gt;#include&lt;ctype.h&gt;#include&lt;pthread.h&gt;#include&lt;sys/wait.h&gt;#include&lt;signal.h&gt;void mywait(int n)&#123; pid_t wpid; while((wpid = waitpid(-1,NULL,WNOHANG)) &gt; 0)&#123; printf(\"pid为%d的进程被回收\\n\",wpid); &#125;&#125;void* jobs(void* argv)&#123; //捕捉信号 异步回收 pthread_detach(pthread_self()); struct sigaction act,oldact; act.sa_handler = mywait; act.sa_flags = 0; sigemptyset(&amp;act.sa_mask); sigaction(SIGCHLD,&amp;act,&amp;oldact); while(1) sleep(1);&#125;int main()&#123; struct sockaddr_in clientaddr; int addrsize; int ListenSock,ClientSock; char ip[16]; struct sockaddr_in addr; bzero(&amp;addr,sizeof(addr)); addr.sin_family = AF_INET; addr.sin_addr.s_addr = htonl(INADDR_ANY); addr.sin_port = htons(1234); ListenSock = socket(AF_INET,SOCK_STREAM,0); if(ListenSock == -1)&#123; perror(\"SCOKET CALL FAILED\"); exit(-1); &#125; if(bind(ListenSock,(struct sockaddr *)&amp;addr,sizeof(addr)) == -1)&#123; perror(\"BIND CALL FAILED\"); exit(-1); &#125; if(listen(ListenSock,128) == -1)&#123; perror(\"LISTEN CALL FAILED\"); exit(-1); &#125; printf(\"Server is Running\\n\"); char buf[100]; bzero(buf,sizeof(buf)); pthread_t tid; pthread_create(&amp;tid,NULL,jobs,NULL); //创建一个线程回收 sigset_t set,oldset; sigemptyset(&amp;set); sigaddset(&amp;set,SIGCHLD); sigprocmask(SIG_BLOCK,&amp;set,&amp;oldset); int nRes; pid_t pid; while(1)&#123; addrsize = sizeof(clientaddr); ClientSock= accept(ListenSock,(struct sockaddr* )&amp;clientaddr,&amp;addrsize); if(ClientSock &lt; 0)&#123; perror(\"ACCEPT ERROR\"); exit(-1); &#125; pid = fork(); //父进程 if(pid &gt; 0)&#123; inet_ntop(AF_INET,&amp;clientaddr.sin_addr.s_addr,ip,sizeof(ip)); printf(\"IP:%s Port:%d\\n\",ip,clientaddr.sin_port); close(ClientSock); &#125; //子进程 else if(pid == 0)&#123; close(ListenSock); while(1)&#123; nRes = read(ClientSock,buf,sizeof(buf)); if(nRes &lt; 0)&#123; perror(\"READ ERROR\"); exit(0); &#125; else if(nRes == 0)&#123;//客户端写端关闭 read返回值为0 这个进程终止 close(ClientSock); exit(-1); &#125; //大小写转换 for(int i = 0;i&lt;nRes;i++)&#123; buf[i] = toupper(buf[i]); &#125; write(ClientSock,buf,nRes); bzero(buf,sizeof(buf)); &#125; &#125; else&#123; perror(\"FORK CALL FAILED\"); exit(-1); &#125; &#125; close(ListenSock); return 0;&#125; 客户端代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include&lt;stdio.h&gt;#include&lt;sys/types.h&gt;#include&lt;sys/socket.h&gt;#include&lt;string.h&gt;#include&lt;unistd.h&gt;#include&lt;stdlib.h&gt;#include&lt;arpa/inet.h&gt;#define SERVER_IP \"127.0.0.1\"#define PORT 1234int main()&#123; struct sockaddr_in addr; bzero(&amp;addr,sizeof(addr)); addr.sin_family = AF_INET; inet_pton(AF_INET,SERVER_IP,&amp;addr.sin_addr.s_addr); addr.sin_port = htons(PORT); int ClientSock; ClientSock = socket(AF_INET,SOCK_STREAM,0); if(ClientSock == -1) &#123; perror(\"SCOKET CALL FAILED\"); exit(-1); &#125; if(-1 == connect(ClientSock,(struct sockaddr*)&amp;addr,sizeof(addr))) &#123; perror(\"CONNECT CALL FAILED\"); exit(-1); &#125; char buf[100]; //scanf(\"%s\",buf); int nRes; while(1) &#123; fgets(buf,sizeof(buf),stdin); //send(ClientSock,buf,sizeof(buf),0); write(ClientSock,buf,sizeof(buf)); nRes = read(ClientSock,buf,sizeof(buf)); if(nRes &gt; 0) &#123; printf(\"%s\",buf); &#125; bzero(buf,sizeof(buf)); &#125; close(ClientSock); return 0;&#125;","comments":true,"tags":[{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"},{"name":"服务器模型","slug":"服务器模型","permalink":"https://oldbuffalo.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A8%A1%E5%9E%8B/"},{"name":"进程","slug":"进程","permalink":"https://oldbuffalo.github.io/tags/%E8%BF%9B%E7%A8%8B/"}]},{"title":"Linux下的网络I/O模型","date":"2018-11-26T12:40:40.000Z","path":"2018/11/Linux下的网络IO模型 /","text":"在进行网络通信的过程中，接收方在读取数据的时候主要做了两件事情:1.等待数据准备好(从网络中抵达内核缓冲区) 2.数据从内核缓冲区拷贝到进程的用户缓冲区 概念区分1.同步/异步 在UNP中POSIX的定义是： 同步I/O操作导致请求进程阻塞，直到I/O操作完成 异步I/O操作不导致请求进程阻塞在我看来，同步就是发生调用之后等待结果的返回，异步就是不等待结果的返回，继而做别的事情 2.阻塞/非阻塞 阻塞和非阻塞关心的是调用发生之后获取调用结果时的状态。阻塞是指调用结果返回之前，当前线程挂起，知道结果返回。非阻塞则不挂起当前线程，采用轮询的方式查看调用结果是否返回。 举个例子 1.我准备烧一壶水，一直在水壶旁边等水开。(同步阻塞)2.我把水壶放好之后，就去做自己的事情，每隔一段时间来看看水开了没有(同步非阻塞)3.这次我用响水壶烧水，水开了之后自动就响，但是我比较傻，担心它不响，一直等水开(异步阻塞)4.我把响水壶放好之后，就去专心地做自己的事情，知道响水壶响了通知我去拿壶。(异步非阻塞)显然异步阻塞只是一种理论上的存在。在效率上看，异步显然明显优于同步。 网络模型1.阻塞型IO 2.非阻塞型IO 这里需要设置套接字的非阻塞选项 创建套接字的时候指定 socket(AF_INET, SOCK_STREAM | SOCK_NONBLOCK, IPPROTO_TCP) linux在一切皆文件 fcntl(sockfd, F_SETFL, fcntl(sockfd, F_GETFL, 0) |O_NONBLOCK） ioctl(sockfd, FIONBIO, 1); //1:非阻塞 0:阻塞 阻塞型IO和非阻塞型IO一般配合多进程或者多线程模型，一个客户端对应一个进程或线程，开销大。 3.IO复用(select、poll、epoll) 阻塞在IO模型调用函数上，等待对应的套接字的IO操作，可以监控多个套接字。IO复用一个进程就可以监控多个套接字，但是实现的是伪并发，客户端的请求只能一个一个处理，并且处理流程不宜过程。 4.信号驱动型IO 需要开启套接字的信号驱动式I/O功能，通过fcntl将socket和SIGIO关联，当被关联的socket可读或可写的时候，系统触发SIGIO信号。(SIGURG是带外数据可读触发，也需要关联)。fcntl做的事情是为socket指定宿主进程或进程组，被指定的进程或进程组将捕获这两个信号。使用SIGIO时，还需要利用fcntl设置O_ASYNC标志，并且需要准备一个信号捕捉函数，在网络数据抵达内核缓冲区的时候会发出一个SIGIO的信号。 5.异步IO 网络数据抵达内核缓冲区的时候，内核再帮我们完成从内核缓冲区到用户缓冲区的拷贝，然后再通知用户。使用aio_read函数给内核传递文件描述符、缓冲区指针、缓冲区大小和文件偏移，并告诉当整个操作完成时如何通知我们(比如通过信号通知)。 总结 前4种IO模型都是同步IO，最后一种才是异步IO。 前4种模型的主要区别在于第一个阶段，因为第二个阶段是一样的，都是recvfrom阻塞从内核缓冲区拷贝到用户缓冲区。异步IO则两个阶段都与前四种不同。 换言之，同步I/O向应用程序通知的是I/O就绪事件，用户需要自己读取数据。 异步I/O向应用程序通知的是I/O完成事件，内核帮用户完成了数据的读写。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"}]},{"title":"拥塞控制","date":"2018-11-17T15:22:28.000Z","path":"2018/11/拥塞控制/","text":"引言 计算机网络中的带宽、交换结点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就会变坏。这种情况就叫做拥塞。 拥塞控制就是防止过多的数据注入到网络中，避免路由器或数据链路过载。(网络中的数据是经过路由器进行转发) 拥塞控制是一个全局性的过程，面对的是整个网络，不用于端到端的流量控制。 拥塞控制的作用就是提高网络利用率，降低丢包率，并保证网络资源对每条数据流的公平性。 慢启动和拥塞避免发送端维护一个拥塞窗口(cwnd)，大小取决于网络的拥塞程度动态地变化。 慢启动:TCP模块一开始发送数据时并不知道网络的实际情况，先探测一下网络的拥塞情况。 下面的实例以报文数量做演示，实际上是以字节为单位。 注意:慢启动阶段接收端没确认一次，拥塞窗口大小就加1 1.第一次发送端发送M1，接收端确认了2.第二次由于接收端确认了M1，因此拥塞窗口加1，发送M2和M33.第三次由于接收端确认了M2和M3，拥塞窗口加2，变成4，发送M4-M7 由此可见，慢启动阶段传输轮次每加一，拥塞窗口数就加倍，呈乘法增长。 但是为了防止拥塞窗口增长过大引起网络拥塞，因此需要一个慢启动的门限值(ssthresh)一旦超过这个门限值，就该用拥塞避免算法。拥塞避免:让拥塞窗口缓慢增长，即每经过一个往返时间RTT(一轮)，拥塞窗口只加1，呈加法增长。 无论是在慢启动阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢启动门限设置为出现拥塞时的发送窗口大小的一半。然后把拥塞窗口设置为1，执行慢启动算法。 快重传和快恢复快重传要求接收方在收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时捎带确认。快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待设置的重传计时器时间到期。 快重传还配合着快恢复。 快重传一旦触发，意味着出现丢包，但考虑到还能收到几个重复地确认包，因此不是网络拥塞造成的，所以不执行慢启动，而是执行快恢复。 快恢复:1.当发送方连续收到三个重复确认时，就执行“乘法减小”算法，ssthresh变成当时拥塞窗口的一半 2.将窗口设置为ssthresh的大小，然后执行拥塞避免算法。 扩展在Linux下，拥塞控制算法有多种实现，比如reno算法、vegas算法、cubic算法等，基本都实现了上述四个部分。 /proc/sys/net/ipv4/tcp_congestion_control文件中指示了机器当前使用的拥塞控制算法。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"https://oldbuffalo.github.io/tags/TCP/"}]},{"title":"滑动窗口","date":"2018-11-17T14:07:22.000Z","path":"2018/11/滑动窗口/","text":"引言当发送方的发送速率过快，以至于接收方没来得及接收，导致出现丢包现象这时候我们需要进行流量控制，TCP采用的是滑动窗口进行流量控制。注意：滑动窗口控制的是发送端和接收端，是端到端的控制 1比特滑动窗口协议(停止等待协议)接收方和发送方的窗口大小都是1，发送方每次都发送一个数据包，必须等待到这个数据包的ACK，才能发送下一个。显然这种方式效率很低，带宽利用率很低，只适合网络环境差或者本身带宽很低的情况下。 滑动窗口(rwnd)发送端和接收端都维护一个数据帧的序列，发送方的窗口大小由接收方确定，目的在于控制发送速度，避免接收方缓存不够大，导致溢出丢包，同时控制流量避免网络拥塞。 滑动窗口允许发送方不必等待接收方的确认就可以连续发送多个数据包，提高了传输效率，同时由于窗口的存在，也限制了流量，达到控制的目的。 发送方 当接收方确认数据后，同时返回提供的窗口大小。 随着窗口中的数据不断被确认，窗口不断右移。 接收方 流程解释：1.客户端向服务器发起连接请求,告诉服务器自己窗口大小是4096，指定MSS为14602.服务器确认客户端的连接请求，并向客户端发起连接请求，指定窗口大小是6144，MSS为10243 客户端确认服务器的连接请求1-3就是三次握手过程4-9客户端给服务器连续发送了六个数据包，总共6144个字节，填满了接收方的窗口。10.接收方确认收到了6144个字节，并且交给应用程序处理了2048个字节，因此返回可用窗口大小204811.接收方确认收到了6144个字节，并且交给应用程序处理了2048个字节，因此返回可用窗口大小409612.客户端给服务器发送1024个字节数据13.客户端请求断开与服务器的连接，同时发送1024个字节数据，然后表示不再给服务器发送数据了14.服务器确认了新发来的两个数据包和客户端的断开请求，但尚未处理数据，返回可用窗口大小为204815.服务器处理了2048个字节，返回可用窗口大小409616.服务器又处理了2048个字节，返回可用窗口大小614417.服务器请求断开和客户端的连接18.客户端确认服务器的断开请求 注：上述所有数字都是以字节为单位。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"https://oldbuffalo.github.io/tags/TCP/"}]},{"title":"三次握手四次挥手","date":"2018-11-17T12:51:23.000Z","path":"2018/11/三次握手四次挥手/","text":"前面说过TCP是一种面向连接的、可靠的、数据流传输协议。 现在就来谈谈TCP是如何建立连接和结束连接的。 三次握手建立连接准备工作：服务器1.创建socket 2.bind 3. listen 4.阻塞在accept,等待客户端的连接客户端调用connet请求连接 过程解释：1.客户端向服务器发送SYN，序号是x，说明客户端请求建立连接，进入SYN_SENT状态2.服务器收到客户端发的SYN，回复给客户端SYN和ACK ，进入SYN_RECV状态注意:同步序号是新的y，确认序号是x+13.客户端收到服务器发的SYN和ACK，回复ACK给服务器 ，进入ESTABLISHED状态注意:客户端的同步序号是x+1(服务器ACK的值),确认序号是y+14.服务器收到客户端的ACK，代表连接已建立，可以进行数据传输,进入ESTABLISHED状态 这时候很自然就会产生一个疑惑，为什么要进行三次握手，不是一次两次或者四次? 一个比较官方的答案是： 为了防止已失效的连接请求报文段突然又传送到了服务器，因而产生错误。 ​ ——《计算机网络(第7版)》谢希仁 对应具体的实例是： 如果某个客户端发送SYN给服务器，但是由于网络中的某些原因在某个网络结点滞留了，对客户端来说，超过一定时间没收到这个报文就认为该报文失效了，但是如果之后这个报文又到达了服务器，此时服务器回复给客户端确认信息，并且发起连接请求。如果只有两次握手，客户端不回复给服务器，告诉它之前的是失效的报文，那么服务器就一直会阻塞等待客户端发送数据，造成错误，其实质就是为了建立可靠的信道。 因为双方都需要确认对方收到了自己发送的序列号，从而建立可靠的信道，确认过程至少要进行三次通信。 四次挥手结束连接 过程解释:1.客户端发送FIN给服务器，序号为u，说明客户端不再发数据给服务器 请求释放从客户端到服务器的连接，进入FIN_WAIT_1状态。 2.服务器收到FIN后，回复ACK，序号是v，确认序号是u+1，同意释放从客户端到服务器的连接，进入CLOSE_WAIT状态 3.客户端收到ACK，此时从客户端到服务器的连接已经释放，但服务器到客户端的连接还没有释放，因此客户端还可以接收数据，进入FIN_WAIT_2状态 4.服务器继续发送发送之前没发完的数据给客户端 5.服务器给客户端发送FIN和ACK，说明服务器已经发送完数据了，请求释放和客户端的连接，就算没收到客户端回复，一段时间之后也会自动释放，进入LAST_ACK状态。 注意：序号是新的w，确认序号依旧是u+1(因为上次ack请求的u+1没收到) 6.客户端收到FIN和ACK，并回复给服务器ACK 序号是u+1，确认序号是w+1，进入TIME_WAIT状态(等待2MSL) 7.服务器收到客户端的ACK后，释放从服务器到客户端的连接 和三次握手一样，同样会产生为什么需要进行四次挥手？ 因为TCP是全双工通信，客户端请求关闭连接是第一、二次挥手，服务器继续传输之前没传完的数据给客户端，这也是为什么不能在第二次挥手的时候将ACK和FIN同时发给客户端，需要进行第三、四次挥手结束服务器到客户端的连接。 正是由于服务器收到客户端的FIN请求之后，ACK和FIN是分两次发送的，中间隔着剩余数据传输，而建立连接服务器ACK和SYN是一起发给客户端的，所以结束连接比建立连接多一次。 TCP状态转移TCP连接的任意一端在任一时刻处在什么状态，当前状态都可以用netstat命令查看。 虚线表示服务器连接的状态转移，实现表示客户端连接的状态转移 具体分析见《Linux高性能服务器编程》P41 连接与断开时候一些特殊情况半关闭状态半关闭：连接的一端结束它的发送后还能接收来自另一端数据的状态 发送FIN包意味着告诉另外一端本端已经完成数据的发送。 服务器和客户端程序判断对方是否已经关闭连接的方法：read系统调用返回0(收到结束报文段)，Linux还有别的检测方法，以后补上。 在四次挥手过程中，客户端发出FIN包，服务器确认FIN包，这时候客户端进入半关闭状态 socket网络编程接口通过shutdown提供对半关闭的支持 连接超时如果一个客户端访问一个距离它很远的服务器或者由于网络繁忙，导致服务器的回复包没有及时到达客户端，客户端会怎么办？ 必然是先进行重传(可能进行多次)，如果重传仍然无效，就通知应用程序连接超时。 超时重连策略：连续发送5个SYN包，时间间隔分别为1s、2s、4s、8s、16s，最后一个TCP报文段的超时时间是32s。因此建立TCP连接的超时时间是63s(根据这个时间和间隔时间推出最后一个报文段的超时时间)。因此，TCP模块总共执行5次超时重连(不算第一个请求的包)。 由/proc/sys/net/ipv4/tcp_syn_retries内核变量所定义，在应用程序中我们可以修改连接超时时间(具体方法以后码上) TIME_WAIT状态首先考虑的是为什么要有这个状态，也就是为什么要有2MSL的等待时间？ 首先解释一下MSL：报文段在网络中的最长生存时间。因为TCP报文段以IP数据报在网络内传输，而IP数据包有限制其生存时间的TTL字段。RFC 1122建议是2min。 1.为了保证客户端发送的最后一个ACK报文能够到达服务器，也就是可靠地终止连接。若未成功到达，则服务器超时重传FIN和ACK报文段，客户端再重传ACK，最后客户端和服务器都正常退出。假设客户端不等待2MSL，而是在发送完ACK之后直接释放关闭，一但这个ACK丢失的话，服务器就无法正常的进入关闭连接状态。 2.可以防止已失效的报文段。客户端在发送最后一个ACK之后，再经过经过2MSL，就可以使本连接持续时间内所产生的所有报文段都从网络中消失，保证在关闭连接后不会有还在网络中滞留的报文段去骚扰服务器。就比如最后一个ACK丢包了，服务器重传了FIN+ACK，但是客户端没有2MSL直接结束，立即开启一个新的连接(相同ip+port)就会收到这个包，造成错误。(Linux中一个TCP连接处于TIME_WIAT状态，无法立即使用呢该连接占用的端口来建立一个新的连接)，也就是说TIME_WAIT保证了新的连接(相同ip+port)不会收到原来连接的数据包。 TCP报文段最大生存时间是MSL，2MSL确保网络上两个传输方向尚未被接收到的、迟到的TCP报文段都消失。 如果有的时候我们希望避免TIME_WAIT状态怎么办？ 也就是说在程序退出后，我们希望能够立即重启它。但由于处在TIME_WAIT状态的连接还占用着端口，程序无法启动。对于客户端程序，一般不会担心这种问题，因为客户端程序一般用系统自动分配的临时端口号来建立连接，一般都不同。但如果是服务器主动关闭连接后异常终止，则因为它总是使用同一个知名服务端口号，所以连接的TIME_WAIT状态将导致它不能立即重启。不过，可以通过socket选项SO_REUSEADDR来强制进程立即使用处在TIME_WAIT状态的连接占用的端口号。 tcpdump抓包测试TIME_WAIT 这里连接的是百度的80端口，第一次接连之后马上退出，第二次尝试连接就显示端口被占用(两次都指定了12345) 使用netstat -nat查看连接状态 FIN_WAIT2不是我们想要的状态，才能够FIN_WAIT2转换到TIME_WAIT需要收到服务器的FIN包，也就是百度服务器在四次挥手的时候并没有发送FIN包。 通过tcpdump抓取和百度服务器四次挥手的过程进一步来证实我的想法 抓包结果为： 前三个IP数据报是三次握手发送的，也就是说四次挥手过程中仅抓取到两个IP数据报，另言之就是百度服务器没有主动发送FIN包。 那问题来了，如果四次挥手的时候，服务器不给客户端发FIN包，会怎么样？ 也就是说客户端处在FIN_WAIT_2状态，等待服务器发送FIN包从而转到TIME_WAIT状态，如果收不到服务器的FIN包，它将一直停留在这个状态。但是如果不是为了在半关闭状态下继续接受数据，连接长时间停留在FIN_WAIT_2状态毫无意义。如果客户端执行半关闭后，还没收到服务器的FIN包就强行退出，此时客户端连接应该由内核来接管，称为孤儿连接。Linux为了防止孤儿连接长时间存留在内核中， 定义了两个内核变量：/proc/sys/net/ipv4/tcp_max_orphans和/proc/sys/net/ipv4/tcp_fin_timeout。 前者指定内核能接管的孤儿连接的数目，后者指定孤儿连接在内核中生存的时间。 何时发送复位报文段(RST)复位报文段的作用是通知对方关闭连接或重新建立连接 1.访问不存在的端口，目标主机对回复一个复位报文段。(如果客户端程序向服务器某个端口发起连接，但该端口仍被处于TIME_WAIT状态的连接所占用，客户端也会受到复位报文段) 2.异常终止连接。TCP提供异常终止连接的一种方法是给对方发送一个复位报文段，一旦发送复位报文段，发送端所有排队等待发送的数据将被丢弃。应用程序可以使用SO_LINGER来发送复位报文段来异常终止连接。 3.处理半打开连接 半打开状态：服务器(或客户端)关闭或者异常终止了连接，而对方没有接收到结束报文段(比如网络故障)，此时客户端(或服务器)还维持着原来的连接，而服务器(或客户端)即使重启，也没有该连接的任何信息。 如果客户端(或服务器)往处于半打开状态的连接写入数据，则对方回应一个复位报文段。","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"TCP","slug":"TCP","permalink":"https://oldbuffalo.github.io/tags/TCP/"}]},{"title":"TCP协议","date":"2018-11-17T11:50:26.000Z","path":"2018/11/TCP协议/","text":"TCP特点TCP全称叫传输控制协议，是传输层两大协议之一。 TCP是一种面向连接的、可靠的、数据流的协议。连接方式是一对一，类似于打电话，数据交互之前需要连接，然后才可以通信。 TCP的可靠体现在: 传输数据之前需要建立连接 发送应答机制(数据需要确认) 发送端超时重传(丢包) 乱序重组(根据序列号) 校验码校验 滑动窗口 拥塞控制 TCP首部 1.源端口和目标端口很好理解，传输层就是实现端到端的通信的。简单介绍一下端口号。端口就是用来标识一个网络应用的。范围是0-66635,1-1023是知名端口号，由Internet号分配机构管理。1024-5000是临时端口，大于5000的是为其他服务器预留的 一些知名端口号: 2.序号 :《TCP/IP:协议》上是这么解释的，用来标识从TCP发端向TCP收端发送的数据字节流，它标识在这个报文段中的第一个数据字节。用序号对每个字节进行技术，序号到达最大值(2的32次-1)再从0开始。初始序号是随机的。 简而言之，序号就是对已发数据字节进行计数的。 3.确认序号 :确认接收端已经收到了发送端前n个字节，请求第n+1个字节开始的数据因此确认序号是上次已成功收到数据字节序号加1 4.首部长度: 给出首部中32bit字(4字节)的数目，由于不加选项的TCP首部至少是20个字节，因此首部长度最小为5，由于首部长度这个字段占4位，因此TCP首部最多有60个字节。 5.六个标志位 置1代表触发 URG 紧急指针有效ACK 确认序号有效PSH 接收方应该尽快将这个报文段交给应用层RST 重建连接SYN 同步序号用来发起一个连接FIN 发端完成发送任务 6.窗口大小 TCP利用滑动窗口进行流量控制 7.检验和 强制性字段 用于收端进行验证 8.紧急指针 是一个正的偏移量(很少用) 9.选项 比较常见的是最长报文大小(MSS) ,在建立连接的第一个报文指定 窗口扩大选项(3个字节，每个字节表示移位值) 时间戳选项(10个字节) 时间戳值和时间戳回送回答字段 TCP头部选项选项最多40字节，加上固定头部20字节，TCP头部最多60字节 TCP头部选项一般结构： 常见的7种TCP头部选项： kind = 0 选项表结束选项 kind = 1 空操作选项，没什么含义，一般用来将TCP选项总长度填充为4字节整数倍 kind = 2 最大报文段长度选项(MSS)，在连接初始化协商，TCP模块通常设置成(MTU-40)字节，去除20字节的TCP头部和20字节的IP头部（假设都不加选项），避免本机IP分片，对以太网而言，MSS一般为1460 kind = 3 窗口扩大因子选项。在连接初始化协商。在TCP头部接收通告窗口大小是16位表示，最大是65536字节，但实际上TCP模块允许的接收通告窗口大小远不止这个数(为了提高TCP吞吐量)，窗口扩大因子(移位数，取值范围0-14)，假设接收窗口一开始大小为M，窗口扩大因子是N，实际接收窗口大小为M*2^N。 可以修改/proc/sys/net/ipv4/tcp_window_scaling内核变量来启用或者关闭窗口扩大因子选项 注意点：和MSS选项一样，窗口扩大因子只能出现在同步报文段中，否则将被忽略。但同步报文段本身不执行窗口扩大操作，即同步报文段头部的接收通告窗口大小就是该TCP报文段的实际接收通告窗口大小。当连接建立之后，每个数据传输方向的窗口扩大因子就固定不变了。(我懵逼了，不懂什么意思) kind = 4 ，选择性确认(SACK)。如果某个TCP报文段丢失，TCP模块会重传最后被确认的TCP报文段后续的所有报文段，这样原先有些已经正确传输但在丢失报文段之后的报文就会被重复发送，从而降低TCP性能。SACK能够改善这种情况，使TCP模块只重新发送丢失的TCP报文段。 可以修改/proc/sys/net/ipv4/tcp_sack内核变量来启用或关闭选择性确认选项 kind = 5 ，SACK实际工作的选项。该选项的参数告诉发送方已经收到并缓存的不连续的数据块，从而让发送端可以据此检查并重发丢失的数据块。块左边沿表示不连续块的第一个数据序号，块右边沿表示不连续块的最后一个数据序号的下一个序号，这一对参数之间的数据是没有收到的，占用8字节。 kind = 8 ,时间戳选项。提供较为精确的计算通信双方之间的回路时间(RTT)的方法，从而为TCP流量控制提供重要信息。 可以修改/proc/sys/net/ipv4/tcp_timestamps内核变量来启用或关闭时间戳选项 tcpdump抓包观察TCP头部 抓取到的数据包： Flags[S]:表示TCP报文段中有SYN标志，是一个同步报文段 seq:序号值。该同步报文值是从127.0.0.1.34278（客户端）到127.0.0.1.23（服务器）这个传输方向上的第一个TCP报文段，所以这个序号值也是这次通信过程中该传输方向上的ISN值。 win:接收通告窗口大小。因为这是一个同步报文段，所以反映的是实际接收通告大小 options：TCP选项。mss是发送端(客户端通告的最大报文段长度)、sackOK表示发送端支持并同意使用SACK选项、TS val是发送端的时间戳、ecr是时间戳回显应答、nop是一个空操作选项、wscale是发送端使用的窗口扩大因子。 前20字节是IP头部，后40字节是TCP头部 因此从第21字节开始分析 十六进制数 十进制表示 TCP头部信息 0x85e6 34278 源端口号 0x0017 23 目的端口号 0x599d891d 1503496477 序号 0x00000000 0 确认号 0xa 10 头部长度时10*4字节 0x002 设置了SYN标志 0xaaaa 43690 接收通告窗口大小 0xfe30 头部校验和 0x0000 没设置URG标志，所以紧急指针无意义 0x0204 最大报文段长度(MSS)选项的kind值和length值 0xffd7 65495 最大报文段长度 0x0402 允许SACK选项 0x080a 时间戳选项的kind值和length值 0x001cdf6d 1892205 时间戳 0x00000000 0 时间戳回显应答 0x01 空操作选项(nop) 0x0303 窗口扩大因子选项的kind值和length值 0x07 7 窗口扩大因子为7(移位数)","comments":true,"tags":[{"name":"网络","slug":"网络","permalink":"https://oldbuffalo.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"Linux高性能服务器编程","slug":"Linux高性能服务器编程","permalink":"https://oldbuffalo.github.io/tags/Linux%E9%AB%98%E6%80%A7%E8%83%BD%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BC%96%E7%A8%8B/"},{"name":"TCP","slug":"TCP","permalink":"https://oldbuffalo.github.io/tags/TCP/"}]},{"title":"设计模式之简单工厂","date":"2018-11-12T12:12:15.000Z","path":"2018/11/设计模式之简单工厂/","text":"学习C++也有一年多了，基础语法、计算机基础也掌握地不错了，但是在写项目时总是觉得设计框架很困难，分析类之间的关系很杂乱，因此开始学习设计模式。 简单工厂也叫做静态工厂模式，是类创建型模式(同种类型的还有，单例，工厂方法，抽象工厂，建造者)，在简单工厂模式中，可以根据参数的不同返回不同类的实例。简单工厂模式专门定义一个工厂类来负责创建其他类的实例，被创建的实例通常都具有共同的父类。 模式结构 工厂类：是该模式的核心，在客户端的直接调用下根据传入参数的不同创建对应的产品(类对象) 抽象产品类：是由简单工厂模式所创建对象的父类，拥有产品们共有的特性和接口 具体产品类: 简单工厂创建的任何对象都是这个角色的实例，用来完成具体工作 实例分析 实例中，加减乘除派生自一个基类，该基类定义了公有的属性以及虚函数接口。在各个派生类中实现了每个派生类中需要的功能。除此之外还定义了简单工厂类，在简单工厂类中，根据运算符决定需要实例化那个运算功能类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778class Calculation&#123; &#x2F;*抽象产品类*&#x2F;public: Calculation(int x,int y): num1(x),num2(y)&#123;&#125;; int num1; int num2; virtual int calculate() &#x3D; 0;&#125;;class Add: public Calculation&#123;public: Add(int n1,int n2):Calculation(n1,n2)&#123;&#125; int calculate()&#123; return num1+num2; &#125;&#125;;class Sub: public Calculation&#123;public: Sub(int n1,int n2):Calculation(n1,n2)&#123;&#125; int calculate()&#123; return num1-num2; &#125;&#125;;class Mul: public Calculation&#123;public: Mul(int n1,int n2):Calculation(n1,n2)&#123;&#125; int calculate()&#123; return num1*num2; &#125;&#125;;class Div: public Calculation&#123;public: Div(int n1,int n2):Calculation(n1,n2)&#123;&#125; int calculate()&#123; if(num2 &#x3D;&#x3D; 0) return 0; return num1&#x2F;num2; &#125;&#125;;class Factory&#123; &#x2F;*简单工厂类*&#x2F;public: int num1; int num2; char op; int result; Calculation* cal; Factory(int n1,char op,int n2)&#123; num1 &#x3D;n1; num2 &#x3D; n2; this-&gt;op &#x3D; op; &#125; int GetResult()&#123; switch(this-&gt;op) &#123; case &#39;+&#39;: cal &#x3D; new Add(num1,num2); break; case &#39;-&#39;: cal &#x3D; new Sub(num1,num2); break; case &#39;*&#39;: cal &#x3D; new Mul(num1,num2); break; case &#39;&#x2F;&#39;: cal &#x3D; new Div(num1,num2); break; default: break; &#125; result &#x3D; cal-&gt;calculate(); return result; &#125;&#125;; 优缺点分析优点： 1.客户端无须知道所创建的具体产品类的类名，只需要知道具体产品类所对应的参数即可，对于一些复杂的类名，通过简单工厂模式可以减少使用者的记忆量 2.当需要引入新的产品是不需要修改客户端的代码，只需要添加相应的产品类并修改工厂类就可以了，所以说从产品的角度上简单工厂模式是符合“开-闭”原则的 3.工厂类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例，客户端可以免除直接创建产品对象的责任，而仅仅“消费”产品；简单工厂模式通过这种做法实现了对责任的分割，它提供了专门的工厂类用于创建对象 缺点：1.一旦工厂类出问题，整个程序会受影响 2.增加系统了中类的个数，在一定程序上增加了系统的复杂度和理解难度 3.系统扩展困难，一旦添加新产品就不得不修改工厂逻辑，在产品类型较多时，有可能造成工厂逻辑过于复杂，不利于系统的扩展和维护 适用场合1.工厂类负责创建的对象比较少：由于创建的对象较少，不会造成工厂方法中的业务逻辑太过复杂。 2、客户端只知道传入工厂类的参数，对于如何创建对象不关心：客户端既不需要关心创建细节，甚至连类名都不需要记住，只需要知道类型所对应的参数。","comments":true,"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://oldbuffalo.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"线程同步经典问题练习","date":"2018-11-09T11:29:37.000Z","path":"2018/11/线程同步经典问题练习/","text":"生产者-消费者问题描述若干个生产者在生产产品，这些产品将提供给若干个消费者去消费，为了使生产者和消费者能并发执行，在两者之间设置一个具有多个缓冲区的缓冲池，生产者将它生产的产品放入一个缓冲区中，消费者可以从缓冲区中取走产品进行消费 问题分析同步: 1.缓冲区满时 生产者不能生产 阻塞 2.缓冲区空时 消费者不能消费 阻塞互斥: 生产和消费是互斥行为信号量+关键段 代码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103#include&lt;iostream&gt;#include&lt;windows.h&gt;#include&lt;process.h&gt;using namespace std;&#x2F;*两个生产者 两个消费者 四块缓冲区*&#x2F;const int GoodsMax &#x3D; 10;CRITICAL_SECTION cs;HANDLE hSemaphore_notFull;HANDLE hSemaphore_notempty;unsigned __stdcall ProducerProc( void * );unsigned __stdcall ConsumerProc( void * );const int bufsize &#x3D; 4;int buf[bufsize]; &#x2F;&#x2F;用数组实现循环队列模拟缓冲区int g_x,g_y;int goods &#x3D; 1; &#x2F;&#x2F;模拟产品bool Pro_exit_flag &#x3D; FALSE;bool Con_exit_flag &#x3D; FALSE;int main()&#123; InitializeCriticalSection(&amp;cs); hSemaphore_notFull &#x3D; CreateSemaphore(NULL,4,4,NULL); hSemaphore_notempty &#x3D; CreateSemaphore(NULL,0,4,NULL); HANDLE handle[4]; handle[0] &#x3D; (HANDLE)_beginthreadex(NULL,0,ProducerProc,NULL,0,NULL); handle[1] &#x3D; (HANDLE)_beginthreadex(NULL,0,ProducerProc,NULL,0,NULL); handle[2] &#x3D; (HANDLE)_beginthreadex(NULL,0,ConsumerProc,NULL,0,NULL); handle[3] &#x3D; (HANDLE)_beginthreadex(NULL,0,ConsumerProc,NULL,0,NULL); WaitForMultipleObjects(4,handle,TRUE,INFINITE); CloseHandle(hSemaphore_notFull); CloseHandle(hSemaphore_notempty); CloseHandle(handle[0]); CloseHandle(handle[1]); CloseHandle(handle[2]); CloseHandle(handle[3]); DeleteCriticalSection(&amp;cs); getchar(); return 0;&#125;unsigned __stdcall ProducerProc(void* lparma)&#123; while(1)&#123; &#x2F;&#x2F;等待有空余的缓冲区，阻塞在满的时候 WaitForSingleObject(hSemaphore_notFull,INFINITE); EnterCriticalSection(&amp;cs); if(!Pro_exit_flag) &#123; buf[g_x] &#x3D; goods; printf(&quot;%d生产者将数据%d放入缓冲区%d\\n&quot;,GetCurrentThreadId(),goods,g_x); &#125; if(goods &#x3D;&#x3D; GoodsMax) &#123; LeaveCriticalSection(&amp;cs); &#x2F;&#x2F;通知另一个生产者线程退出，工作已经结束了 ReleaseSemaphore(hSemaphore_notFull,1,NULL); ReleaseSemaphore(hSemaphore_notempty,1,NULL);&#x2F;&#x2F;通知消费者消费 Pro_exit_flag &#x3D; TRUE; break; &#125; goods++; g_x &#x3D; (g_x+1)%bufsize; LeaveCriticalSection(&amp;cs); ReleaseSemaphore(hSemaphore_notempty,1,NULL); &#x2F;&#x2F;通知消费可以消费了 &#125; printf(&quot;************%d生产者已经完美地结束了工作\\n&quot;,GetCurrentThreadId()); return 0;&#125;unsigned __stdcall ConsumerProc( void * lparma)&#123; while(1)&#123; &#x2F;&#x2F;等待缓冲区有东西 WaitForSingleObject(hSemaphore_notempty,INFINITE); EnterCriticalSection(&amp;cs); if(!Con_exit_flag) printf(&quot;\\t%d消费者将数据%d从缓冲区%d拿出\\n&quot;,GetCurrentThreadId(),buf[g_y],g_y); if(buf[g_y] &#x3D;&#x3D; GoodsMax)&#123; LeaveCriticalSection(&amp;cs); ReleaseSemaphore(hSemaphore_notempty,1,NULL); &#x2F;&#x2F;无故释放一个信号量告诉另一个线程退出 Con_exit_flag &#x3D; TRUE; break; &#125; g_y &#x3D; (g_y+1)%bufsize; LeaveCriticalSection(&amp;cs); Sleep(20); &#x2F;&#x2F;通知生产者生产 ReleaseSemaphore(hSemaphore_notFull,1,NULL); &#125; printf(&quot;**********%d消费者完美地结束了工作\\n&quot;,GetCurrentThreadId()); return 0;&#125; 读者写者问题描述有一个写者很多读者，多个读者可以同时读文件，但写者在写文件时不允许有读者在读文件，同样有读者在读文件时写者也不去能写文件。 问题分析同步:1.写者要等到没有读者时才能去写文件 2.所有读者要等待写者完成写文件后才能去读文件 人工事件+自动事件 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include&lt;iostream&gt;#include&lt;windows.h&gt;#include&lt;process.h&gt;&#x2F;*读者写者 有一个写者和多个读者 写和读不能同时进行 可以同时读*&#x2F;&#x2F;*利用事件进行同步通知*&#x2F;&#x2F;*用一个变量记录正在读的个数 第一个读的线程设置不能写入标志，最后一个读完的线程解除不能写入标志*&#x2F;HANDLE g_hEventRead,g_hEventWrite;CRITICAL_SECTION cs;int g_ReaderNum;unsigned __stdcall WriteProc( void * );unsigned __stdcall ReadProc( void * );int main()&#123; g_hEventRead &#x3D; CreateEvent(NULL,TRUE,TRUE,NULL); &#x2F;&#x2F;有事件 人工 g_hEventWrite &#x3D; CreateEvent(NULL,FALSE,FALSE,NULL); InitializeCriticalSection(&amp;cs); HANDLE handle[5]; handle[0] &#x3D; (HANDLE)_beginthreadex(NULL,0,WriteProc,NULL,0,NULL); handle[1] &#x3D; (HANDLE)_beginthreadex(NULL,0,ReadProc,NULL,0,NULL); handle[2] &#x3D; (HANDLE)_beginthreadex(NULL,0,ReadProc,NULL,0,NULL); Sleep(50); handle[3] &#x3D; (HANDLE)_beginthreadex(NULL,0,ReadProc,NULL,0,NULL); handle[4] &#x3D; (HANDLE)_beginthreadex(NULL,0,ReadProc,NULL,0,NULL); WaitForMultipleObjects(5,handle,TRUE,INFINITE); for(int i &#x3D; 0;i&lt;5;i++) CloseHandle(handle[i]); CloseHandle(g_hEventRead); CloseHandle(g_hEventWrite); DeleteCriticalSection(&amp;cs); getchar(); return 0;&#125;unsigned __stdcall WriteProc( void * lparma)&#123; printf(&quot;写者线程等待写操作\\n&quot;,GetCurrentThreadId()); WaitForSingleObject(g_hEventWrite,INFINITE); ResetEvent(g_hEventRead); &#x2F;&#x2F;控制不能进行读操作 printf(&quot;写者线程正在进行写操作\\n&quot;); Sleep(rand()%100); printf(&quot;写者线程结束写操作\\n&quot;); SetEvent(g_hEventRead);&#x2F;&#x2F;告诉读者可以开始读了 return 0;&#125;unsigned __stdcall ReadProc( void *lparma )&#123; &#x2F;*由于读者等待的是人工事件 一旦有事件并且不置成无信号的话 就可以让线程共享*&#x2F; printf(&quot;%d读者线程等待进行读操作\\n&quot;,GetCurrentThreadId()); WaitForSingleObject(g_hEventRead,INFINITE); EnterCriticalSection(&amp;cs); g_ReaderNum++; if(g_ReaderNum &#x3D;&#x3D; 1) &#x2F;&#x2F;一旦有读者开始读 就不让写者工作 ResetEvent(g_hEventWrite); LeaveCriticalSection(&amp;cs); printf(&quot;%d读者线程正在进行读操作\\n&quot;,GetCurrentThreadId()); Sleep(rand()%100); printf(&quot;%d读者线程结束读操作\\n&quot;,GetCurrentThreadId()); EnterCriticalSection(&amp;cs); g_ReaderNum--; if(g_ReaderNum &#x3D;&#x3D; 0) &#x2F;&#x2F;读者全部读完之后，告诉写者可以工作了 SetEvent(g_hEventWrite); LeaveCriticalSection(&amp;cs); return 0;&#125; 还可以通过读写锁实现 读写锁(SRWLOCK)读写锁在对资源进行保护的同时，还能区分想要读取资源值的线程（读取者线程）和想要更新资源的线程（写入者线程）。对于读取者线程，读写锁会允许他们并发的执行。当有写入者线程在占有资源时，读写锁会让其它写入者线程和读取者线程等待 初始化:InitializeSRWLock 写入者线程申请写资源:AcquireSRWLockExclusive 写入者线程释放对资源的占用：ReleaseSRWLockExclusive 读取者线程申请读资源:AcquireSRWLockShared 读取者线程释放对资源的占用：ReleaseSRWLockShared 注意：1.一个线程仅能锁定资源一次，不能多次锁定资源。2.先声明后初始化，不用销毁，系统自动清理 只要在线程函数中对读写操作加读写锁就可以了，比事件来得简单多了。","comments":true,"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://oldbuffalo.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Windows下的线程同步","date":"2018-11-07T11:02:33.000Z","path":"2018/11/Windows下的线程同步/","text":"引言线程可以共享进程的资源，这是一件很好的事情，便于线程之间通信。但是，同时对全局资源进行操作，也容易造成一些问题。例如，两根线程同时对一个全局变量进行++操作，假如初值为0，线程A加1000次，线程B加1000次，结果很有可能不是我们想象中的2000。因为某个线程加完之后还没写入内存，另一根线程就读出了之前的数，这就会造成加的次数减少，导致最后的值小于2000。这是个很简单的例子，但是警示我们在多线程编程中，同时操作全局资源，要注意线程同步的问题。 线程同步：让线程协调一致地工作，有序访问全局资源，保证资源完整性。Windows下线程互斥和同步的方式​互斥：指某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的 访问顺序，即访问是无序的。 ​同步: 在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源，如“第一类读写者模型”。 ​同步包括互斥，互斥其实是一种特殊的同步 原子访问 利用Interlocked系列函数 只能对一个变量进行原子操作 增减操作 返回变量执行增减操作之后的值 ​InterlockedIncrement ​InterlockedDecrement ​ InterlockedExchangeAdd 返回运算后的值，注意！加个负数就是减。 赋值操作 ​InterlockedExchange函数会返回原先的值。 *关键段(临界区) * 让多行代码以原子方式对资源进行操作 CRITICAL_SECTION (结构体) ​初始化:InitializeCriticalSection 销毁: DeleteCriticalSection​进入：EnterCriticalSection 离开：LeaveCriticalSection​尝试进入：TryEnterCriticalSection​初始化旋转锁: InitializeCriticalSectionAndSpinCoun​设置旋转锁次数:SetCriticalSectionSpinCount 直接阻塞​ 对于一个线程在访问临界区，别的想要访问的线程会从用户态切到内核态，一旦那个线程离开，阻塞的线程就切换到可调度状态，这样来回切换状态开销大，效率不高 旋转锁 拿不到锁不马上阻塞，而是等待一段时间再阻塞 异步处理 TryEnter 尝试着拿锁，拿不到就处理别的工作 注意点:如果在关键段中途离开，离开之前需要解开关键段。 互斥量 内核对象 通过句柄操作 配合 WaitForSingleObject使用 互斥对象包含使用计数、线程ID以及一个递归计数(占有互斥量的次数)创建:CreateMutex进入:WaitForSingleObject 等互斥量释放:ReleaseMutex跨进程操作:OpenMutex 通过创建时候的最后一个参数：名字 事件 内核对象 通过句柄操作 创建:CreateEvent 注意创建的是人工事件还是自动事件，初始化是有事件还是没有事件进入:WaitForSingleObject 等事件 如果是自动事件自动变成无事件，如果是人工，需要手动置成无事件设置成有事件:SetEvent 设置成无事件:ResetEvent跨进程操作:OpenEvent ​注意点：如果是人工事件，设置成有信号不变回去的话，所有的线程都能共享资源。适合通知的场合，如果 需要线程之间互斥，则设置成自动事件。 信号量 内核对象 通过句柄操作创建:CreateSemaphore 注意初始化的信号量个数以及信号量的最大值(不一定是线程个数，看情况而定)​进入:WaitForSingleObject 等信号量​释放:ReleaseSemaphore​跨进程操作:OpenSemaphore​注意点:1.一次释放信号量个数不允许超过最大值2.分多次释放信号量，如果总和超过最大值，就取最大值 误区volatile并不能实现线程同步，只是防止编译优化，每次都要求从内存中读取值。 它们之间的区别码一个整理得不错的博客 原子访问局限性比较大，只能作用于变量，因此使用范围不是很广泛。 关键段只能在同一个进程中实现线程同步，而其余三个内核对象都可以实现跨进程。如果是同一进程中进行线程同步，建议用临界区，因为更节省系统资源，更有效率，因为关键段是用户模式下的同步对象内核对象的缺点是性能。要从用户态切换到内核态，开销大。有线程所有权概念，可以实现互斥，但实现不了同步。 互斥量有线程所有权，谁创建谁有优先选择权，可以实现互斥，实现不了同步。能很好地处理”遗弃”问题 “遗弃”问题就是占有某种资源的进程意外终止后，其它等待该资源的进程能否感知 事件有人工事件，可以同时让多个线程做事，但是指定不了个数，而信号量可以指定个数","comments":true,"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://oldbuffalo.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Windows","slug":"Windows","permalink":"https://oldbuffalo.github.io/tags/Windows/"}]},{"title":"Linux下的线程","date":"2018-11-07T04:09:05.000Z","path":"2018/11/linux下的线程/","text":"线程概述线程的一些特性和状态转换和Windows下面类似。因此就简单介绍一下，重点突出Linux下面的一些特色的地方。 1.线程是轻量级进程(light-weight process)，也有PCB(process control block)，创建线程使用的底层函数和进程一样，都是clone(具体参见进程创建过程)2.从内核里看进程和线程是一样的，都有各自不同的PCB，但是PCB指向的内存资源的三级页表是相同的(换句话说，就是进程和线程共享某些资源，通过间接寻址，指向同一块虚拟地址空间)3.线程就是寄存器和栈(调度单位就是寄存器和栈,保护和恢复现场)4.线程是最小的调度单位，内核通过调度编号(LWP)去调度。（LWP—线程编号）5.独占资源的称为进程，进程可以蜕化成主控线程。 ps -Lf pid 显示指定进程的线程信息ps -eLf 显示所有线程 线程间资源共享资源 1.文件描述符表 2.信号处理方式 3.当前工作目录(pwd)4.用户ID、组ID 5.内存地址空间0-3G(32位)用户地址空间:Text、Data、Bss、堆、lib 注意堆区：linux是共享堆，线程和进程指向同一块堆空间，可以设置成非共享堆，但Windows就是非共享堆，每个线程都有自己的堆空间。 线程间非共享资源1.线程id 2. 处理器现场和内核栈指针(保护上下文) 3.用户空间栈 4.errno全局变量5.阻塞信号集(屏蔽字) 6.进程调度优先级 线程优缺点优点:1. 提高程序并发性2.开销小,不用重新分配内存3.通信和共享数据方便 缺点:1.线程稳定性差2.gbd调试困难3.线程使用信号比较麻烦。(虽然有同样的处理函数，但是可以对别的线程设置屏蔽字，并且信号不能调试，再加上多线程调试难度很大) 线程原语Linux下采用的线程接口称为”pthread”或”POSIX线程”，采用的是NPTL库(Native POSIX Thread Library) getconf GNU_LIBPTHREAD_VERSION 查看当前pthread库版本 使用线程库时 gcc时要指定 -lpthread pthread_create 创建线程 注意第二个参数 线程属性一般不怎么使用(具体参见APUE p342）pthread_self 获取当前线程的idpthread_join 阻塞函数 等待指定的线程退出，并回收资源，第二个参数可以获取线程退出码pthread_detach 设置线程为分离态，一旦线程退出，内核自动回收资源。 优点:释放了主控线程，不需要再进行回收操作 缺点:无法获得退出状态了 线程在创建的时候默认是可回收态，也就是说当可回收态的线程退出时，其线程ID和退出状态将被保留，等待另一个线程调用pthread_join。一旦线程被置成分离态，再调用pthread_join就会出错 线程退出方式1.return 如果是普通线程return，会回到主控线程，主控线程return，则进程终止2.pthread_exit(void* status) 只会结束调用该函数的线程本身，不会影响其他人，推荐使用这个函数注意点:指针status不能指向线程函数中的某个局部变量3.exit(0) 无论哪种线程调用，都导致进程终止4.pthread_cancel(pthread_t tid) 通过tid结束指定线程 统一退出码是-1 还能安排多个线程退出时的处理函数(APUE p316) 类似于信号杀死进程 信号处理条件(产生中断、异常、系统调用，从用户态切换到内核态，返回用户态再处理信号)，但是pthread_cancel,只有产生系统调用的时候才会检测cancel事件。可以配合空调函数pthread_testcancel()产生系统调用，但是什么事情都没做。 注意点： 1.与出错时返回-1，并置errno为某个正值的大多数系统函数不同，pthread函数出错时返回正值，不设置errno，成功返回0，由于不设置errno,因此不能用perror打印，可以用strerror把错误码转换成错误信息再打印2.注意处理主控线程和普通线程之间的竞争关系，可以让主控线程sleep几秒，保证普通线程在主控线程退出前有充分时间运行3.pthread_self获得的线程id和pthread_create传出的线程id是否等价？ 考虑这个问题之前，先来看一下pthread_create的内部实现1.创建线程2.clone 共享资源3.传出线程id完成前两步的时候，该线程就能被内核调用，现在假设这样一种情况，线程处理函数的工作极其短暂，在pthread_create尚未传出线程id的时候，线程就结束了。那么当线程id传出时，这个线程已经不在了。 因此区别在于pthread_self一定能保证线程是存活的，而后者可能线程已经结束了。 再考虑一种情况，假如传出的线程id是一个全局变量，在线程处理函数中打印这个全局的线程id，如果说此时线程创建函数还没有传出这个值，只是完成了前两步，那么这个全局变量就是未初始化的值，不是真正的线程id。","comments":true,"tags":[{"name":"Linux","slug":"Linux","permalink":"https://oldbuffalo.github.io/tags/Linux/"},{"name":"操作系统","slug":"操作系统","permalink":"https://oldbuffalo.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"Windows下的线程","date":"2018-11-06T13:08:17.000Z","path":"2018/11/Windows下的线程/","text":"线程介绍进程中的执行单元，线程是最小的调度单位，进程是最小的分配资源的单元。换言之，就是线程是进程的一部分，帮进程干事情，cpu调度的是线程，而不是进程，进程只提供一块空间。特点:1.轻量2.可并发执行3.切换开销小4.共享进程资源，也有自己特有的线程堆栈和内核对象因为线程共享进程的资源很多，例如进程的地址空间、打开文件、定时器、信号量、全局、静态变量等，拥有的系统资源很少，因此很轻量，从而上下文切换的开销很小。 什么时候需要使用线程？在同一个进程中，需要完成不同的工作，又不想因为某个工作阻塞而影响别的工作的时候，就将不同的工作放在不同的线程，并发的执行，这样既可以提高程序吞吐量又可以改善响应时间。 线程状态转换 其中可运行也称为就绪。就绪-&gt;运行 获得cpu时间片运行-&gt;就绪 cpu时间片耗尽运行-&gt;阻塞 1.等待I/O操作发生2.sleep3.试图获得锁4.等待事件阻塞-&gt;就绪 1.I/O操作完成2.sleep时间到了3.成功获得锁4.事件触发 那么为什么不能从阻塞到运行以及就绪到阻塞呢？ 线程构成1.线程堆栈(函数中的局部变量和函数参数)，线程退出时释放2.内核对象(Windows核心编程第三章有对这个概念深入的介绍) 这里主要关注内核对象中的使用次数(计数器)、暂停次数(挂起计数器)、信号(已通知=FALSE) 使用次数初始值为2，线程退出时减1，关闭句柄的时候减1，为0时释放内核对象 暂停次数初始值为1，在创建线程时判断是否有挂起标志，没有的话再置为0 信号初始值为FALSE，线程退出时变为TRUE，一般用WiatForSingleObject()检测是否有信号，从而判断线程是否正常退出 线程的常用函数创建CreateThread和_beginthreadex 创建成功返回句柄参数就不罗列了，有安全属性，线程栈大小，线程函数入口地址，传入参数，创建标志，线程ID 这里着重强调一下两者的区别(介意使用后者)前者是Windows函数，后者是C/C++运行期库函数，主要的区别在于对于系统全局变量的影响上。比如C运行库全局变量errno，在系统函数出错时进行赋值，如果是多线程编程，很容易造成值覆盖的问题。 12345if(&#x2F;*某个系统函数调用出错*&#x2F;)&#123; switch(errno)&#123; &#x2F;&#x2F;错误处理函数 &#125;&#125; 假如线程A运行到if和switch之间，时间片用完了，这时候errno已经被赋值，但是还没进入switch的时候被切换掉了，此时同一进程的线程B运行时某个函数改动了errno，当线程A重新切换到运行态的时候，errno的值已经不是预想的了。因此要避免这种多线程访问修改导致数据覆盖的问题。 CreateThread没有办法解决这个问题，_beginthreadex在创建新线程时会分配并初始化一个_tiddata块。这个_tiddata块自然是用来存放一些需要线程独享的数据。事实上新线程运行时会首先将_tiddata块与自己进一步关联起来,从而接下里调用标准C运行库函数进行操作时就只会改变线程自身数据块的值。 注意点：1.通过句柄操作线程，线程退出时要记得关闭句柄​ 2.无法连着两次关闭句柄​ 3.创建之后关闭了句柄，线程还在，只是无法操作线程了。 挂起、唤醒SuspendThread、ResumeThread注意:1.每挂起一次，内核对象的挂起计数器就加1，为0时线程才工作，因此挂起多少次，就要唤醒对应次数​ 2.对于一个尚未挂起的线程进行唤醒是无用的操作。 死亡1.函数返回 return 这是最好的方式2.ExitThread _endthreadex 最好使用后者 这两个函数只能销毁自身，释放堆栈3.TerminateThread 强制杀死任意线程 不安全 不释放资源4.包含线程的进程退出 将线程函数作为类成员函数需要注意的问题？要定义成静态成员变量。因为非静态成员函数都会在参数列表中加上一个this指针为为参数,线程处理函数相当于变成DWORD WINAPI ThreadFun(LPVOID, CMyClass *this) ，这和标准的线程函数就不匹配了，编译就通不过。况且，如果是非静态成员函数，不定义类对象或者指针就无法调用，一旦对象生命期结束了，难道线程函数就无法调用了？因此要脱离类本身存在，定义成静态的(相当于一个全局函数)。","comments":true,"tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://oldbuffalo.github.io/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Windows","slug":"Windows","permalink":"https://oldbuffalo.github.io/tags/Windows/"}]},{"title":"重载","date":"2018-11-03T04:14:26.000Z","path":"2018/11/重载/","text":"函数重载多个函数拥有相同的函数名，但是参数列表不同，仅仅返回值不同不行。 参数列表包括参数的类型、参数的个数、参数顺序，只要有一个不同就叫参数列表不同。 在C语言中，如果需要实现两个数相加，但不确定类型，可能需要定义多个函数 int add1(int,int); double add2(double,double) 在C++中，函数重载就体现了它的优势，没必要取多个函数名，有时候取名字真的是一件很麻烦的事情。 int add(int,int); double add(double,double); 在具体调用的时候会根据传入的参数，选择对应的函数。 重载实现机理C++代码在编译时会根据参数列表对函数重命名。 举个例子,int Add(int a,int b)会被重命名为Add_int_int,double Add(double a,double b)会被重命名为Add_double_double。当发生函数调用时，编译器根据传入的实参去猪哥匹配，选择对应的函数，如果匹配失败，编译器报错，这叫重载决议。也就是说本质上它们还是不同的函数，占用不同的内存，入口地址也不一样。 操作符重载对于内类的数据类型，执行一些操作很方便，譬如将两个整数相加，但是如何将两个类对象相加呢？ 这时候操作符重载就派上作用了，所谓操作符重载就是运算符与类结合，产生新的定义。 注意：不能重载的运算符有 .和.*和? : 和:: 和sizeof 如何实现定义成类的成员函数或者友元函数，当然如果不需要访问类中非公有成员，也不需要友元，只需定义成全局函数。 假设现在有一个Test类。 重载加号、减号第一种方式 Test operator+(const Test&amp; ); //第一个操作数必须是类对象第二种方式 Test operator+(const Test&amp;,const Test&amp;); //定义成友元函数，解决加法交换律 调用方式：1.隐式调用 obj1+obj22.显式调用 obj1.operator(obj2)—-成员函数 operator+(obj1,obj2)—–友元函数 执行时 ，隐式调用和显式调用都会调用operator+() 重载自增，自减 123456789Test operator++()&#123; &#x2F;&#x2F;++obj this-&gt;x++; return *this;&#125;Test operator(int x)&#123; &#x2F;&#x2F;obj++ Test temp &#x3D; *this; &#x2F;&#x2F;保存原有的状态 this-&gt;x++; retrun temp;&#125; 前缀形式，通过返回*this或者自身引用，也就是返回变化之后的结果 （++obj,–obj） 后缀形式，有一个int类型的虚参，返回的是原状态是拷贝后的临时变量。","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"}]},{"title":"构造函数","date":"2018-11-02T04:52:10.000Z","path":"2018/11/构造函数/","text":"构造函数介绍构造函数：类通过一个或几个特殊的成员函数来控制其成员对象的初始化过程。 特点：1. 没有返回类型 2. 支持重载 3. 不能被声明成const(这一点还不是很理解 先码上 C++Primer p235) 4.无法被子类继承 既然构造函数也是函数，那么什么时候调用构造函数？ 答案：对象被创建的时候。 构造函数执行顺序: ①传参 ②给类数据成员开辟空间 ③执行冒号语法给数据成员初始化 ④执行构造函数括号里面的内容 如果不指定构造函数，编译器会默认生成一个构造函数，拷贝构造函数(浅拷贝)，析构函数,重载=操作符函数。 当我们不需要编译器生成的这么函数时，就需要自己显式地声明出来。通过利用这点我们就可以限制对象的产生，例如，我们将默认构造函数，拷贝构造函数声明为私有，就可以防止外界来产生这个对象，这点主要是在单例模式中使用。 如果我们需要默认的构造函数可以用 类名()=default; //C++11新特性 初始化成员对象的方式 构造函数里赋值 初始化列表 类内直接初始化(C++11新特性） 需要注意的是：const类型的成员、引用以及只有带参数构造的类成员 必须使用初始化列表或者类内直接初始化(编译器不支持的话就只能选用前者) 例如: 1234567891011121314151617class A&#123; int x; A(int y)&#123;x = y;&#125;&#125;;class B&#123; A a; const int b; int &amp;c; static int si; static const int sci; static const int sci2 = 100; static const double = 99.9 //error //在vs2012中只有静态常量整型才能在类中初始化 B():a(100),b(10),c(c.a)&#123;&#125;&#125;; int B::si = 1;const int B::sci = 2; 由此可见，初始化列表和构造函数赋值完成的是同样的工作，但是有的工作构造函数做不了，因此最好使用初始化列表，整理一下理由。 const类型的成员、引用以及只有带参数构造的类成员 必须使用初始化列表或者类内直接初始化 效率更高，这涉及初始化和赋值关于底层效率的问题。如果在类的构造函数中赋值，在成员初始化时会调用一次默认的构造函数，在函数体中赋值又调用一次。而利用初始化列表仅调用一次。 成员变量初始化顺序用初始化列表进行初始化，是按照变量声明的顺序进行初始化 123456class T&#123; int x; int y; T(int val):y(val),x(y+1)&#123;&#125; &#125;; &#x2F;&#x2F;输出x&#x3D;-858993459,y&#x3D;10 可见x是一个未定义的值，这是因为编译器先初始了x，因为x先定义，此时y还没有被初始化为10。由此可见变量初始化的顺序跟变量在内存中的顺序有关。 解决方案：1.保持声明和初始化顺序一致 2.使用构造函数赋值 需要注意的点：static成员变量必须在类外初始化 为什么？ 因为在类外定义和初始化是保证static成员变量只被定义一次的好方法，static变量的生命期与类对象是异步的，这也是可以用作用域访问静态成员变量的原因。如果在类内初始化，让静态成员变量依赖于类对象，就无所谓静态两字了。 继承关系的初始化顺序： 基类的静态成员 派生类的静态成员 基类的成员变量 派生类的成员变量 当派生类中不含对象成员时: 构造执行顺序: 基类-&gt;派生类(构造函数无法被继承，为了继承父类中的成员变量，要先调用父类的构造) 析构执行顺序：派生类-&gt;基类 当派生类中含有对象成员时：构造执行顺序:基类-&gt;对象成员构造-&gt;派生类(类成员初始化总在构造函数执行之前) 析构执行顺序:派生类-&gt;对象成员析构-&gt;基类 扩展关于构造函数，C++11新特性还有一个委托构造函数，大致想法就是使用别的构造函数来实现自己。(C++ primer 261)","comments":true,"tags":[{"name":"C++","slug":"C","permalink":"https://oldbuffalo.github.io/tags/C/"}]},{"title":"知识点整理","date":"2018-11-01T04:14:07.000Z","path":"2018/11/知识点整理/","text":"整理一下C++后端需要掌握的知识点，以备自己复习和整理。 C语言数据类型和类型转换类型修饰符(static const extern)标准I/O 文件I/O运算符优先级define和typedef(注意区别 以及使用上的注意点) 数组(二维数组 指针数组 数组的指针 下标访问原理) 数组名(sizeof &amp;)指针(二级指针 指针常量 常量指针)动态申请内存(malloc free)字符串(各种库函数 strlen strcat strcpy strcmp strncpy strncmp atoi itoa…)结构体(对齐方式)枚举、联合内存分区(堆区 栈区 静态数据区(全局/静态变量(分成初始化和未初始化的) 、 文字常量区(字符串常量)) 代码段 命令行参数)多文件编译(编译的过程、头文件包含去重) C++命名空间标准I/O 文件I/O(注意和C效率上的区别)动态申请内存(new delete 注意和C的区别)封装(类 访问修饰符 友元)this指针构造、析构、重载操作符、拷贝构造引用(注意和指针的区别)、const(注意和C的区别)类和类之间的关系(四种平行关系)继承(继承修饰符、单继承、多继承)虚函数、多态、函数重载、重写、内联STL六大组件(内容很多)模板(泛型编程)C++11和C++17新特性异常处理 OS线程(特点、使用场合、内部结构、状态转换)线程之间通信(全局变量、发送消息)线程同步windows(临界区、事件、互斥量、信号量…)linux(临界区(互斥锁)、条件变量、读写锁、信号量…)线程同步典型问题:生产者—消费者模型、哲学家就餐模型、读者写者死锁(定义、产生原因、条件、避免算法(银行家算法))进程(特点、内存分布、与线程的区别)进程间通信(IPC)windows(文件映射、共享内存(前一种的特例)、匿名管道、命名管道、邮件槽、剪贴板、网络….)linux(匿名管道、有名管道、消息、内存共享映射、消息队列、信号量、网络…)多线程模型、线程池、进程池、内存池cpu调度算法(一般是分时复用)内存管理(连续和非连续)分页、段、段页式、页面置换算法、调用约定 网络ip分类和子网划分、子网掩码库(动态库和静态库 区别、适用场合)OSI七层模型、TCP/IP四层模型(每层的作用 )UDP(报文结构、数据报、特点、适用场合)TCP(报文结构、数据流、特点、使用场合、滑动窗口、流量控制、超时重发)三次握手四次挥手(为什么 每次都干了什么)、心跳保活机制HTTP(特点、请求方式、返回码、爬虫)、抓包工具服务器基础 C/S模型 B/S模型I/O模型windows(select、消息机制、时间通知、完成端口)linux(select、poll、epoll)多线程模型服务器(nginx)、多进程模型服务器(Apache) 数据库(知识点还不是很了解、带补)关系型数据库Mysql(增删改查 索引 事务 )数据库引擎、数据库优化Mysql底层实现(好像是红黑树)关系型数据库Mongdb(增删改查 ) 数据结构和算法数组、链表、栈、队列、矩阵二叉树(前序 中序 后序遍历 Morris遍历)、序列化和反序列化哈夫曼编码AVL树、红黑树、B树、B+树、B-树图(有向、无向、有权、无权)图的深度优先和广度优先遍历、拓扑排序、最小生成树问题、单源最短路径问题堆结构哈希表、一致性哈希结构、并查集结构与应用布隆过滤器和bitmap算法(大量数据去重)排序算法(分析其时间空间复杂度)二分查找、字符串查找算法(KMP、Manacher…)贪心、动态规划(0-1背包问题) linux(待补)虚拟机的使用vim使用、Shell脚本/python脚本、Makefile编写、gdb调试基本命令(ls,cd….)文件系统(inode)、信号、进程、线程、网络 其他必备知识git、github、markdown写作习惯正则表达式win32、MFC、Qt","comments":true,"tags":[{"name":"随笔","slug":"随笔","permalink":"https://oldbuffalo.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"写给21岁的自己","date":"2018-10-27T13:22:16.000Z","path":"2018/10/写给21岁的自己/","text":"现状​ 今天哈尔滨下了第一场雪，我才恍惚间发现，这已经是我上大学的第三年了。仍然记得来上大学第一年，是在我生日的那天下的第一场雪，这两年不变的是寒冷，变的是心境。 告别那个她​ 前几天生日的时候和大哥聊了一晚上，也释怀了很多。分手了也快两个月了，虽然表现得若无其事的样子，宿友和同学也并不知晓，但还是会在深夜难过，会偷偷看她的朋友圈和微博。但前几天有人问怎么最近没看见你和你女朋友视频，我尴尬地笑了笑，说了句分手了。其实喜欢一个人的时候，最害怕自己变得无趣。每天只耳语两三句的日子已经有一阵了，我曾经也想到过会有这样的结局。但更愿意相信这种状态是短暂的，异地状态在毕业就能解除，凭着对彼此的喜欢能支撑着下去。虽然最后分手不仅仅是因为彼此的交流变少了，但这是一个主要原因。究其原因，在于我自己。刚分手的那几天，每天都翻着以前的聊天记录，想着当初为什么喜欢说那么多废话，那么愿意和她分享生活中的小事，上课迟到了要说，走路滑倒了也要说，但久而久之，越来越觉得没有必要说了。我是个很容易受感情影响的人，很难将情感和生活分离开来。我狠下心来删掉了联络方式，即便如此我还是切不断过去。 分手时她说的话我一直都保存在备忘录中，每天晚上都拿出来看一下，问一问自己为什么。如今我已经从感情中走了出来，但还有很长的时间去和过去告别。我不知道我什么时候有勇气去删掉手机相册里关于她的照片，什么时候有勇气去丢弃她送的种种礼物，什么时候真的不在意她生活的点点滴滴。努力去遗忘，努力尝试新的开始，很喜欢那天大哥说的一句话:分手也是另一种抵达。过去的一段经历，会让你更清楚地知道你喜欢什么的人，自己在恋爱关系中需要改进的地方，以及一段属于两个人的回忆。不说了，好好学习去了，人丑单身还不学习，将来我的儿子可怎么找小姐姐。 我还有他们 上了大学之后，和爸妈见面的机会越来越少，可以说的话也越来越少。从小到大，虽然家里不是很富裕，但是爸妈总是能满足我的要求，有很多时候我想要这想要那，但都藏在心里了。因为我知道，他们做多已经够多了，以后想要的东西得靠你自己去争取。因此，这一年，就算从小妈妈跟我说读书是为了你自己，但我想这一年为了他们而学，尽早地实现财务自由，为他们逐渐老去的背影提供可靠的保障。 关于我两年前，我是带着一份不甘心来到这里的，时时刻刻想说这里不属于我，虽然的确用GPA证明了自己，但是始终找不到自己的方向，因此我开始接触软件，也学习硬件。在比较中慢慢找寻，逐步放弃，我发现可能编程是适合我的那一个。虽然现在我已经熟悉了很多，但 远远没达到我心目中的高度。最近一直在听一首歌《像我这样的人》，感触很多，像我这样平凡的人又不甘平凡的人，世界上很多，不用力活一回， 你又怎么会成为那个闪闪发光的人呢？ 记录一段话，以此自省 害怕平凡，却无意间被人潮左右，害怕被左右，却无奈像羔羊前涌。不停追逐，猛然间才发现依然不过是万千平凡中的一个。自信却因为现实不得不自卑。什么都懂，却又不想放弃固守的那一份单纯。觉得自己不一样，却真的找不出和他人的异同。 憧憬既然已经决定直接秋招，非科班出身又没有优势，就给自己提几点要求。 增强理论知识，多看书籍 接下来要完成的书单（完成之后再来滑掉） Effective C++ More Effective C++ STL源码解析 C++设计模式 Windows核心编程 TCP/IP详解 Linux网络编程 Linux环境高级编程 算法4 编程之美 好好利用Github，锻炼写博客的能力 再写一个项目，回顾一下之前写过的 坚持LeetCode、牛客刷题，提升一下手写代码的能力 多涉猎各个领域的书籍，文字表达能力有多差心里有点数 锻炼身体！！！！减肥减肥减肥","comments":true,"tags":[{"name":"随笔","slug":"随笔","permalink":"https://oldbuffalo.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"汉诺塔问题","date":"2018-10-04T07:48:42.000Z","path":"2018/10/汉诺塔问题/","text":"问题描述有a,b,c三根柱子，如今柱子a上面有64个盘子(盘子大小从上到下按大小排列)目的:将柱子a上面的盘子全部移动到柱子c上面，列出方法和次数规则: 1. 每次只能移动一个盘子 2. 小盘子只能放在大盘子之上 这是一道很经典的题目，问题描述也很简单，用递归做起来也比较简单，但不是很好理解 分析算法一直是我的软肋，尤其是涉及递归的更加不好理解(为何如此之菜，哎)一上来碰到这种问题肯定没什么思路，机智如我就开始找规律嘛64个太多,那就从1个开始吧。1个 a-&gt;c 1次2个 a-&gt;b a-&gt;c b-&gt;c 3次3个 a-&gt;c a-&gt;b c-&gt;b a-&gt;c b-&gt;a b-&gt;c a-&gt;c 7次这时候根据我多年找规律的经验就可以大胆地猜测 总的次数是2^n-1那64个的话应该是2^64-1(天文数字 根本不可能完成的任务)虽然猜出了次数(毫无理论依据,逃)，但是还是不知道移动的次序。 问题分解从第一步开始想大概率是毫无头绪的，因为你有无数种选择。那么倒推着想。首先假设已经成功将a柱上面的63个盘子移到了b柱，此时只要将a柱最后一个盘子移动到c柱，这是确定的。这时候问题就变成了，如何将b柱上63个盘子移动到c。这和之前的问题一模一样，只不过数据规模变小了，并且是从a变到了b。因此可以采用一个的思考方法，先将b上面的62个盘子移到a，再将最下面的盘子移到c，以此类推就有了解决问题的一个循环的流程。 递归以上的流程就是一个递归的过程。我所理解的递归就是有不断地用更小规模的数据去求上层数据，当然必须有一个终止的时刻返回。 代码展示1234567def fun(n,a,b,c): #n代表数据规模 a,b,c是三个柱子 从a-&gt;c if n &#x3D;&#x3D; 1: print(a,&#39;-&gt;&#39;,c) else: fun(n-1,a,c,b) #第一步把n-1个数据从a-&gt;b print(a,&#39;-&gt;&#39;,c) #第二步把第n个数组从a-&gt;c fun(n-1,b,a,c) #这时候问题规模下降1 变成n-1个数从b-&gt;c的问题 拓展我们知道绝大多数的递归都能用循环来写，这里有一种循环方式实现的方法，代码过长这里就不贴出来了，链接 总结其实就是想发篇博客练一下warkdown语法的，但是被各种空格，对齐方式所折磨。算法很捉急，这算是个开头吧。","comments":true,"tags":[{"name":"算法","slug":"算法","permalink":"https://oldbuffalo.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"庆祝博客的诞生","date":"2018-09-20T05:20:28.000Z","path":"2018/09/庆祝博客的诞生/","text":"起源去年就一直想搭一个属于自己的博客，但疏于前端知识的缺乏，动手了几次都因为各种问题搁置了这个想法。随着学的东西越来越多，越发觉得需要一个用来整理、回顾知识的博客。于是，上网找了各种教程和视频，捣鼓了两天终于搭建完成了。 心路历程前期跟着教程安装node.js git 和 hexo都很顺利。本地的静态博客也搭建完毕了，于是在阿里云买了个域名，dns服务器解析也添加了记录，但用自己的域名始终ping不出来，试了一下午都没解决，最后发现是在阿里云上没有实名认证。紧接着马上写了个测试博文，随之而来的是第二个问题，点P击博文标题无法跳转，又是找了一下午的问题，一遍又一遍看各种配置文件和js文件都没搞定，真的是心力交瘁，无奈一下换了个主题问题就解决了，吐槽archer，也可能我不会用啊哈哈哈。 Futuer总之，基础的博客总算搭建完成，其余的各种插件和功能后期再慢慢研究和加入吧，纪念一下这个激动人心的时候，接下来要好好利用这个平台，坚持写博文,day day up。最后感谢一下这个博主的分享 链接 测试一下 ceshi sad sads sadsad 新增 wuyu 12import mathprint(math.sqrt(2))","comments":true,"tags":[{"name":"随笔","slug":"随笔","permalink":"https://oldbuffalo.github.io/tags/%E9%9A%8F%E7%AC%94/"}]}]